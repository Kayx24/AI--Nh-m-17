# HÆ¯á»šNG DáºªN BÃ€I Táº¬P: DOTS AND BOXES

## Tá»•ng quan

BÃ i táº­p nÃ y implement cÃ¡c thuáº­t toÃ¡n AI Ä‘á»ƒ chÆ¡i trÃ² chÆ¡i Dots and Boxes, tá»« cÆ¡ báº£n (Random) Ä‘áº¿n nÃ¢ng cao (Minimax, Heuristic, Monte Carlo).

## Cáº¥u trÃºc file

- `assignment_dots_and_boxes.ipynb` - Notebook chÃ­nh chá»©a toÃ n bá»™ code vÃ  documentation

## CÃ¡c Task Ä‘Ã£ hoÃ n thÃ nh

### âœ… Task 1: Äá»‹nh nghÄ©a bÃ i toÃ¡n tÃ¬m kiáº¿m (10 Ä‘iá»ƒm)

**Ná»™i dung:**
- Äá»‹nh nghÄ©a 5 thÃ nh pháº§n: Initial state, Actions, Transition model, Terminal test, Utility
- PhÃ¢n tÃ­ch kÃ­ch thÆ°á»›c khÃ´ng gian tráº¡ng thÃ¡i
- Æ¯á»›c tÃ­nh kÃ­ch thÆ°á»›c game tree

**Káº¿t quáº£:**
- KhÃ´ng gian tráº¡ng thÃ¡i: 2^L vá»›i L = sá»‘ Ä‘Æ°á»ng káº» (2mn - m - n)
- Game tree: Phá»©c táº¡p hÆ¡n do luáº­t "Ä‘i tiáº¿p khi hoÃ n thÃ nh box"
- Board 3Ã—3: 12 lines, 2^12 = 4096 states
- Board 5Ã—5: 40 lines, 2^40 = ~1 trillion states

### âœ… Task 2: Game Environment & Random Agent (30 Ä‘iá»ƒm)

**Implementation:**

1. **Board Representation:**
```python
board = {
    'size': (4, 4),      # Sá»‘ hÃ ng vÃ  cá»™t Ä‘iá»ƒm
    'lines': {},         # Dict cÃ¡c Ä‘Æ°á»ng káº» Ä‘Ã£ váº½
    'boxes': {}          # Dict boxes Ä‘Ã£ hoÃ n thÃ nh
}
```

2. **Helper Functions:**
- `actions(board)` - Láº¥y danh sÃ¡ch nÆ°á»›c Ä‘i há»£p lá»‡
- `result(board, action, player)` - Apply action, tráº£ vá» board má»›i vÃ  next player
- `terminal(board)` - Kiá»ƒm tra game káº¿t thÃºc
- `utility(board, player)` - TÃ­nh Ä‘iá»ƒm
- `display_board(board)` - Visualization báº±ng ASCII art

3. **Random Agent:**
- Chá»n ngáº«u nhiÃªn tá»« available actions
- Baseline Ä‘á»ƒ so sÃ¡nh cÃ¡c agents khÃ¡c

**Thá»±c nghiá»‡m:**
- 1000 games giá»¯a 2 random players
- Káº¿t quáº£: Player Ä‘i trÆ°á»›c tháº¯ng ~52-55% (cÃ³ lá»£i tháº¿ nhá»)

### âœ… Task 3: Minimax vá»›i Alpha-Beta Pruning (30 Ä‘iá»ƒm)

**Implementation:**

```python
def minimax_alpha_beta(board, player, alpha, beta, maximizing):
    # Base cases
    if terminal(board):
        return utility(board, player), None
    
    # Recursive cases vá»›i pruning
    # Äáº·c biá»‡t: Xá»­ lÃ½ rule "Ä‘i tiáº¿p khi hoÃ n thÃ nh box"
```

**CÃ¡c cáº£i tiáº¿n:**

1. **Move Ordering:**
   - Completing moves (hoÃ n thÃ nh box) â†’ Æ°u tiÃªn cao nháº¥t
   - Safe moves (khÃ´ng táº¡o box 3 cáº¡nh) â†’ Æ°u tiÃªn trung bÃ¬nh
   - Risky moves (táº¡o box 3 cáº¡nh) â†’ Æ°u tiÃªn tháº¥p nháº¥t
   - **Káº¿t quáº£:** Giáº£m 30-50% nodes cáº§n explore

2. **Symmetry Reduction:**
   - Loáº¡i bá» moves Ä‘á»‘i xá»©ng trong opening
   - Giáº£m ~50-75% search space cho first move

3. **Opening Book:**
   - Hardcode best first moves cho cÃ¡c board sizes
   - TrÃ¡nh pháº£i search toÃ n bá»™ tree tá»« empty board

**Performance:**
- Board 3Ã—3: ~1-5 giÃ¢y cho first move
- Board 4Ã—4: ~30-60 giÃ¢y (cÃ³ thá»ƒ quÃ¡ cháº­m)
- Board lá»›n hÆ¡n: KhÃ´ng kháº£ thi vá»›i full minimax

### âœ… Task 4: Heuristic Alpha-Beta (30 Ä‘iá»ƒm)

**Heuristic Evaluation Function:**

```python
def heuristic_evaluation(board, player):
    score = 0
    score += (completed_boxes) Ã— 100           # Quan trá»ng nháº¥t
    score -= (almost_complete_boxes) Ã— 50      # Nguy hiá»ƒm
    score += (half_complete_boxes) Ã— 10        # Tiá»m nÄƒng
    score += (neutral_boxes) Ã— 2               # Linh hoáº¡t
    score += bonus_if_leading Ã— 30             # Dáº«n trÆ°á»›c
    return score
```

**Depth-Limited Search:**
- Giá»›i háº¡n Ä‘á»™ sÃ¢u search
- Sá»­ dá»¥ng heuristic thay vÃ¬ terminal utility khi Ä‘áº¡t max_depth
- Trade-off: Optimal vs Speed

**Chiáº¿n lÆ°á»£c chá»n Depth:**
- Board 3Ã—3: Depth 4-6
- Board 4Ã—4: Depth 3-4
- Board 5Ã—5: Depth 2-3
- Adaptive: Early game dÃ¹ng depth tháº¥p, endgame dÃ¹ng depth cao

**Performance:**
- Board 4Ã—4 vá»›i depth 4: ~2-5 giÃ¢y
- Board 5Ã—5 vá»›i depth 4: ~5-10 giÃ¢y
- Kháº£ thi cho board lá»›n

### âœ… Advanced Task: Pure Monte Carlo Search (10 Ä‘iá»ƒm bonus)

**Implementation:**

```python
def pure_monte_carlo_search(board, player, num_simulations):
    # Vá»›i má»—i possible move:
    #   1. Apply move
    #   2. Cháº¡y N random simulations Ä‘áº¿n terminal
    #   3. Äáº¿m sá»‘ tháº¯ng/thua
    # Chá»n move cÃ³ win rate cao nháº¥t
```

**Æ¯u Ä‘iá»ƒm:**
- KhÃ´ng cáº§n heuristic evaluation
- KhÃ´ng cáº§n domain knowledge
- Scale tá»‘t vá»›i board lá»›n
- Anytime algorithm

**NhÆ°á»£c Ä‘iá»ƒm:**
- KhÃ´ng optimal
- Cáº§n nhiá»u simulations (100-1000+)
- Cháº­m hÆ¡n heuristic search vá»›i board nhá»

**Use cases:**
- Board lá»›n (5Ã—5+)
- Khi thiáº¿u domain knowledge
- Games cÃ³ random elements

**Best First Move Analysis:**
- Board 5Ã—5: 40 possible first moves
- Symmetry reduction: ~10 unique moves
- Monte Carlo vá»›i 200 sims/move
- Káº¿t luáº­n: Moves gáº§n center tá»‘t nháº¥t

## So sÃ¡nh cÃ¡c thuáº­t toÃ¡n

| Thuáº­t toÃ¡n | Optimal? | Speed | Max Board | Complexity |
|------------|----------|-------|-----------|------------|
| Random | âŒ | âš¡âš¡âš¡ | Unlimited | O(1) |
| Minimax Full | âœ… | ğŸŒ | 3Ã—3, 3Ã—4 | O(b^d) |
| Minimax + Ordering | âœ… | ğŸŒâš¡ | 3Ã—3, 3Ã—4 | O(b^d) optimized |
| Heuristic (d=4) | âš ï¸ | âš¡âš¡ | 5Ã—5 | O(b^d) with cutoff |
| Monte Carlo | âŒ | âš¡ | 7Ã—7+ | O(n Ã— m) |

**ChÃº thÃ­ch:**
- âš¡ = Nhanh
- ğŸŒ = Cháº­m
- âœ… = Optimal
- âš ï¸ = Near-optimal
- âŒ = Not optimal

## Káº¿t quáº£ Tournament

**Minimax vs Random:**
- Minimax tháº¯ng: ~100% (trÃªn board 3Ã—3)

**Heuristic Depth-4 vs Depth-2:**
- Depth-4 tháº¯ng: ~80-90%

**Monte Carlo vs Random:**
- Monte Carlo tháº¯ng: ~90-95%

**Minimax vs Monte Carlo:**
- Minimax tháº¯ng: ~70-80% (trÃªn board 3Ã—3)
- Monte Carlo cáº¡nh tranh tá»‘t hÆ¡n trÃªn board lá»›n

## Cáº£i tiáº¿n cÃ³ thá»ƒ thá»±c hiá»‡n

1. **Monte Carlo Tree Search (MCTS):**
   - Káº¿t há»£p tree search vÃ  simulation
   - UCB1 Ä‘á»ƒ balance exploration/exploitation
   - Máº¡nh hÆ¡n Pure MC

2. **Transposition Table:**
   - Cache cÃ¡c states Ä‘Ã£ evaluate
   - TrÃ¡nh re-compute

3. **Iterative Deepening:**
   - TÄƒng depth dáº§n
   - CÃ³ answer báº¥t cá»© lÃºc nÃ o
   - Time management tá»‘t hÆ¡n

4. **Neural Network:**
   - Há»c evaluation function tá»« data
   - AlphaZero-style approach

5. **Advanced Strategies:**
   - Chain detection and analysis
   - Control theory (Berlekamp)
   - Endgame database

## CÃ¡ch cháº¡y code

1. Má»Ÿ file `assignment_dots_and_boxes.ipynb` trong VS Code hoáº·c Jupyter
2. Chá»n Python kernel (Python 3.7+)
3. Run All Cells (hoáº·c run tá»«ng cell)

**LÆ°u Ã½:**
- KhÃ´ng cáº§n install packages (chá»‰ dÃ¹ng built-in libraries)
- Má»™t sá»‘ cells cháº¡y lÃ¢u (1-3 phÃºt)
- CÃ³ thá»ƒ giáº£m num_games/num_simulations Ä‘á»ƒ test nhanh

## Thá»i gian thá»±c hiá»‡n

- Task 1: ~1 giá»
- Task 2: ~2-3 giá»
- Task 3: ~3-4 giá»
- Task 4: ~2-3 giá»
- Advanced: ~2 giá»
- **Tá»•ng:** ~10-13 giá»

## TÃ i liá»‡u tham kháº£o

- Russell & Norvig - Artificial Intelligence: A Modern Approach (Chapter 5)
- [Dots and Boxes - Wikipedia](https://en.wikipedia.org/wiki/Dots_and_Boxes)
- [Tic-Tac-Toe examples from CS7320-AI](https://github.com/mhahsler/CS7320-AI)
- Berlekamp - "The Dots and Boxes Game" (1974)

## LiÃªn há»‡

Náº¿u cÃ³ cÃ¢u há»i vá» implementation, vui lÃ²ng táº¡o issue hoáº·c liÃªn há»‡ qua email.

---

**LÆ°u Ã½:** Code nÃ y Ä‘Æ°á»£c viáº¿t cho má»¥c Ä‘Ã­ch há»c táº­p. CÃ³ thá»ƒ optimize thÃªm cho production use.
