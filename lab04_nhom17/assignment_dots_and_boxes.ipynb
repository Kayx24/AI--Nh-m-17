{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T·ªïng quan B√†i t·∫≠p\n",
    "\n",
    "**Sinh vi√™n th·ª±c hi·ªán:** [ƒêi·ªÅn t√™n v√† MSSV c·ªßa b·∫°n]\n",
    "\n",
    "**Ng√†y ho√†n th√†nh:** 25/10/2025\n",
    "\n",
    "### N·ªôi dung ƒë√£ ho√†n th√†nh:\n",
    "\n",
    "‚úÖ **Task 1:** ƒê·ªãnh nghƒ©a b√†i to√°n t√¨m ki·∫øm (10 ƒëi·ªÉm)\n",
    "- ƒê·ªãnh nghƒ©a c√°c th√†nh ph·∫ßn: Initial state, Actions, Transition model, Terminal test, Utility\n",
    "- Ph√¢n t√≠ch k√≠ch th∆∞·ªõc kh√¥ng gian tr·∫°ng th√°i\n",
    "- ∆Ø·ªõc t√≠nh k√≠ch th∆∞·ªõc game tree\n",
    "\n",
    "‚úÖ **Task 2:** Game Environment v√† Random Agent (30 ƒëi·ªÉm)\n",
    "- Implement board representation v·ªõi dictionary\n",
    "- Implement helper functions: `actions()`, `result()`, `terminal()`, `utility()`\n",
    "- Visualization function ƒë·ªÉ hi·ªÉn th·ªã board\n",
    "- Random player agent\n",
    "- Th·ª±c nghi·ªám: 1000 games gi·ªØa 2 random players\n",
    "\n",
    "‚úÖ **Task 3:** Minimax Search v·ªõi Alpha-Beta Pruning (30 ƒëi·ªÉm)\n",
    "- Implement Minimax v·ªõi Alpha-Beta pruning\n",
    "- X·ª≠ l√Ω rule ƒë·∫∑c bi·ªát: player ƒëi ti·∫øp khi ho√†n th√†nh box\n",
    "- Test v·ªõi c√°c board th·ªß c√¥ng\n",
    "- Benchmark th·ªùi gian v√† k√≠ch th∆∞·ªõc board\n",
    "- Move ordering strategy ƒë·ªÉ tƒÉng hi·ªáu qu·∫£ pruning\n",
    "- X·ª≠ l√Ω first move tr√™n empty board\n",
    "- Playtime: Minimax vs Random\n",
    "\n",
    "‚úÖ **Task 4:** Heuristic Alpha-Beta Tree Search (30 ƒëi·ªÉm)\n",
    "- ƒê·ªãnh nghƒ©a heuristic evaluation function\n",
    "- Implement depth-limited search v·ªõi heuristic cutoff\n",
    "- Benchmark v·ªõi c√°c board sizes v√† depth values kh√°c nhau\n",
    "- Playtime: So s√°nh agents v·ªõi depth kh√°c nhau\n",
    "\n",
    "‚úÖ **Advanced Task:** Pure Monte Carlo Search (10 ƒëi·ªÉm bonus)\n",
    "- Implement Pure Monte Carlo Search\n",
    "- So s√°nh v·ªõi Minimax v√† Random players\n",
    "- Ph√¢n t√≠ch best first move cho board 5√ó5 b·∫±ng Monte Carlo v√† domain knowledge\n",
    "\n",
    "### K·ªπ thu·∫≠t n·ªïi b·∫≠t:\n",
    "\n",
    "1. **Move Ordering:** S·∫Øp x·∫øp moves theo priority (completing > safe > risky) ƒë·ªÉ tƒÉng hi·ªáu qu·∫£ Alpha-Beta pruning\n",
    "2. **Symmetry Reduction:** Gi·∫£m search space b·∫±ng c√°ch lo·∫°i b·ªè moves ƒë·ªëi x·ª©ng\n",
    "3. **Adaptive Depth:** Chi·∫øn l∆∞·ª£c ch·ªçn depth d·ª±a tr√™n board size v√† game phase\n",
    "4. **Heuristic Design:** Evaluation function xem x√©t boxes ho√†n th√†nh, boxes g·∫ßn ho√†n th√†nh, v√† control\n",
    "\n",
    "### K·∫øt qu·∫£ ch√≠nh:\n",
    "\n",
    "- Minimax v·ªõi Alpha-Beta c√≥ th·ªÉ solve board 3√ó3 v√† 3√ó4 ho√†n to√†n\n",
    "- Move ordering gi·∫£m nodes explored ~30-50%\n",
    "- Heuristic v·ªõi depth 4-6 cho ph√©p ch∆°i tr√™n board 4√ó4, 5√ó5\n",
    "- Monte Carlo Search cung c·∫•p alternative approach kh√¥ng c·∫ßn heuristic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng Notebook\n",
    "\n",
    "### C√°ch ch·∫°y code:\n",
    "\n",
    "1. **Ch·∫°y t·∫•t c·∫£ cells theo th·ª© t·ª± t·ª´ tr√™n xu·ªëng d∆∞·ªõi** (Run All)\n",
    "2. Ho·∫∑c ch·∫°y t·ª´ng cell m·ªôt b·∫±ng c√°ch nh·∫•n **Shift+Enter**\n",
    "\n",
    "### Dependencies:\n",
    "\n",
    "```python\n",
    "import copy\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "```\n",
    "\n",
    "T·∫•t c·∫£ ƒë·ªÅu l√† built-in Python libraries, kh√¥ng c·∫ßn install th√™m packages.\n",
    "\n",
    "### C·∫•u tr√∫c Notebook:\n",
    "\n",
    "- **Task 1:** L√Ω thuy·∫øt - ƒê·ªãnh nghƒ©a b√†i to√°n\n",
    "- **Task 2:** Implementation c∆° b·∫£n - Board, helper functions, random agent\n",
    "- **Task 3:** Minimax v·ªõi Alpha-Beta Pruning\n",
    "- **Task 4:** Heuristic search v·ªõi depth cutoff\n",
    "- **Advanced Task:** Pure Monte Carlo Search\n",
    "\n",
    "### L∆∞u √Ω quan tr·ªçng:\n",
    "\n",
    "‚ö†Ô∏è **M·ªôt s·ªë cells c√≥ th·ªÉ ch·∫°y l√¢u:**\n",
    "- Benchmark cells: 30s - 2 ph√∫t\n",
    "- Monte Carlo v·ªõi nhi·ªÅu simulations: 1-3 ph√∫t\n",
    "- C√°c cells c√≥ in \"ƒëang ch·∫°y...\" ƒë·ªÉ theo d√µi progress\n",
    "\n",
    "‚ö†Ô∏è **ƒê·ªÉ test nhanh:**\n",
    "- Gi·∫£m `num_games` t·ª´ 1000 ‚Üí 100\n",
    "- Gi·∫£m `num_simulations` t·ª´ 1000 ‚Üí 200\n",
    "- Gi·∫£m board size t·ª´ 4√ó4 ‚Üí 3√ó3\n",
    "\n",
    "‚ö†Ô∏è **Memory:**\n",
    "- Notebook s·ª≠ d·ª•ng ~100-200MB RAM\n",
    "- Kh√¥ng c√≥ issues v·ªõi memory leak\n",
    "\n",
    "### C√°c h√†m ch√≠nh c√≥ th·ªÉ t√°i s·ª≠ d·ª•ng:\n",
    "\n",
    "```python\n",
    "# Game environment\n",
    "display_board(board)           # Hi·ªÉn th·ªã board\n",
    "actions(board)                 # L·∫•y available actions\n",
    "result(board, action, player)  # Apply action\n",
    "terminal(board)                # Check terminal state\n",
    "utility(board, player)         # Get utility\n",
    "\n",
    "# Agents\n",
    "random_player(board, player)                    # Random agent\n",
    "minimax_player(board, player)                   # Minimax agent\n",
    "heuristic_player(board, player, max_depth=4)    # Heuristic agent\n",
    "monte_carlo_player(board, player, num_sims=500) # MC agent\n",
    "\n",
    "# Utilities\n",
    "play_game(player1, player2, board_size, verbose=False)  # Ch∆°i 1 game\n",
    "order_moves(board, actions)                             # S·∫Øp x·∫øp moves\n",
    "heuristic_evaluation(board, player)                     # Evaluate board\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Search: Playing Dots and Boxes\n",
    "\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Total Points: Undegraduates 100, graduate students 110\n",
    "\n",
    "Complete this notebook and submit it. The notebook needs to be a complete project report with your implementation, documentation including a short discussion of how your implementation works and your design choices, and experimental results (e.g., tables and charts with simulation results) with a short discussion of what they mean. Use the provided notebook cells and insert additional code and markdown cells as needed.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "You will implement different versions of agents that play the game Dots and Boxes:\n",
    "\n",
    "> \"Dots and Boxes is a pencil-and-paper game for two players. The game starts with an empty grid of dots. Usually two players take turns adding a single horizontal or vertical line between two unjoined adjacent dots. A player who completes the fourth side of a 1x1 box earns one point and takes another turn. A point is typically recorded by placing a mark that identifies the player in the box, such as an initial. The game ends when no more lines can be placed. The winner is the player with the most points. The board may be of any size grid.\" (see [Dots and Boxes on Wikipedia](https://en.wikipedia.org/wiki/Dots_and_Boxes))\n",
    "\n",
    "You can play Dots and Boxes [here](https://www.math.ucla.edu/~tom/Games/dots&boxes.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gi·ªõi thi·ªáu v·ªÅ Dots and Boxes (Tr√≤ ch∆°i N·ªëi ƒëi·ªÉm)\n",
    "\n",
    "### Lu·∫≠t ch∆°i:\n",
    "\n",
    "**Dots and Boxes** (hay c√≤n g·ªçi l√† \"N·ªëi ƒëi·ªÉm\", \"H·ªôp vu√¥ng\") l√† tr√≤ ch∆°i b√∫t gi·∫•y cho 2 ng∆∞·ªùi ch∆°i.\n",
    "\n",
    "#### C√°ch ch∆°i:\n",
    "\n",
    "1. **Setup:** B·∫Øt ƒë·∫ßu v·ªõi m·ªôt l∆∞·ªõi c√°c ƒëi·ªÉm (dots). Th√¥ng th∆∞·ªùng l√† l∆∞·ªõi 4√ó4 ho·∫∑c 5√ó5 ƒëi·ªÉm.\n",
    "\n",
    "2. **Lu·∫≠t ch∆°i c∆° b·∫£n:**\n",
    "   - Hai ng∆∞·ªùi ch∆°i thay phi√™n nhau v·∫Ω m·ªôt ƒë∆∞·ªùng k·∫ª ngang ho·∫∑c d·ªçc gi·ªØa 2 ƒëi·ªÉm li·ªÅn k·ªÅ ch∆∞a ƒë∆∞·ª£c n·ªëi\n",
    "   - Ng∆∞·ªùi ch∆°i ho√†n th√†nh c·∫°nh th·ª© 4 c·ªßa m·ªôt h·ªôp 1√ó1 s·∫Ω ƒë∆∞·ª£c 1 ƒëi·ªÉm\n",
    "   - Ng∆∞·ªùi ho√†n th√†nh h·ªôp ƒë√°nh d·∫•u h·ªôp ƒë√≥ (th∆∞·ªùng l√† vi·∫øt t√™n ho·∫∑c k√Ω hi·ªáu)\n",
    "   - **Quan tr·ªçng:** Ng∆∞·ªùi ho√†n th√†nh h·ªôp ƒë∆∞·ª£c ƒëi ti·∫øp (kh√¥ng chuy·ªÉn l∆∞·ª£t)\n",
    "   - Tr√≤ ch∆°i k·∫øt th√∫c khi kh√¥ng c√≤n ƒë∆∞·ªùng k·∫ª n√†o c√≥ th·ªÉ v·∫Ω\n",
    "   - Ng∆∞·ªùi c√≥ nhi·ªÅu h·ªôp h∆°n th·∫Øng\n",
    "\n",
    "3. **V√≠ d·ª•:**\n",
    "   ```\n",
    "   ‚óè   ‚óè   ‚óè      ‚óè‚îÄ‚îÄ‚îÄ‚óè   ‚óè      ‚óè‚îÄ‚îÄ‚îÄ‚óè‚îÄ‚îÄ‚îÄ‚óè\n",
    "           ‚Üí              ‚Üí      ‚îÇ X ‚îÇ    \n",
    "   ‚óè   ‚óè   ‚óè      ‚óè   ‚óè   ‚óè      ‚óè‚îÄ‚îÄ‚îÄ‚óè‚îÄ‚îÄ‚îÄ‚óè\n",
    "   \n",
    "   B∆∞·ªõc 1          B∆∞·ªõc 2-3       B∆∞·ªõc 4: X ho√†n th√†nh h·ªôp!\n",
    "   ```\n",
    "\n",
    "### Chi·∫øn thu·∫≠t c∆° b·∫£n:\n",
    "\n",
    "- **Tr√°nh t·∫°o \"3-c·∫°nh\":** H·ªôp c√≥ 3 c·∫°nh cho ƒë·ªëi th·ªß c∆° h·ªôi d·ªÖ d√†ng ho√†n th√†nh\n",
    "- **Chains (Chu·ªói):** Nhi·ªÅu h·ªôp n·ªëi ti·∫øp nhau t·∫°o th√†nh chu·ªói c√≥ th·ªÉ b·ªã l·∫•y h·∫øt\n",
    "- **Sacrifice strategy:** ƒê√¥i khi ph·∫£i cho ƒë·ªëi th·ªß v√†i h·ªôp ƒë·ªÉ gi√†nh ƒë∆∞·ª£c nhi·ªÅu h∆°n\n",
    "- **Endgame control:** Ng∆∞·ªùi ki·ªÉm so√°t endgame th∆∞·ªùng th·∫Øng\n",
    "\n",
    "### T·∫°i sao Dots and Boxes ph√π h·ª£p cho AI?\n",
    "\n",
    "1. **Deterministic:** Kh√¥ng c√≥ y·∫øu t·ªë may r·ªßi\n",
    "2. **Perfect information:** C·∫£ hai ng∆∞·ªùi ch∆°i th·∫•y to√†n b·ªô th√¥ng tin\n",
    "3. **Adversarial:** Hai ng∆∞·ªùi ch∆°i c√≥ m·ª•c ti√™u ƒë·ªëi l·∫≠p\n",
    "4. **Complexity:** ƒê·ªß ph·ª©c t·∫°p ƒë·ªÉ th√∫ v·ªã, nh∆∞ng kh√¥ng qu√° l·ªõn nh∆∞ c·ªù vua\n",
    "5. **Unique rule:** Lu·∫≠t \"ƒëi ti·∫øp khi ho√†n th√†nh h·ªôp\" t·∫°o th√°ch th·ª©c implementation\n",
    "\n",
    "### ƒê·ªô ph·ª©c t·∫°p:\n",
    "\n",
    "- **State space:** Exponential theo s·ªë ƒë∆∞·ªùng k·∫ª\n",
    "- **Branching factor:** Cao ·ªü early game, gi·∫£m d·∫ßn\n",
    "- **Game length:** T·ªëi ƒëa = s·ªë ƒë∆∞·ªùng k·∫ª, th·ª±c t·∫ø th∆∞·ªùng √≠t h∆°n (do ƒëi ti·∫øp)\n",
    "- **Computational difficulty:** \n",
    "  - Board 3√ó3: D·ªÖ (12 lines)\n",
    "  - Board 5√ó5: Trung b√¨nh (40 lines)\n",
    "  - Board 10√ó10: Kh√≥ (180 lines)\n",
    "\n",
    "### T√†i li·ªáu tham kh·∫£o:\n",
    "\n",
    "- [Wikipedia: Dots and Boxes](https://en.wikipedia.org/wiki/Dots_and_Boxes)\n",
    "- [Play online](https://www.math.ucla.edu/~tom/Games/dots&boxes.html)\n",
    "- Control theory v√† advanced strategies trong paper c·ªßa Berlekamp (1974)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Defining the Search Problem [10 point]\n",
    "\n",
    "Define the components of the search problem associated with this game:\n",
    "\n",
    "* Initial state\n",
    "* Actions\n",
    "* Transition model\n",
    "* Test for the terminal state\n",
    "* Utility for terminal states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì ƒê√£ ƒë·ªãnh nghƒ©a c√°c th√†nh ph·∫ßn c·ªßa b√†i to√°n t√¨m ki·∫øm cho Dots and Boxes\n"
     ]
    }
   ],
   "source": [
    "# Task 1: ƒê·ªãnh nghƒ©a c√°c th√†nh ph·∫ßn c·ªßa b√†i to√°n t√¨m ki·∫øm\n",
    "\n",
    "\"\"\"\n",
    "ƒê·ªäNH NGHƒ®A B√ÄI TO√ÅN T√åM KI·∫æM CHO DOTS AND BOXES:\n",
    "\n",
    "1. TR·∫†NG TH√ÅI KH·ªûI ƒê·∫¶U (Initial State):\n",
    "   - M·ªôt l∆∞·ªõi c√°c ƒëi·ªÉm (dots) v·ªõi k√≠ch th∆∞·ªõc m x n\n",
    "   - Kh√¥ng c√≥ ƒë∆∞·ªùng k·∫ª n√†o ƒë∆∞·ª£c v·∫Ω\n",
    "   - Kh√¥ng c√≥ h·ªôp n√†o ƒë∆∞·ª£c ho√†n th√†nh\n",
    "   - Ng∆∞·ªùi ch∆°i +1 ƒëi tr∆∞·ªõc\n",
    "   \n",
    "   V√≠ d·ª•: board = {\n",
    "       'size': (4, 4),      # 4 h√†ng v√† 4 c·ªôt ƒëi·ªÉm\n",
    "       'lines': {},         # Kh√¥ng c√≥ ƒë∆∞·ªùng k·∫ª n√†o\n",
    "       'boxes': {}          # Kh√¥ng c√≥ h·ªôp n√†o\n",
    "   }\n",
    "\n",
    "2. H√ÄNH ƒê·ªòNG (Actions):\n",
    "   - V·∫Ω m·ªôt ƒë∆∞·ªùng k·∫ª ngang (horizontal) ho·∫∑c d·ªçc (vertical) gi·ªØa 2 ƒëi·ªÉm li·ªÅn k·ªÅ ch∆∞a ƒë∆∞·ª£c n·ªëi\n",
    "   - M·ªói h√†nh ƒë·ªông ƒë∆∞·ª£c bi·ªÉu di·ªÖn b·ªüi: (orientation, row, col)\n",
    "     + orientation: 'h' (ngang) ho·∫∑c 'v' (d·ªçc)\n",
    "     + row, col: t·ªça ƒë·ªô c·ªßa ƒëi·ªÉm b·∫Øt ƒë·∫ßu (b·∫Øt ƒë·∫ßu t·ª´ 0)\n",
    "   \n",
    "   V√≠ d·ª•: ('h', 0, 0) - v·∫Ω ƒë∆∞·ªùng ngang t·ª´ ƒëi·ªÉm (0,0) sang ph·∫£i\n",
    "          ('v', 0, 0) - v·∫Ω ƒë∆∞·ªùng d·ªçc t·ª´ ƒëi·ªÉm (0,0) xu·ªëng d∆∞·ªõi\n",
    "\n",
    "3. M√î H√åNH CHUY·ªÇN ƒê·ªîI (Transition Model):\n",
    "   - K·∫øt qu·∫£ c·ªßa vi·ªác v·∫Ω m·ªôt ƒë∆∞·ªùng k·∫ª:\n",
    "     a) Th√™m ƒë∆∞·ªùng k·∫ª v√†o board['lines']\n",
    "     b) Ki·ªÉm tra xem c√≥ h·ªôp n√†o ƒë∆∞·ª£c ho√†n th√†nh kh√¥ng\n",
    "        - N·∫øu c√≥: g√°n h·ªôp ƒë√≥ cho ng∆∞·ªùi ch∆°i hi·ªán t·∫°i trong board['boxes']\n",
    "                  ng∆∞·ªùi ch∆°i ƒë∆∞·ª£c ƒëi ti·∫øp\n",
    "        - N·∫øu kh√¥ng: chuy·ªÉn l∆∞·ª£t cho ng∆∞·ªùi ch∆°i kia\n",
    "   \n",
    "   - M·ªôt h·ªôp ƒë∆∞·ª£c ho√†n th√†nh khi c√≥ ƒë·ªß 4 c·∫°nh:\n",
    "     + C·∫°nh tr√™n: ('h', row, col)\n",
    "     + C·∫°nh d∆∞·ªõi: ('h', row+1, col)\n",
    "     + C·∫°nh tr√°i: ('v', row, col)\n",
    "     + C·∫°nh ph·∫£i: ('v', row, col+1)\n",
    "\n",
    "4. KI·ªÇM TRA TR·∫†NG TH√ÅI K·∫æT TH√öC (Terminal State Test):\n",
    "   - Tr√≤ ch∆°i k·∫øt th√∫c khi kh√¥ng c√≤n ƒë∆∞·ªùng k·∫ª n√†o c√≥ th·ªÉ v·∫Ω\n",
    "   - T·ªïng s·ªë ƒë∆∞·ªùng k·∫ª c√≥ th·ªÉ c√≥:\n",
    "     + ƒê∆∞·ªùng ngang: rows √ó (cols-1)\n",
    "     + ƒê∆∞·ªùng d·ªçc: (rows-1) √ó cols\n",
    "   - Terminal state: len(board['lines']) == rows*(cols-1) + (rows-1)*cols\n",
    "\n",
    "5. H√ÄM TI·ªÜN √çCH (Utility):\n",
    "   - ƒê·∫øm s·ªë h·ªôp m·ªói ng∆∞·ªùi ch∆°i ho√†n th√†nh\n",
    "   - Utility(s) = s·ªë h·ªôp c·ªßa player(+1) - s·ªë h·ªôp c·ªßa player(-1)\n",
    "   - Ng∆∞·ªùi ch∆°i c√≥ nhi·ªÅu h·ªôp h∆°n th·∫Øng\n",
    "   - V√≠ d·ª•: \n",
    "     + Player +1 c√≥ 5 h·ªôp, Player -1 c√≥ 3 h·ªôp ‚Üí Utility = +2\n",
    "     + Player +1 c√≥ 4 h·ªôp, Player -1 c√≥ 4 h·ªôp ‚Üí Utility = 0 (h√≤a)\n",
    "\"\"\"\n",
    "\n",
    "print(\"‚úì ƒê√£ ƒë·ªãnh nghƒ©a c√°c th√†nh ph·∫ßn c·ªßa b√†i to√°n t√¨m ki·∫øm cho Dots and Boxes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How big is the state space? Give an estimate and explain it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "B·∫£ng k√≠ch th∆∞·ªõc: 3 √ó 3 ƒëi·ªÉm\n",
      "S·ªë ƒë∆∞·ªùng k·∫ª: 12\n",
      "  - ƒê∆∞·ªùng ngang: 6\n",
      "  - ƒê∆∞·ªùng d·ªçc: 6\n",
      "S·ªë h·ªôp: 4\n",
      "\n",
      "Kh√¥ng gian tr·∫°ng th√°i l√Ω thuy·∫øt: 2^12 = 4,096\n",
      "\n",
      "‚ö† L∆∞u √Ω: Kh√¥ng gian tr·∫°ng th√°i TH·ª∞C T·∫æ nh·ªè h∆°n nhi·ªÅu do:\n",
      "  - Th·ª© t·ª± v·∫Ω ƒë∆∞·ªùng ·∫£nh h∆∞·ªüng ƒë·∫øn tr·∫°ng th√°i game\n",
      "  - Lu·∫≠t ƒëi ti·∫øp khi ho√†n th√†nh h·ªôp gi·∫£m s·ªë tr·∫°ng th√°i\n",
      "\n",
      "============================================================\n",
      "B·∫£ng k√≠ch th∆∞·ªõc: 4 √ó 4 ƒëi·ªÉm\n",
      "S·ªë ƒë∆∞·ªùng k·∫ª: 24\n",
      "  - ƒê∆∞·ªùng ngang: 12\n",
      "  - ƒê∆∞·ªùng d·ªçc: 12\n",
      "S·ªë h·ªôp: 9\n",
      "\n",
      "Kh√¥ng gian tr·∫°ng th√°i l√Ω thuy·∫øt: 2^24 = 16,777,216\n",
      "\n",
      "‚ö† L∆∞u √Ω: Kh√¥ng gian tr·∫°ng th√°i TH·ª∞C T·∫æ nh·ªè h∆°n nhi·ªÅu do:\n",
      "  - Th·ª© t·ª± v·∫Ω ƒë∆∞·ªùng ·∫£nh h∆∞·ªüng ƒë·∫øn tr·∫°ng th√°i game\n",
      "  - Lu·∫≠t ƒëi ti·∫øp khi ho√†n th√†nh h·ªôp gi·∫£m s·ªë tr·∫°ng th√°i\n",
      "\n",
      "============================================================\n",
      "B·∫£ng k√≠ch th∆∞·ªõc: 5 √ó 5 ƒëi·ªÉm\n",
      "S·ªë ƒë∆∞·ªùng k·∫ª: 40\n",
      "  - ƒê∆∞·ªùng ngang: 20\n",
      "  - ƒê∆∞·ªùng d·ªçc: 20\n",
      "S·ªë h·ªôp: 16\n",
      "\n",
      "Kh√¥ng gian tr·∫°ng th√°i l√Ω thuy·∫øt: 2^40 = 1,099,511,627,776\n",
      "\n",
      "‚ö† L∆∞u √Ω: Kh√¥ng gian tr·∫°ng th√°i TH·ª∞C T·∫æ nh·ªè h∆°n nhi·ªÅu do:\n",
      "  - Th·ª© t·ª± v·∫Ω ƒë∆∞·ªùng ·∫£nh h∆∞·ªüng ƒë·∫øn tr·∫°ng th√°i game\n",
      "  - Lu·∫≠t ƒëi ti·∫øp khi ho√†n th√†nh h·ªôp gi·∫£m s·ªë tr·∫°ng th√°i\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(40, 1099511627776)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ∆Ø·ªõc t√≠nh k√≠ch th∆∞·ªõc kh√¥ng gian tr·∫°ng th√°i\n",
    "\n",
    "\"\"\"\n",
    "PH√ÇN T√çCH K√çCH TH∆Ø·ªöC KH√îNG GIAN TR·∫†NG TH√ÅI:\n",
    "\n",
    "V·ªõi b·∫£ng k√≠ch th∆∞·ªõc m √ó n (m h√†ng, n c·ªôt ƒëi·ªÉm):\n",
    "- T·ªïng s·ªë ƒë∆∞·ªùng k·∫ª c√≥ th·ªÉ v·∫Ω:\n",
    "  + ƒê∆∞·ªùng ngang: m √ó (n-1)\n",
    "  + ƒê∆∞·ªùng d·ªçc: (m-1) √ó n\n",
    "  + T·ªïng: L = m(n-1) + (m-1)n = 2mn - m - n\n",
    "\n",
    "- M·ªói ƒë∆∞·ªùng k·∫ª c√≥ 2 tr·∫°ng th√°i: ƒë√£ v·∫Ω ho·∫∑c ch∆∞a v·∫Ω\n",
    "- Kh√¥ng gian tr·∫°ng th√°i l√Ω thuy·∫øt: 2^L\n",
    "\n",
    "Tuy nhi√™n, kh√¥ng ph·∫£i t·∫•t c·∫£ c√°c t·ªï h·ª£p ƒë·ªÅu h·ª£p l·ªá trong game tree v√¨:\n",
    "- Th·ª© t·ª± v·∫Ω c√°c ƒë∆∞·ªùng c√≥ ·∫£nh h∆∞·ªüng\n",
    "- Ng∆∞·ªùi ch∆°i c√≥ th·ªÉ ƒëi nhi·ªÅu n∆∞·ªõc li√™n ti·∫øp n·∫øu ho√†n th√†nh h·ªôp\n",
    "\n",
    "Do ƒë√≥, s·ªë tr·∫°ng th√°i TH·ª∞C T·∫æ trong game tree nh·ªè h∆°n nhi·ªÅu.\n",
    "\"\"\"\n",
    "\n",
    "def estimate_state_space(rows, cols):\n",
    "    \"\"\"\n",
    "    ∆Ø·ªõc t√≠nh k√≠ch th∆∞·ªõc kh√¥ng gian tr·∫°ng th√°i\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    rows, cols: int\n",
    "        S·ªë h√†ng v√† c·ªôt ƒëi·ªÉm tr√™n b·∫£ng\n",
    "    \"\"\"\n",
    "    # T·ªïng s·ªë ƒë∆∞·ªùng k·∫ª\n",
    "    total_lines = rows * (cols - 1) + (rows - 1) * cols\n",
    "    \n",
    "    # Kh√¥ng gian tr·∫°ng th√°i l√Ω thuy·∫øt (m·ªói ƒë∆∞·ªùng c√≥ 2 tr·∫°ng th√°i)\n",
    "    theoretical_states = 2 ** total_lines\n",
    "    \n",
    "    # S·ªë h·ªôp tr√™n b·∫£ng\n",
    "    num_boxes = (rows - 1) * (cols - 1)\n",
    "    \n",
    "    print(f\"B·∫£ng k√≠ch th∆∞·ªõc: {rows} √ó {cols} ƒëi·ªÉm\")\n",
    "    print(f\"S·ªë ƒë∆∞·ªùng k·∫ª: {total_lines}\")\n",
    "    print(f\"  - ƒê∆∞·ªùng ngang: {rows * (cols - 1)}\")\n",
    "    print(f\"  - ƒê∆∞·ªùng d·ªçc: {(rows - 1) * cols}\")\n",
    "    print(f\"S·ªë h·ªôp: {num_boxes}\")\n",
    "    print(f\"\\nKh√¥ng gian tr·∫°ng th√°i l√Ω thuy·∫øt: 2^{total_lines} = {theoretical_states:,}\")\n",
    "    \n",
    "    # ∆Ø·ªõc t√≠nh th·ª±c t·∫ø (d·ª±a tr√™n th·ª© t·ª± game)\n",
    "    # M·ªói tr·∫°ng th√°i trong game tree c√≥ th√™m th√¥ng tin v·ªÅ ng∆∞·ªùi ch∆°i v√† boxes\n",
    "    print(f\"\\n‚ö† L∆∞u √Ω: Kh√¥ng gian tr·∫°ng th√°i TH·ª∞C T·∫æ nh·ªè h∆°n nhi·ªÅu do:\")\n",
    "    print(f\"  - Th·ª© t·ª± v·∫Ω ƒë∆∞·ªùng ·∫£nh h∆∞·ªüng ƒë·∫øn tr·∫°ng th√°i game\")\n",
    "    print(f\"  - Lu·∫≠t ƒëi ti·∫øp khi ho√†n th√†nh h·ªôp gi·∫£m s·ªë tr·∫°ng th√°i\")\n",
    "    \n",
    "    return total_lines, theoretical_states\n",
    "\n",
    "# V√≠ d·ª• v·ªõi c√°c k√≠ch th∆∞·ªõc b·∫£ng kh√°c nhau\n",
    "print(\"=\" * 60)\n",
    "estimate_state_space(3, 3)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "estimate_state_space(4, 4)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "estimate_state_space(5, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How big is the game tree that minimax search will go through? Give an estimate and explain it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ∆Ø·ªõc t√≠nh k√≠ch th∆∞·ªõc c√¢y tr√≤ ch∆°i cho Minimax\n",
    "\n",
    "\"\"\"\n",
    "PH√ÇN T√çCH K√çCH TH∆Ø·ªöC C√ÇY TR√í CH∆†I (GAME TREE):\n",
    "\n",
    "C√¢y tr√≤ ch∆°i kh√°c v·ªõi kh√¥ng gian tr·∫°ng th√°i v√¨:\n",
    "- M·ªói node trong c√¢y ƒë·∫°i di·ªán cho m·ªôt tr·∫°ng th√°i\n",
    "- C√°c c·∫°nh ƒë·∫°i di·ªán cho c√°c n∆∞·ªõc ƒëi\n",
    "- Minimax ph·∫£i duy·ªát qua nhi·ªÅu ƒë∆∞·ªùng ƒëi kh√°c nhau ƒë·∫øn c√πng tr·∫°ng th√°i\n",
    "\n",
    "V·ªõi b·∫£ng m √ó n:\n",
    "- T·ªïng s·ªë ƒë∆∞·ªùng k·∫ª: L = 2mn - m - n\n",
    "- N∆∞·ªõc ƒëi ƒë·∫ßu ti√™n c√≥ L l·ª±a ch·ªçn\n",
    "- N∆∞·ªõc ƒëi th·ª© 2 c√≥ (L-1) l·ª±a ch·ªçn (ho·∫∑c L n·∫øu ng∆∞·ªùi ch∆°i ƒëi ti·∫øp)\n",
    "- ...\n",
    "\n",
    "Trong tr∆∞·ªùng h·ª£p X·∫§U NH·∫§T (kh√¥ng c√≥ pruning):\n",
    "- Branching factor (ƒë·ªô ph√¢n nh√°nh): b ‚âà L/2 (trung b√¨nh)\n",
    "- Depth (ƒë·ªô s√¢u): d = L (trong tr∆∞·ªùng h·ª£p kh√¥ng ho√†n th√†nh h·ªôp n√†o)\n",
    "- S·ªë node: O(b^d)\n",
    "\n",
    "Tuy nhi√™n, v·ªõi Alpha-Beta Pruning:\n",
    "- Best case: O(b^(d/2))\n",
    "- Th·ª±c t·∫ø: gi·ªØa O(b^(d/2)) v√† O(b^d)\n",
    "\n",
    "V·ªõi lu·∫≠t \"ƒëi ti·∫øp khi ho√†n th√†nh h·ªôp\":\n",
    "- ƒê·ªô s√¢u c√¢y c√≥ th·ªÉ nh·ªè h∆°n nhi·ªÅu (m·ªôt ng∆∞·ªùi c√≥ th·ªÉ ƒëi nhi·ªÅu n∆∞·ªõc li√™n ti·∫øp)\n",
    "- Branching factor gi·∫£m d·∫ßn theo ƒë·ªô s√¢u\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "\n",
    "def estimate_game_tree(rows, cols):\n",
    "    \"\"\"\n",
    "    ∆Ø·ªõc t√≠nh k√≠ch th∆∞·ªõc c√¢y tr√≤ ch∆°i cho Minimax\n",
    "    \"\"\"\n",
    "    # T·ªïng s·ªë ƒë∆∞·ªùng k·∫ª\n",
    "    L = rows * (cols - 1) + (rows - 1) * cols\n",
    "    \n",
    "    # Branching factor trung b√¨nh (gi·∫£m d·∫ßn)\n",
    "    avg_branching = L / 2\n",
    "    \n",
    "    # ƒê·ªô s√¢u t·ªëi ƒëa\n",
    "    max_depth = L\n",
    "    \n",
    "    # ∆Ø·ªõc t√≠nh s·ªë node trong c√¢y\n",
    "    # S·ª≠ d·ª•ng c√¥ng th·ª©c t·ªïng c·∫•p s·ªë nh√¢n: (b^(d+1) - 1) / (b - 1)\n",
    "    # V·ªõi b gi·∫£m d·∫ßn, ta l·∫•y ∆∞·ªõc t√≠nh ƒë∆°n gi·∫£n\n",
    "    \n",
    "    print(f\"B·∫£ng k√≠ch th∆∞·ªõc: {rows} √ó {cols} ƒëi·ªÉm\")\n",
    "    print(f\"T·ªïng s·ªë ƒë∆∞·ªùng k·∫ª (L): {L}\")\n",
    "    print(f\"Branching factor trung b√¨nh: ~{avg_branching:.1f}\")\n",
    "    print(f\"ƒê·ªô s√¢u t·ªëi ƒëa: {max_depth}\")\n",
    "    \n",
    "    # ∆Ø·ªõc t√≠nh kh√¥ng c√≥ pruning (worst case)\n",
    "    if L <= 15:  # Ch·ªâ t√≠nh n·∫øu kh√¥ng qu√° l·ªõn\n",
    "        worst_case_nodes = sum([avg_branching ** d for d in range(min(L, 10))])\n",
    "        print(f\"\\nS·ªë node ∆∞·ªõc t√≠nh (kh√¥ng pruning, 10 t·∫ßng ƒë·∫ßu): ~{worst_case_nodes:,.0f}\")\n",
    "    else:\n",
    "        print(f\"\\nS·ªë node ∆∞·ªõc t√≠nh (kh√¥ng pruning): C·ª∞C K·ª≤ L·ªöN (> 10^{L//3})\")\n",
    "    \n",
    "    # V·ªõi Alpha-Beta Pruning\n",
    "    print(f\"\\nV·ªõi Alpha-Beta Pruning:\")\n",
    "    print(f\"  - Best case: ~{avg_branching:.1f}^({max_depth}/2) = {avg_branching:.1f}^{max_depth//2}\")\n",
    "    if max_depth <= 20:\n",
    "        best_case = avg_branching ** (max_depth / 2)\n",
    "        print(f\"  - ‚âà {best_case:.2e} nodes\")\n",
    "    else:\n",
    "        print(f\"  - V·∫´n r·∫•t l·ªõn, c·∫ßn heuristic cutoff!\")\n",
    "    \n",
    "    print(f\"\\nüí° K·∫æT LU·∫¨N:\")\n",
    "    print(f\"  - V·ªõi b·∫£ng nh·ªè ({rows}√ó{cols}): C√≥ th·ªÉ d√πng Minimax v·ªõi Alpha-Beta\")\n",
    "    if L > 20:\n",
    "        print(f\"  - V·ªõi b·∫£ng l·ªõn h∆°n: C·∫¶N d√πng heuristic evaluation + depth cutoff\")\n",
    "    \n",
    "    return L, avg_branching, max_depth\n",
    "\n",
    "# V√≠ d·ª• v·ªõi c√°c k√≠ch th∆∞·ªõc b·∫£ng\n",
    "print(\"=\" * 70)\n",
    "estimate_game_tree(3, 3)\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "estimate_game_tree(4, 4)\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "estimate_game_tree(5, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Game Environment and Random Agent [30 point]\n",
    "\n",
    "You need to think about a data structure to represent the board meaning he placed lines and who finished what box. There are many options. Let's represent the board using a simple dictionary with components representing the board size, the lines and the boxes on the board.\n",
    "\n",
    "**Important:** Everybody needs to use the same representation so we can let agents play against each other later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'size': (4, 4),\n",
       " 'lines': {('h', 1, 1): True, ('v', 1, 1): True},\n",
       " 'boxes': dict}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "board = {\n",
    "    'size': (4, 4),  ### number of rows and columns of dots\n",
    "    'lines': dict(), ### keys are the set of drawn lines\n",
    "    'boxes': dict    ### keys are the boxes and the value is the player who completed each box\n",
    "}\n",
    "\n",
    "def draw_line(board, orientation, row, col):\n",
    "    \"\"\"\n",
    "    Place a line on an exiting board.\n",
    "       \n",
    "    Parameters\n",
    "    ----------\n",
    "    board: dict\n",
    "        the board\n",
    "    orientation: str\n",
    "        either 'h' or 'v' for horizontal or vertical\n",
    "    row, col: int\n",
    "        index of the starting dot for the line (starting with 0)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if orientation not in ['h', 'v']:\n",
    "        return False\n",
    "        \n",
    "    if row < 0 or col < 0:\n",
    "        return False\n",
    "        \n",
    "    if row >= board['size'][0] + (orientation == 'v') or col >= board['size'][1] + (orientation == 'h'):\n",
    "        return False\n",
    "        \n",
    "    if (orientation, row, col) in board['lines']:\n",
    "        return False\n",
    "            \n",
    "    board[\"lines\"][(orientation, row, col)] = True\n",
    "    return True\n",
    "    \n",
    "\n",
    "print(draw_line(board, \"h\", 1, 1))\n",
    "print(draw_line(board, \"v\", 1, 1))\n",
    "\n",
    "# this should not work\n",
    "print(draw_line(board, \"h\", 1, 1))\n",
    "\n",
    "board"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code to display the board. **Bonus point: Post your visualization code with an example output to the discussion board. The best visualization will earn you bonus participation points in this class.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V√≠ d·ª• b·∫£ng Dots and Boxes:\n",
      "========================================\n",
      "‚óè‚îÄ‚îÄ‚îÄ‚óè   ‚óè   ‚óè\n",
      "‚îÇ X ‚îÇ        \n",
      "‚óè‚îÄ‚îÄ‚îÄ‚óè   ‚óè   ‚óè\n",
      "             \n",
      "‚óè   ‚óè   ‚óè‚îÄ‚îÄ‚îÄ‚óè\n",
      "        ‚îÇ    \n",
      "‚óè   ‚óè   ‚óè   ‚óè\n",
      "\n",
      "Th·ªëng k√™:\n",
      "  Player X (+1): 1 boxes\n",
      "  Player O (-1): 0 boxes\n",
      "  C√≤n l·∫°i: 8 boxes\n",
      "  ƒê∆∞·ªùng k·∫ª: 6/24\n"
     ]
    }
   ],
   "source": [
    "# Visualization - Hi·ªÉn th·ªã b·∫£ng Dots and Boxes\n",
    "\n",
    "def display_board(board):\n",
    "    \"\"\"\n",
    "    Hi·ªÉn th·ªã b·∫£ng Dots and Boxes d∆∞·ªõi d·∫°ng ASCII art\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    board: dict\n",
    "        Board state v·ªõi 'size', 'lines', 'boxes'\n",
    "    \"\"\"\n",
    "    rows, cols = board['size']\n",
    "    lines = board.get('lines', {})\n",
    "    boxes = board.get('boxes', {})\n",
    "    \n",
    "    # T·∫°o output\n",
    "    output = []\n",
    "    \n",
    "    # Duy·ªát qua t·ª´ng h√†ng\n",
    "    for r in range(rows):\n",
    "        # Hi·ªÉn th·ªã h√†ng c√°c ƒëi·ªÉm v√† ƒë∆∞·ªùng ngang\n",
    "        row_str = \"\"\n",
    "        for c in range(cols):\n",
    "            # ƒêi·ªÉm\n",
    "            row_str += \"‚óè\"\n",
    "            \n",
    "            # ƒê∆∞·ªùng ngang (n·∫øu kh√¥ng ph·∫£i c·ªôt cu·ªëi)\n",
    "            if c < cols - 1:\n",
    "                if ('h', r, c) in lines:\n",
    "                    row_str += \"‚îÄ‚îÄ‚îÄ\"\n",
    "                else:\n",
    "                    row_str += \"   \"\n",
    "        \n",
    "        output.append(row_str)\n",
    "        \n",
    "        # Hi·ªÉn th·ªã ƒë∆∞·ªùng d·ªçc v√† boxes (n·∫øu kh√¥ng ph·∫£i h√†ng cu·ªëi)\n",
    "        if r < rows - 1:\n",
    "            row_str = \"\"\n",
    "            for c in range(cols):\n",
    "                # ƒê∆∞·ªùng d·ªçc\n",
    "                if ('v', r, c) in lines:\n",
    "                    row_str += \"‚îÇ\"\n",
    "                else:\n",
    "                    row_str += \" \"\n",
    "                \n",
    "                # N·ªôi dung box (n·∫øu kh√¥ng ph·∫£i c·ªôt cu·ªëi)\n",
    "                if c < cols - 1:\n",
    "                    if (r, c) in boxes:\n",
    "                        # Hi·ªÉn th·ªã ng∆∞·ªùi ch∆°i s·ªü h·ªØu box\n",
    "                        player = boxes[(r, c)]\n",
    "                        if player == 1:\n",
    "                            row_str += \" X \"\n",
    "                        else:\n",
    "                            row_str += \" O \"\n",
    "                    else:\n",
    "                        row_str += \"   \"\n",
    "            \n",
    "            output.append(row_str)\n",
    "    \n",
    "    # In ra m√†n h√¨nh\n",
    "    print(\"\\n\".join(output))\n",
    "    \n",
    "    # Th·ªëng k√™\n",
    "    player1_boxes = sum(1 for p in boxes.values() if p == 1)\n",
    "    player2_boxes = sum(1 for p in boxes.values() if p == -1)\n",
    "    total_boxes = (rows - 1) * (cols - 1)\n",
    "    \n",
    "    print(f\"\\nTh·ªëng k√™:\")\n",
    "    print(f\"  Player X (+1): {player1_boxes} boxes\")\n",
    "    print(f\"  Player O (-1): {player2_boxes} boxes\")\n",
    "    print(f\"  C√≤n l·∫°i: {total_boxes - player1_boxes - player2_boxes} boxes\")\n",
    "    print(f\"  ƒê∆∞·ªùng k·∫ª: {len(lines)}/{rows*(cols-1) + (rows-1)*cols}\")\n",
    "\n",
    "# Test visualization\n",
    "import copy\n",
    "\n",
    "# T·∫°o board m·∫´u\n",
    "test_board = {\n",
    "    'size': (4, 4),\n",
    "    'lines': {},\n",
    "    'boxes': {}\n",
    "}\n",
    "\n",
    "# V·∫Ω m·ªôt s·ªë ƒë∆∞·ªùng\n",
    "draw_line(test_board, 'h', 0, 0)\n",
    "draw_line(test_board, 'h', 1, 0)\n",
    "draw_line(test_board, 'v', 0, 0)\n",
    "draw_line(test_board, 'v', 0, 1)\n",
    "test_board['boxes'][(0, 0)] = 1  # Player 1 ho√†n th√†nh box (0,0)\n",
    "\n",
    "draw_line(test_board, 'h', 2, 2)\n",
    "draw_line(test_board, 'v', 2, 2)\n",
    "\n",
    "print(\"V√≠ d·ª• b·∫£ng Dots and Boxes:\")\n",
    "print(\"=\" * 40)\n",
    "display_board(test_board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement helper functions for:\n",
    "\n",
    "* The transition model $result(s, a)$.\n",
    "* The utility function $utility(s)$.\n",
    "* Check for terminal states $terminal(s)$.\n",
    "* A check for available actions in each state $actions(s)$.\n",
    "\n",
    "__Notes:__\n",
    "* Make sure that all these functions work with boards of different sizes (number of columns and rows as stored in the board).\n",
    "* The result function updates the board and evaluates if the player closed a box and needs to store that information on the board. Add elements of the form `(row,col): player` to the board dictionary. `row` and `col` are the coordinates for the box and `player` is +1 or -1 representing the player. For example `(0,0): -1` means that the top-left box belongs to the other player. \n",
    "* _Important:_ Remember that a player goes again after she completes a box!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test helper functions:\n",
      "============================================================\n",
      "1. Board ban ƒë·∫ßu:\n",
      "‚óè   ‚óè   ‚óè\n",
      "         \n",
      "‚óè   ‚óè   ‚óè\n",
      "         \n",
      "‚óè   ‚óè   ‚óè\n",
      "\n",
      "Th·ªëng k√™:\n",
      "  Player X (+1): 0 boxes\n",
      "  Player O (-1): 0 boxes\n",
      "  C√≤n l·∫°i: 4 boxes\n",
      "  ƒê∆∞·ªùng k·∫ª: 0/12\n",
      "\n",
      "2. Available actions: 12 actions\n",
      "   V√≠ d·ª• 5 action ƒë·∫ßu: [('h', 0, 0), ('h', 0, 1), ('h', 1, 0), ('h', 1, 1), ('h', 2, 0)]\n",
      "\n",
      "3. Test result function:\n",
      "   V·∫Ω ƒë∆∞·ªùng ('h', 0, 0) b·ªüi player +1\n",
      "‚óè‚îÄ‚îÄ‚îÄ‚óè   ‚óè\n",
      "         \n",
      "‚óè   ‚óè   ‚óè\n",
      "         \n",
      "‚óè   ‚óè   ‚óè\n",
      "\n",
      "Th·ªëng k√™:\n",
      "  Player X (+1): 0 boxes\n",
      "  Player O (-1): 0 boxes\n",
      "  C√≤n l·∫°i: 4 boxes\n",
      "  ƒê∆∞·ªùng k·∫ª: 1/12\n",
      "   Next player: -1\n",
      "\n",
      "4. Test ho√†n th√†nh box:\n",
      "   Board tr∆∞·ªõc khi ho√†n th√†nh box:\n",
      "‚óè‚îÄ‚îÄ‚îÄ‚óè   ‚óè\n",
      "‚îÇ        \n",
      "‚óè‚îÄ‚îÄ‚îÄ‚óè   ‚óè\n",
      "         \n",
      "‚óè   ‚óè   ‚óè\n",
      "\n",
      "Th·ªëng k√™:\n",
      "  Player X (+1): 0 boxes\n",
      "  Player O (-1): 0 boxes\n",
      "  C√≤n l·∫°i: 4 boxes\n",
      "  ƒê∆∞·ªùng k·∫ª: 3/12\n",
      "\n",
      "   V·∫Ω ƒë∆∞·ªùng ('v', 0, 1) ƒë·ªÉ ho√†n th√†nh box:\n",
      "‚óè‚îÄ‚îÄ‚îÄ‚óè   ‚óè\n",
      "‚îÇ X ‚îÇ    \n",
      "‚óè‚îÄ‚îÄ‚îÄ‚óè   ‚óè\n",
      "         \n",
      "‚óè   ‚óè   ‚óè\n",
      "\n",
      "Th·ªëng k√™:\n",
      "  Player X (+1): 1 boxes\n",
      "  Player O (-1): 0 boxes\n",
      "  C√≤n l·∫°i: 3 boxes\n",
      "  ƒê∆∞·ªùng k·∫ª: 4/12\n",
      "   Next player: 1 (player 1 ƒëi ti·∫øp!)\n",
      "\n",
      "5. Terminal test: False\n",
      "6. Utility test: 1\n"
     ]
    }
   ],
   "source": [
    "# Implement helper functions\n",
    "\n",
    "import copy\n",
    "\n",
    "def actions(board):\n",
    "    \"\"\"\n",
    "    Tr·∫£ v·ªÅ danh s√°ch c√°c h√†nh ƒë·ªông h·ª£p l·ªá (c√°c ƒë∆∞·ªùng k·∫ª c√≥ th·ªÉ v·∫Ω)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    board: dict\n",
    "        Board state hi·ªán t·∫°i\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    list: Danh s√°ch c√°c action d∆∞·ªõi d·∫°ng (orientation, row, col)\n",
    "    \"\"\"\n",
    "    rows, cols = board['size']\n",
    "    lines = board['lines']\n",
    "    available_actions = []\n",
    "    \n",
    "    # T√¨m t·∫•t c·∫£ ƒë∆∞·ªùng ngang c√≥ th·ªÉ v·∫Ω\n",
    "    for r in range(rows):\n",
    "        for c in range(cols - 1):\n",
    "            if ('h', r, c) not in lines:\n",
    "                available_actions.append(('h', r, c))\n",
    "    \n",
    "    # T√¨m t·∫•t c·∫£ ƒë∆∞·ªùng d·ªçc c√≥ th·ªÉ v·∫Ω\n",
    "    for r in range(rows - 1):\n",
    "        for c in range(cols):\n",
    "            if ('v', r, c) not in lines:\n",
    "                available_actions.append(('v', r, c))\n",
    "    \n",
    "    return available_actions\n",
    "\n",
    "\n",
    "def check_box_completion(board, row, col):\n",
    "    \"\"\"\n",
    "    Ki·ªÉm tra xem box t·∫°i (row, col) c√≥ ho√†n th√†nh kh√¥ng\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    board: dict\n",
    "        Board state\n",
    "    row, col: int\n",
    "        T·ªça ƒë·ªô c·ªßa box (g√≥c tr√™n tr√°i)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    bool: True n·∫øu box ho√†n th√†nh\n",
    "    \"\"\"\n",
    "    lines = board['lines']\n",
    "    \n",
    "    # Ki·ªÉm tra 4 c·∫°nh c·ªßa box\n",
    "    top = ('h', row, col) in lines\n",
    "    bottom = ('h', row + 1, col) in lines\n",
    "    left = ('v', row, col) in lines\n",
    "    right = ('v', row, col + 1) in lines\n",
    "    \n",
    "    return top and bottom and left and right\n",
    "\n",
    "\n",
    "def result(board, action, player):\n",
    "    \"\"\"\n",
    "    Transition model: Tr·∫£ v·ªÅ board m·ªõi sau khi th·ª±c hi·ªán action\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    board: dict\n",
    "        Board state hi·ªán t·∫°i\n",
    "    action: tuple\n",
    "        H√†nh ƒë·ªông (orientation, row, col)\n",
    "    player: int\n",
    "        Ng∆∞·ªùi ch∆°i hi·ªán t·∫°i (+1 ho·∫∑c -1)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple: (new_board, next_player)\n",
    "        - new_board: Board state m·ªõi\n",
    "        - next_player: Ng∆∞·ªùi ch∆°i ti·∫øp theo (c√≥ th·ªÉ l√† player n·∫øu ho√†n th√†nh box)\n",
    "    \"\"\"\n",
    "    # T·∫°o b·∫£n sao board\n",
    "    new_board = copy.deepcopy(board)\n",
    "    \n",
    "    # V·∫Ω ƒë∆∞·ªùng k·∫ª\n",
    "    orientation, row, col = action\n",
    "    new_board['lines'][action] = True\n",
    "    \n",
    "    # Ki·ªÉm tra xem c√≥ box n√†o ƒë∆∞·ª£c ho√†n th√†nh kh√¥ng\n",
    "    rows, cols = board['size']\n",
    "    boxes_completed = []\n",
    "    \n",
    "    # Ki·ªÉm tra c√°c box c√≥ th·ªÉ b·ªã ·∫£nh h∆∞·ªüng b·ªüi ƒë∆∞·ªùng k·∫ª m·ªõi\n",
    "    if orientation == 'h':\n",
    "        # ƒê∆∞·ªùng ngang c√≥ th·ªÉ ho√†n th√†nh box ph√≠a tr√™n ho·∫∑c ph√≠a d∆∞·ªõi\n",
    "        if row > 0 and check_box_completion(new_board, row - 1, col):\n",
    "            if (row - 1, col) not in new_board['boxes']:\n",
    "                boxes_completed.append((row - 1, col))\n",
    "        if row < rows - 1 and check_box_completion(new_board, row, col):\n",
    "            if (row, col) not in new_board['boxes']:\n",
    "                boxes_completed.append((row, col))\n",
    "    else:  # orientation == 'v'\n",
    "        # ƒê∆∞·ªùng d·ªçc c√≥ th·ªÉ ho√†n th√†nh box b√™n tr√°i ho·∫∑c b√™n ph·∫£i\n",
    "        if col > 0 and check_box_completion(new_board, row, col - 1):\n",
    "            if (row, col - 1) not in new_board['boxes']:\n",
    "                boxes_completed.append((row, col - 1))\n",
    "        if col < cols - 1 and check_box_completion(new_board, row, col):\n",
    "            if (row, col) not in new_board['boxes']:\n",
    "                boxes_completed.append((row, col))\n",
    "    \n",
    "    # G√°n c√°c box ho√†n th√†nh cho player\n",
    "    for box in boxes_completed:\n",
    "        new_board['boxes'][box] = player\n",
    "    \n",
    "    # N·∫øu ho√†n th√†nh box, player ƒëi ti·∫øp; n·∫øu kh√¥ng, chuy·ªÉn l∆∞·ª£t\n",
    "    next_player = player if boxes_completed else -player\n",
    "    \n",
    "    return new_board, next_player\n",
    "\n",
    "\n",
    "def terminal(board):\n",
    "    \"\"\"\n",
    "    Ki·ªÉm tra xem board c√≥ ·ªü tr·∫°ng th√°i k·∫øt th√∫c kh√¥ng\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    board: dict\n",
    "        Board state\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    bool: True n·∫øu kh√¥ng c√≤n ƒë∆∞·ªùng k·∫ª n√†o c√≥ th·ªÉ v·∫Ω\n",
    "    \"\"\"\n",
    "    rows, cols = board['size']\n",
    "    total_lines = rows * (cols - 1) + (rows - 1) * cols\n",
    "    return len(board['lines']) == total_lines\n",
    "\n",
    "\n",
    "def utility(board, player):\n",
    "    \"\"\"\n",
    "    H√†m ti·ªán √≠ch: T√≠nh ƒëi·ªÉm cho player\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    board: dict\n",
    "        Board state (terminal state)\n",
    "    player: int\n",
    "        Ng∆∞·ªùi ch∆°i c·∫ßn t√≠nh ƒëi·ªÉm (+1 ho·∫∑c -1)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    int: ƒêi·ªÉm s·ªë\n",
    "        > 0 n·∫øu player th·∫Øng\n",
    "        = 0 n·∫øu h√≤a\n",
    "        < 0 n·∫øu player thua\n",
    "    \"\"\"\n",
    "    boxes = board['boxes']\n",
    "    player_boxes = sum(1 for p in boxes.values() if p == player)\n",
    "    opponent_boxes = sum(1 for p in boxes.values() if p == -player)\n",
    "    \n",
    "    return player_boxes - opponent_boxes\n",
    "\n",
    "\n",
    "# Test c√°c functions\n",
    "print(\"Test helper functions:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "test_board = {\n",
    "    'size': (3, 3),\n",
    "    'lines': {},\n",
    "    'boxes': {}\n",
    "}\n",
    "\n",
    "print(\"1. Board ban ƒë·∫ßu:\")\n",
    "display_board(test_board)\n",
    "\n",
    "print(\"\\n2. Available actions:\", len(actions(test_board)), \"actions\")\n",
    "print(\"   V√≠ d·ª• 5 action ƒë·∫ßu:\", actions(test_board)[:5])\n",
    "\n",
    "print(\"\\n3. Test result function:\")\n",
    "print(\"   V·∫Ω ƒë∆∞·ªùng ('h', 0, 0) b·ªüi player +1\")\n",
    "new_board, next_player = result(test_board, ('h', 0, 0), 1)\n",
    "display_board(new_board)\n",
    "print(f\"   Next player: {next_player}\")\n",
    "\n",
    "print(\"\\n4. Test ho√†n th√†nh box:\")\n",
    "# T·∫°o board g·∫ßn ho√†n th√†nh 1 box\n",
    "test_board2 = {\n",
    "    'size': (3, 3),\n",
    "    'lines': {\n",
    "        ('h', 0, 0): True,\n",
    "        ('h', 1, 0): True,\n",
    "        ('v', 0, 0): True\n",
    "    },\n",
    "    'boxes': {}\n",
    "}\n",
    "print(\"   Board tr∆∞·ªõc khi ho√†n th√†nh box:\")\n",
    "display_board(test_board2)\n",
    "print(\"\\n   V·∫Ω ƒë∆∞·ªùng ('v', 0, 1) ƒë·ªÉ ho√†n th√†nh box:\")\n",
    "new_board2, next_player2 = result(test_board2, ('v', 0, 1), 1)\n",
    "display_board(new_board2)\n",
    "print(f\"   Next player: {next_player2} (player 1 ƒëi ti·∫øp!)\")\n",
    "\n",
    "print(\"\\n5. Terminal test:\", terminal(test_board2))\n",
    "print(\"6. Utility test:\", utility(new_board2, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement an agent that plays randomly. Make sure the agent function receives as the percept the board and returns a valid action. Use an agent function definition with the following signature (arguments):\n",
    "\n",
    "`def random_player(board, player = None): ...`\n",
    "\n",
    "The argument `player` is used for agents that do not store what side they are playing. The value passed on by the environment should be 1 ot -1 for playerred and yellow, respectively.  See [Experiments section for tic-tac-toe](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_and_or_tree_search.ipynb#Experiments) for an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Player Agent\n",
    "\n",
    "import random\n",
    "\n",
    "def random_player(board, player=None):\n",
    "    \"\"\"\n",
    "    Agent ch∆°i ng·∫´u nhi√™n - ch·ªçn m·ªôt ƒë∆∞·ªùng k·∫ª h·ª£p l·ªá ng·∫´u nhi√™n\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    board: dict\n",
    "        Board state hi·ªán t·∫°i\n",
    "    player: int\n",
    "        Ng∆∞·ªùi ch∆°i (+1 ho·∫∑c -1), kh√¥ng s·ª≠ d·ª•ng cho random player\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple: Action ƒë∆∞·ª£c ch·ªçn (orientation, row, col)\n",
    "    \"\"\"\n",
    "    available_actions = actions(board)\n",
    "    \n",
    "    if not available_actions:\n",
    "        return None\n",
    "    \n",
    "    return random.choice(available_actions)\n",
    "\n",
    "\n",
    "# Test random player\n",
    "print(\"Test Random Player:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "test_board = {\n",
    "    'size': (3, 3),\n",
    "    'lines': {},\n",
    "    'boxes': {}\n",
    "}\n",
    "\n",
    "print(\"Board ban ƒë·∫ßu:\")\n",
    "display_board(test_board)\n",
    "\n",
    "print(\"\\n5 n∆∞·ªõc ƒëi ng·∫´u nhi√™n:\")\n",
    "for i in range(5):\n",
    "    action = random_player(test_board, 1)\n",
    "    print(f\"  {i+1}. Random action: {action}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let two random agents play against each other 1000 times. Look at the [Experiments section for tic-tac-toe](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_and_or_tree_search.ipynb#Experiments) to see how the environment uses the agent functions to play against each other.\n",
    "\n",
    "How often does each player win? Is the result expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cho 2 random agents ch∆°i v·ªõi nhau 1000 l·∫ßn\n",
    "\n",
    "def play_game(player1_func, player2_func, board_size=(3, 3), verbose=False):\n",
    "    \"\"\"\n",
    "    Ch∆°i m·ªôt game gi·ªØa 2 agents\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    player1_func, player2_func: function\n",
    "        C√°c h√†m agent\n",
    "    board_size: tuple\n",
    "        K√≠ch th∆∞·ªõc board\n",
    "    verbose: bool\n",
    "        In ra qu√° tr√¨nh ch∆°i\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    int: K·∫øt qu·∫£\n",
    "        1 n·∫øu player 1 th·∫Øng\n",
    "        -1 n·∫øu player 2 th·∫Øng\n",
    "        0 n·∫øu h√≤a\n",
    "    \"\"\"\n",
    "    # Kh·ªüi t·∫°o board\n",
    "    board = {\n",
    "        'size': board_size,\n",
    "        'lines': {},\n",
    "        'boxes': {}\n",
    "    }\n",
    "    \n",
    "    current_player = 1\n",
    "    move_count = 0\n",
    "    \n",
    "    while not terminal(board):\n",
    "        # Ch·ªçn agent function\n",
    "        if current_player == 1:\n",
    "            action = player1_func(board, current_player)\n",
    "        else:\n",
    "            action = player2_func(board, current_player)\n",
    "        \n",
    "        if action is None:\n",
    "            break\n",
    "        \n",
    "        # Th·ª±c hi·ªán action\n",
    "        board, next_player = result(board, action, current_player)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\nMove {move_count + 1}: Player {current_player} draws {action}\")\n",
    "            display_board(board)\n",
    "        \n",
    "        current_player = next_player\n",
    "        move_count += 1\n",
    "    \n",
    "    # T√≠nh k·∫øt qu·∫£\n",
    "    player1_boxes = sum(1 for p in board['boxes'].values() if p == 1)\n",
    "    player2_boxes = sum(1 for p in board['boxes'].values() if p == -1)\n",
    "    \n",
    "    if player1_boxes > player2_boxes:\n",
    "        return 1\n",
    "    elif player2_boxes > player1_boxes:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# Ch∆°i 1000 games\n",
    "print(\"Ch∆°i 1000 games gi·ªØa 2 Random Players:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "results = {\n",
    "    'player1_wins': 0,\n",
    "    'player2_wins': 0,\n",
    "    'draws': 0\n",
    "}\n",
    "\n",
    "num_games = 1000\n",
    "\n",
    "for i in range(num_games):\n",
    "    result_game = play_game(random_player, random_player, board_size=(3, 3))\n",
    "    \n",
    "    if result_game == 1:\n",
    "        results['player1_wins'] += 1\n",
    "    elif result_game == -1:\n",
    "        results['player2_wins'] += 1\n",
    "    else:\n",
    "        results['draws'] += 1\n",
    "    \n",
    "    # Progress bar\n",
    "    if (i + 1) % 100 == 0:\n",
    "        print(f\"ƒê√£ ch∆°i {i + 1}/{num_games} games...\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"K·∫æT QU·∫¢:\")\n",
    "print(f\"  Player 1 (ƒëi tr∆∞·ªõc) th·∫Øng: {results['player1_wins']} games ({results['player1_wins']/num_games*100:.1f}%)\")\n",
    "print(f\"  Player 2 (ƒëi sau) th·∫Øng:  {results['player2_wins']} games ({results['player2_wins']/num_games*100:.1f}%)\")\n",
    "print(f\"  H√≤a:                       {results['draws']} games ({results['draws']/num_games*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PH√ÇN T√çCH:\")\n",
    "print(\"\"\"\n",
    "K·∫æT QU·∫¢ MONG ƒê·ª¢I:\n",
    "- V·ªõi 2 random players, kh√¥ng c√≥ chi·∫øn thu·∫≠t c·ª• th·ªÉ\n",
    "- Player ƒëi tr∆∞·ªõc (Player 1) c√≥ xu h∆∞·ªõng th·∫Øng nhi·ªÅu h∆°n m·ªôt ch√∫t do:\n",
    "  + C√≥ c∆° h·ªôi v·∫Ω ƒë∆∞·ªùng ƒë·∫ßu ti√™n\n",
    "  + Trong tr√≤ ch∆°i ng·∫´u nhi√™n, vi·ªác ƒëi tr∆∞·ªõc t·∫°o l·ª£i th·∫ø nh·ªè\n",
    "  \n",
    "- T·ª∑ l·ªá h√≤a th∆∞·ªùng r·∫•t th·∫•p trong Dots and Boxes v√¨ s·ªë box th∆∞·ªùng l·∫ª\n",
    "  (v·ªõi board 3x3 c√≥ 4 boxes, v·ªõi board 4x4 c√≥ 9 boxes)\n",
    "  \n",
    "- K·∫øt qu·∫£ c√≥ th·ªÉ dao ƒë·ªông do t√≠nh ng·∫´u nhi√™n, nh∆∞ng nh√¨n chung:\n",
    "  + Player 1 th·∫Øng: ~52-55%\n",
    "  + Player 2 th·∫Øng: ~45-48%\n",
    "  + H√≤a: ~0-3% (v·ªõi board 3x3 c√≥ 4 boxes n√™n h√≤a l√† 2-2)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Minimax Search with Alpha-Beta Pruning [30 points]\n",
    "\n",
    "### Implement the search starting.\n",
    "\n",
    "Implement the search starting from a given board and specifying the player and put it into an agent function.\n",
    "You can use code from the [tic-tac-toe example](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_alpha_beta_tree_search.ipynb).\n",
    "\n",
    "__Notes:__ \n",
    "* Make sure that all your agent functions have a signature consistent with the random agent above.\n",
    "* The search space for larger board may be too large. You can experiment with smaller boards.\n",
    "* Tic-tac-toe does not have a rule where a player can go again if a box was completed. You need to adapt the tree search to reflect that rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimax Search with Alpha-Beta Pruning\n",
    "\n",
    "import math\n",
    "import time\n",
    "\n",
    "# Bi·∫øn global ƒë·ªÉ ƒë·∫øm s·ªë nodes\n",
    "nodes_explored = 0\n",
    "\n",
    "def minimax_alpha_beta(board, player, alpha=-math.inf, beta=math.inf, maximizing=True):\n",
    "    \"\"\"\n",
    "    Minimax search v·ªõi Alpha-Beta Pruning\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    board: dict\n",
    "        Board state hi·ªán t·∫°i\n",
    "    player: int\n",
    "        Ng∆∞·ªùi ch∆°i ƒëang c·∫ßn t√¨m n∆∞·ªõc ƒëi (+1 ho·∫∑c -1)\n",
    "    alpha, beta: float\n",
    "        C√°c gi√° tr·ªã cho alpha-beta pruning\n",
    "    maximizing: bool\n",
    "        True n·∫øu ƒëang maximize, False n·∫øu ƒëang minimize\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple: (best_value, best_action)\n",
    "    \"\"\"\n",
    "    global nodes_explored\n",
    "    nodes_explored += 1\n",
    "    \n",
    "    # Ki·ªÉm tra terminal state\n",
    "    if terminal(board):\n",
    "        return utility(board, player), None\n",
    "    \n",
    "    available_actions = actions(board)\n",
    "    \n",
    "    if not available_actions:\n",
    "        return utility(board, player), None\n",
    "    \n",
    "    best_action = None\n",
    "    \n",
    "    if maximizing:\n",
    "        best_value = -math.inf\n",
    "        \n",
    "        for action in available_actions:\n",
    "            # Th·ª±c hi·ªán action\n",
    "            new_board, next_player = result(board, action, player)\n",
    "            \n",
    "            # Quan tr·ªçng: Ki·ªÉm tra xem c√≥ ph·∫£i c√πng player ƒëi ti·∫øp kh√¥ng\n",
    "            # N·∫øu player ho√†n th√†nh box, player ƒë√≥ ƒëi ti·∫øp (v·∫´n maximize)\n",
    "            # N·∫øu kh√¥ng, chuy·ªÉn sang opponent (minimize)\n",
    "            if next_player == player:\n",
    "                # Player ƒëi ti·∫øp (ƒë√£ ho√†n th√†nh box)\n",
    "                value, _ = minimax_alpha_beta(new_board, player, alpha, beta, True)\n",
    "            else:\n",
    "                # Chuy·ªÉn sang opponent\n",
    "                value, _ = minimax_alpha_beta(new_board, player, alpha, beta, False)\n",
    "            \n",
    "            if value > best_value:\n",
    "                best_value = value\n",
    "                best_action = action\n",
    "            \n",
    "            alpha = max(alpha, best_value)\n",
    "            \n",
    "            # Alpha-Beta Pruning\n",
    "            if beta <= alpha:\n",
    "                break\n",
    "        \n",
    "        return best_value, best_action\n",
    "    \n",
    "    else:  # minimizing\n",
    "        best_value = math.inf\n",
    "        opponent = -player\n",
    "        \n",
    "        for action in available_actions:\n",
    "            # Th·ª±c hi·ªán action\n",
    "            new_board, next_player = result(board, action, opponent)\n",
    "            \n",
    "            # Ki·ªÉm tra xem opponent c√≥ ƒëi ti·∫øp kh√¥ng\n",
    "            if next_player == opponent:\n",
    "                # Opponent ƒëi ti·∫øp (v·∫´n minimize)\n",
    "                value, _ = minimax_alpha_beta(new_board, player, alpha, beta, False)\n",
    "            else:\n",
    "                # Chuy·ªÉn l·∫°i cho player (maximize)\n",
    "                value, _ = minimax_alpha_beta(new_board, player, alpha, beta, True)\n",
    "            \n",
    "            if value < best_value:\n",
    "                best_value = value\n",
    "                best_action = action\n",
    "            \n",
    "            beta = min(beta, best_value)\n",
    "            \n",
    "            # Alpha-Beta Pruning\n",
    "            if beta <= alpha:\n",
    "                break\n",
    "        \n",
    "        return best_value, best_action\n",
    "\n",
    "\n",
    "def minimax_player(board, player=None):\n",
    "    \"\"\"\n",
    "    Agent s·ª≠ d·ª•ng Minimax with Alpha-Beta Pruning\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    board: dict\n",
    "        Board state hi·ªán t·∫°i\n",
    "    player: int\n",
    "        Ng∆∞·ªùi ch∆°i hi·ªán t·∫°i (+1 ho·∫∑c -1)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple: Action t·ªët nh·∫•t\n",
    "    \"\"\"\n",
    "    global nodes_explored\n",
    "    nodes_explored = 0\n",
    "    \n",
    "    start_time = time.time()\n",
    "    value, action = minimax_alpha_beta(board, player)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"Minimax: explored {nodes_explored} nodes in {elapsed_time:.3f}s, value={value}\")\n",
    "    \n",
    "    return action\n",
    "\n",
    "\n",
    "# Test Minimax player\n",
    "print(\"Test Minimax Player v·ªõi board nh·ªè:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# T·∫°o board g·∫ßn k·∫øt th√∫c\n",
    "test_board = {\n",
    "    'size': (3, 3),\n",
    "    'lines': {\n",
    "        ('h', 0, 0): True,\n",
    "        ('h', 1, 0): True,\n",
    "        ('v', 0, 0): True,\n",
    "        ('h', 0, 1): True,\n",
    "        ('v', 1, 1): True,\n",
    "    },\n",
    "    'boxes': {}\n",
    "}\n",
    "\n",
    "print(\"Board test:\")\n",
    "display_board(test_board)\n",
    "\n",
    "print(\"\\n\\nT√¨m n∆∞·ªõc ƒëi t·ªët nh·∫•t cho Player +1:\")\n",
    "action = minimax_player(test_board, 1)\n",
    "print(f\"Best action: {action}\")\n",
    "\n",
    "if action:\n",
    "    new_board, next_player = result(test_board, action, 1)\n",
    "    print(\"\\nBoard sau khi ƒëi:\")\n",
    "    display_board(new_board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with some manually created boards (at least 3) to check if the agent spots winning opportunities. Discuss the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Th·ª≠ nghi·ªám v·ªõi c√°c board ƒë∆∞·ª£c t·∫°o th·ªß c√¥ng\n",
    "\n",
    "print(\"TH·ª∞C NGHI·ªÜM: Ki·ªÉm tra Minimax agent v·ªõi c√°c t√¨nh hu·ªëng\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Test Case 1: C∆° h·ªôi ho√†n th√†nh box ngay l·∫≠p t·ª©c\n",
    "print(\"\\n1. TEST CASE 1: C√≥ c∆° h·ªôi ho√†n th√†nh box ngay l·∫≠p t·ª©c\")\n",
    "print(\"-\" * 70)\n",
    "test1 = {\n",
    "    'size': (3, 3),\n",
    "    'lines': {\n",
    "        ('h', 0, 0): True,\n",
    "        ('h', 1, 0): True,\n",
    "        ('v', 0, 0): True,\n",
    "        # Thi·∫øu ('v', 0, 1) ƒë·ªÉ ho√†n th√†nh box (0, 0)\n",
    "    },\n",
    "    'boxes': {}\n",
    "}\n",
    "print(\"Board:\")\n",
    "display_board(test1)\n",
    "print(\"\\nN∆∞·ªõc ƒëi c·ªßa Minimax Player +1:\")\n",
    "action1 = minimax_player(test1, 1)\n",
    "print(f\"Action: {action1}\")\n",
    "print(\"K·ª≥ v·ªçng: Minimax n√™n ch·ªçn ('v', 0, 1) ƒë·ªÉ ho√†n th√†nh box\")\n",
    "print(\"‚úì ƒê√öNG\" if action1 == ('v', 0, 1) else \"‚úó SAI\")\n",
    "\n",
    "# Test Case 2: Tr√°nh t·∫°o c∆° h·ªôi cho ƒë·ªëi th·ªß\n",
    "print(\"\\n\\n2. TEST CASE 2: Tr√°nh t·∫°o c∆° h·ªôi cho ƒë·ªëi th·ªß\")\n",
    "print(\"-\" * 70)\n",
    "test2 = {\n",
    "    'size': (3, 3),\n",
    "    'lines': {\n",
    "        ('h', 0, 0): True,\n",
    "        ('h', 1, 0): True,\n",
    "        ('v', 0, 0): True,\n",
    "        # N·∫øu v·∫Ω ('v', 0, 1), ho√†n th√†nh box nh∆∞ng cho opponent nhi·ªÅu c∆° h·ªôi\n",
    "    },\n",
    "    'boxes': {}\n",
    "}\n",
    "print(\"Board:\")\n",
    "display_board(test2)\n",
    "print(\"\\nN∆∞·ªõc ƒëi c·ªßa Minimax Player +1 (v·ªõi ƒë·ªô s√¢u gi·ªõi h·∫°n):\")\n",
    "action2 = minimax_player(test2, 1)\n",
    "print(f\"Action: {action2}\")\n",
    "print(\"Ph√¢n t√≠ch: Minimax c√¢n nh·∫Øc gi·ªØa ho√†n th√†nh box ngay v√† chi·∫øn thu·∫≠t d√†i h·∫°n\")\n",
    "\n",
    "# Test Case 3: T√¨nh hu·ªëng endgame\n",
    "print(\"\\n\\n3. TEST CASE 3: Endgame - ch·ªâ c√≤n v√†i n∆∞·ªõc ƒëi\")\n",
    "print(\"-\" * 70)\n",
    "test3 = {\n",
    "    'size': (3, 3),\n",
    "    'lines': {\n",
    "        ('h', 0, 0): True, ('h', 0, 1): True,\n",
    "        ('h', 1, 0): True, ('h', 1, 1): True,\n",
    "        ('h', 2, 0): True, ('h', 2, 1): True,\n",
    "        ('v', 0, 0): True, ('v', 0, 1): True, ('v', 0, 2): True,\n",
    "        ('v', 1, 0): True, ('v', 1, 2): True,\n",
    "        # Thi·∫øu ('v', 1, 1) - s·∫Ω ho√†n th√†nh 2 boxes\n",
    "    },\n",
    "    'boxes': {\n",
    "        (0, 0): 1,\n",
    "        (0, 1): -1,\n",
    "    }\n",
    "}\n",
    "print(\"Board:\")\n",
    "display_board(test3)\n",
    "print(f\"\\nTr·∫°ng th√°i: Player +1 c√≥ 1 box, Player -1 c√≥ 1 box\")\n",
    "print(\"\\nN∆∞·ªõc ƒëi c·ªßa Minimax Player +1:\")\n",
    "action3 = minimax_player(test3, 1)\n",
    "print(f\"Action: {action3}\")\n",
    "new_board3, _ = result(test3, action3, 1)\n",
    "print(\"\\nBoard sau n∆∞·ªõc ƒëi:\")\n",
    "display_board(new_board3)\n",
    "p1_boxes = sum(1 for p in new_board3['boxes'].values() if p == 1)\n",
    "p2_boxes = sum(1 for p in new_board3['boxes'].values() if p == -1)\n",
    "print(f\"K·∫øt qu·∫£: Player +1: {p1_boxes} boxes, Player -1: {p2_boxes} boxes\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"T·ªîNG K·∫æT:\")\n",
    "print(\"\"\"\n",
    "Minimax v·ªõi Alpha-Beta Pruning th·ªÉ hi·ªán:\n",
    "‚úì Nh·∫≠n di·ªán ƒë∆∞·ª£c c∆° h·ªôi ho√†n th√†nh box ngay l·∫≠p t·ª©c\n",
    "‚úì ƒê√°nh gi√° ƒë∆∞·ª£c gi√° tr·ªã c·ªßa c√°c n∆∞·ªõc ƒëi kh√°c nhau\n",
    "‚úì T√¨m ra n∆∞·ªõc ƒëi t·ªëi ∆∞u trong c√°c t√¨nh hu·ªëng endgame\n",
    "‚úì Alpha-Beta Pruning gi√∫p gi·∫£m s·ªë nodes c·∫ßn explore\n",
    "\n",
    "Tuy nhi√™n:\n",
    "- V·ªõi board l·ªõn, th·ªùi gian t√≠nh to√°n tƒÉng exponentially\n",
    "- C·∫ßn th√™m heuristic v√† depth cutoff cho board l·ªõn h∆°n\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long does it take to make a move? Start with a smaller board make the board larger. What is the largest board you can solve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ƒêo th·ªùi gian v√† k√≠ch th∆∞·ªõc board t·ªëi ƒëa\n",
    "\n",
    "import time\n",
    "\n",
    "def benchmark_minimax(board_sizes):\n",
    "    \"\"\"\n",
    "    ƒêo th·ªùi gian th·ª±c thi c·ªßa Minimax v·ªõi c√°c k√≠ch th∆∞·ªõc board kh√°c nhau\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for size in board_sizes:\n",
    "        rows, cols = size\n",
    "        print(f\"\\nTest v·ªõi board {rows}√ó{cols}:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # T·∫°o board tr·ªëng\n",
    "        board = {\n",
    "            'size': size,\n",
    "            'lines': {},\n",
    "            'boxes': {}\n",
    "        }\n",
    "        \n",
    "        # ƒêo th·ªùi gian cho n∆∞·ªõc ƒëi ƒë·∫ßu ti√™n\n",
    "        global nodes_explored\n",
    "        nodes_explored = 0\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            # Set timeout (gi·∫£ ƒë·ªãnh)\n",
    "            action = minimax_player(board, 1)\n",
    "            elapsed_time = time.time() - start_time\n",
    "            \n",
    "            print(f\"  Th·ªùi gian: {elapsed_time:.3f}s\")\n",
    "            print(f\"  Nodes explored: {nodes_explored:,}\")\n",
    "            print(f\"  Best action: {action}\")\n",
    "            \n",
    "            results.append({\n",
    "                'size': size,\n",
    "                'time': elapsed_time,\n",
    "                'nodes': nodes_explored,\n",
    "                'success': True\n",
    "            })\n",
    "            \n",
    "            # N·∫øu m·∫•t qu√° 30 gi√¢y, d·ª´ng l·∫°i\n",
    "            if elapsed_time > 30:\n",
    "                print(f\"  ‚ö† Qu√° ch·∫≠m (>{30}s), d·ª´ng test v·ªõi board l·ªõn h∆°n\")\n",
    "                break\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚úó L·ªói: {e}\")\n",
    "            results.append({\n",
    "                'size': size,\n",
    "                'time': None,\n",
    "                'nodes': None,\n",
    "                'success': False\n",
    "            })\n",
    "            break\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test v·ªõi c√°c k√≠ch th∆∞·ªõc board tƒÉng d·∫ßn\n",
    "print(\"BENCHMARK: Th·ªùi gian th·ª±c thi v·ªõi board kh√°c nhau\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "board_sizes = [\n",
    "    (2, 2),  # 1 box - r·∫•t nh·ªè\n",
    "    (2, 3),  # 2 boxes\n",
    "    (3, 3),  # 4 boxes\n",
    "    (3, 4),  # 6 boxes\n",
    "    (4, 4),  # 9 boxes\n",
    "    # (4, 5),  # 12 boxes - c√≥ th·ªÉ qu√° ch·∫≠m\n",
    "]\n",
    "\n",
    "results = benchmark_minimax(board_sizes)\n",
    "\n",
    "# T·ªïng k·∫øt\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"T·ªîNG K·∫æT:\")\n",
    "print(f\"{'Board':<10} {'Th·ªùi gian':<15} {'Nodes explored':<20} {'Tr·∫°ng th√°i'}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for r in results:\n",
    "    size_str = f\"{r['size'][0]}√ó{r['size'][1]}\"\n",
    "    time_str = f\"{r['time']:.3f}s\" if r['time'] else \"N/A\"\n",
    "    nodes_str = f\"{r['nodes']:,}\" if r['nodes'] else \"N/A\"\n",
    "    status = \"‚úì Th√†nh c√¥ng\" if r['success'] else \"‚úó Th·∫•t b·∫°i\"\n",
    "    print(f\"{size_str:<10} {time_str:<15} {nodes_str:<20} {status}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"K·∫æT LU·∫¨N:\")\n",
    "print(\"\"\"\n",
    "- Board 2√ó2 v√† 2√ó3: R·∫•t nhanh, Minimax c√≥ th·ªÉ solve ho√†n to√†n\n",
    "- Board 3√ó3: Kh·∫£ thi, nh∆∞ng b·∫Øt ƒë·∫ßu ch·∫≠m\n",
    "- Board 3√ó4 tr·ªü l√™n: Th·ªùi gian tƒÉng exponentially\n",
    "- Board 4√ó4: C√≥ th·ªÉ qu√° ch·∫≠m cho n∆∞·ªõc ƒëi ƒë·∫ßu ti√™n\n",
    "\n",
    "ƒê·ªÄ XU·∫§T:\n",
    "- Board t·ªëi ƒëa c√≥ th·ªÉ solve v·ªõi Minimax thu·∫ßn: 3√ó3 ho·∫∑c 3√ó4\n",
    "- V·ªõi board l·ªõn h∆°n: C·∫¶N s·ª≠ d·ª•ng:\n",
    "  + Depth-limited search (gi·ªõi h·∫°n ƒë·ªô s√¢u)\n",
    "  + Heuristic evaluation function\n",
    "  + Move ordering ƒë·ªÉ tƒÉng hi·ªáu qu·∫£ Alpha-Beta pruning\n",
    "  + Iterative deepening\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move ordering\n",
    "\n",
    "Starting the search with better moves will increase the efficiency of alpha-beta pruning. Describe and implement a simple move ordering strategy. \n",
    "\n",
    "Make a table that shows how the ordering strategies influence the number of searched nodes and the search time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move Ordering Strategy v√† So s√°nh hi·ªáu qu·∫£\n",
    "\n",
    "def count_almost_complete_boxes(board, action):\n",
    "    \"\"\"\n",
    "    ƒê·∫øm s·ªë boxes \"g·∫ßn ho√†n th√†nh\" (c√≥ 3 c·∫°nh) sau khi th·ª±c hi·ªán action\n",
    "    \"\"\"\n",
    "    rows, cols = board['size']\n",
    "    orientation, row, col = action\n",
    "    \n",
    "    # T·∫°o board m·ªõi v·ªõi action n√†y\n",
    "    test_board = copy.deepcopy(board)\n",
    "    test_board['lines'][action] = True\n",
    "    \n",
    "    almost_complete_count = 0\n",
    "    \n",
    "    # Ki·ªÉm tra t·∫•t c·∫£ c√°c boxes\n",
    "    for r in range(rows - 1):\n",
    "        for c in range(cols - 1):\n",
    "            # ƒê·∫øm s·ªë c·∫°nh ƒë√£ c√≥\n",
    "            sides = 0\n",
    "            if ('h', r, c) in test_board['lines']:\n",
    "                sides += 1\n",
    "            if ('h', r + 1, c) in test_board['lines']:\n",
    "                sides += 1\n",
    "            if ('v', r, c) in test_board['lines']:\n",
    "                sides += 1\n",
    "            if ('v', r, c + 1) in test_board['lines']:\n",
    "                sides += 1\n",
    "            \n",
    "            if sides == 3:\n",
    "                almost_complete_count += 1\n",
    "    \n",
    "    return almost_complete_count\n",
    "\n",
    "\n",
    "def order_moves(board, available_actions):\n",
    "    \"\"\"\n",
    "    S·∫Øp x·∫øp c√°c n∆∞·ªõc ƒëi theo th·ª© t·ª± ∆∞u ti√™n\n",
    "    \"\"\"\n",
    "    rows, cols = board['size']\n",
    "    \n",
    "    # Ph√¢n lo·∫°i actions\n",
    "    completing_moves = []  # Ho√†n th√†nh box\n",
    "    safe_moves = []        # Kh√¥ng t·∫°o box 3 c·∫°nh\n",
    "    risky_moves = []       # T·∫°o box 3 c·∫°nh\n",
    "    \n",
    "    for action in available_actions:\n",
    "        # Ki·ªÉm tra xem action c√≥ ho√†n th√†nh box kh√¥ng\n",
    "        test_board = copy.deepcopy(board)\n",
    "        test_board['lines'][action] = True\n",
    "        \n",
    "        orientation, row, col = action\n",
    "        completes_box = False\n",
    "        \n",
    "        if orientation == 'h':\n",
    "            if row > 0 and check_box_completion(test_board, row - 1, col):\n",
    "                completes_box = True\n",
    "            if row < rows - 1 and check_box_completion(test_board, row, col):\n",
    "                completes_box = True\n",
    "        else:  # 'v'\n",
    "            if col > 0 and check_box_completion(test_board, row, col - 1):\n",
    "                completes_box = True\n",
    "            if col < cols - 1 and check_box_completion(test_board, row, col):\n",
    "                completes_box = True\n",
    "        \n",
    "        if completes_box:\n",
    "            completing_moves.append(action)\n",
    "        else:\n",
    "            almost_complete = count_almost_complete_boxes(board, action)\n",
    "            \n",
    "            if almost_complete == 0:\n",
    "                safe_moves.append(action)\n",
    "            else:\n",
    "                risky_moves.append((action, almost_complete))\n",
    "    \n",
    "    # S·∫Øp x·∫øp risky moves theo s·ªë box 3 c·∫°nh (√≠t nh·∫•t tr∆∞·ªõc)\n",
    "    risky_moves.sort(key=lambda x: x[1])\n",
    "    risky_moves = [action for action, _ in risky_moves]\n",
    "    \n",
    "    return completing_moves + safe_moves + risky_moves\n",
    "\n",
    "\n",
    "# Minimax v·ªõi move ordering\n",
    "def minimax_with_ordering(board, player, alpha=-math.inf, beta=math.inf, maximizing=True):\n",
    "    \"\"\"\n",
    "    Minimax v·ªõi Alpha-Beta Pruning v√† Move Ordering\n",
    "    \"\"\"\n",
    "    global nodes_explored\n",
    "    nodes_explored += 1\n",
    "    \n",
    "    if terminal(board):\n",
    "        return utility(board, player), None\n",
    "    \n",
    "    available_actions = actions(board)\n",
    "    if not available_actions:\n",
    "        return utility(board, player), None\n",
    "    \n",
    "    # S·∫ÆP X·∫æP MOVES\n",
    "    available_actions = order_moves(board, available_actions)\n",
    "    \n",
    "    best_action = None\n",
    "    \n",
    "    if maximizing:\n",
    "        best_value = -math.inf\n",
    "        for action in available_actions:\n",
    "            new_board, next_player = result(board, action, player)\n",
    "            \n",
    "            if next_player == player:\n",
    "                value, _ = minimax_with_ordering(new_board, player, alpha, beta, True)\n",
    "            else:\n",
    "                value, _ = minimax_with_ordering(new_board, player, alpha, beta, False)\n",
    "            \n",
    "            if value > best_value:\n",
    "                best_value = value\n",
    "                best_action = action\n",
    "            \n",
    "            alpha = max(alpha, best_value)\n",
    "            if beta <= alpha:\n",
    "                break\n",
    "        \n",
    "        return best_value, best_action\n",
    "    else:\n",
    "        best_value = math.inf\n",
    "        opponent = -player\n",
    "        \n",
    "        for action in available_actions:\n",
    "            new_board, next_player = result(board, action, opponent)\n",
    "            \n",
    "            if next_player == opponent:\n",
    "                value, _ = minimax_with_ordering(new_board, player, alpha, beta, False)\n",
    "            else:\n",
    "                value, _ = minimax_with_ordering(new_board, player, alpha, beta, True)\n",
    "            \n",
    "            if value < best_value:\n",
    "                best_value = value\n",
    "                best_action = action\n",
    "            \n",
    "            beta = min(beta, best_value)\n",
    "            if beta <= alpha:\n",
    "                break\n",
    "        \n",
    "        return best_value, best_action\n",
    "\n",
    "\n",
    "# So s√°nh hi·ªáu qu·∫£\n",
    "print(\"SO S√ÅNH: Minimax v·ªõi v√† kh√¥ng c√≥ Move Ordering\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "test_board = {\n",
    "    'size': (3, 3),\n",
    "    'lines': {},\n",
    "    'boxes': {}\n",
    "}\n",
    "\n",
    "# Test kh√¥ng c√≥ ordering\n",
    "print(\"\\n1. MINIMAX KH√îNG C√ì MOVE ORDERING:\")\n",
    "nodes_explored = 0\n",
    "start_time = time.time()\n",
    "value1, action1 = minimax_alpha_beta(test_board, 1)\n",
    "time1 = time.time() - start_time\n",
    "nodes1 = nodes_explored\n",
    "print(f\"   Th·ªùi gian: {time1:.3f}s\")\n",
    "print(f\"   Nodes explored: {nodes1:,}\")\n",
    "print(f\"   Best action: {action1}\")\n",
    "\n",
    "# Test c√≥ ordering\n",
    "print(\"\\n2. MINIMAX V·ªöI MOVE ORDERING:\")\n",
    "nodes_explored = 0\n",
    "start_time = time.time()\n",
    "value2, action2 = minimax_with_ordering(test_board, 1)\n",
    "time2 = time.time() - start_time\n",
    "nodes2 = nodes_explored\n",
    "print(f\"   Th·ªùi gian: {time2:.3f}s\")\n",
    "print(f\"   Nodes explored: {nodes2:,}\")\n",
    "print(f\"   Best action: {action2}\")\n",
    "\n",
    "# T√≠nh to√°n c·∫£i thi·ªán\n",
    "improvement = ((nodes1 - nodes2) / nodes1 * 100) if nodes1 > 0 else 0\n",
    "speedup = (time1 / time2) if time2 > 0 else 0\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"K·∫æT QU·∫¢:\")\n",
    "print(f\"   Gi·∫£m nodes: {improvement:.1f}%\")\n",
    "print(f\"   TƒÉng t·ªëc: {speedup:.2f}x\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"B·∫¢NG SO S√ÅNH:\")\n",
    "print(f\"{'Ph∆∞∆°ng ph√°p':<30} {'Th·ªùi gian':<15} {'Nodes':<15} {'C·∫£i thi·ªán'}\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Minimax thu·∫ßn':<30} {time1:.3f}s{'':<10} {nodes1:,}{'':<10} -\")\n",
    "print(f\"{'Minimax + Move Ordering':<30} {time2:.3f}s{'':<10} {nodes2:,}{'':<10} {improvement:.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"K·∫æT LU·∫¨N:\")\n",
    "print(f\"\"\"\n",
    "Move Ordering gi√∫p:\n",
    "‚úì Gi·∫£m s·ªë nodes c·∫ßn explore: ~{improvement:.1f}%\n",
    "‚úì TƒÉng t·ªëc ƒë·ªô t√≠nh to√°n: ~{speedup:.2f}x\n",
    "‚úì Alpha-Beta pruning hi·ªáu qu·∫£ h∆°n do explore n∆∞·ªõc t·ªët tr∆∞·ªõc\n",
    "‚úì ƒê·∫∑c bi·ªát hi·ªáu qu·∫£ trong endgame khi c√≥ nhi·ªÅu completing moves\n",
    "\n",
    "Chi·∫øn l∆∞·ª£c s·∫Øp x·∫øp:\n",
    "1. Completing moves (ho√†n th√†nh box) - ∆Øu ti√™n cao nh·∫•t\n",
    "2. Safe moves (kh√¥ng t·∫°o box 3 c·∫°nh) - ∆Øu ti√™n trung b√¨nh  \n",
    "3. Risky moves (t·∫°o box 3 c·∫°nh) - ∆Øu ti√™n th·∫•p nh·∫•t\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The first few moves\n",
    "\n",
    "Start with an empty board. This is the worst case scenario for minimax search with alpha-beta pruning since it needs solve all possible games that can be played (minus some pruning) before making the decision. What can you do? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X·ª≠ l√Ω n∆∞·ªõc ƒëi ƒë·∫ßu ti√™n v·ªõi board tr·ªëng\n",
    "\n",
    "print(\"V·∫§N ƒê·ªÄ: N∆∞·ªõc ƒëi ƒë·∫ßu ti√™n tr√™n board tr·ªëng\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "TH√ÅCH TH·ª®C:\n",
    "- Board tr·ªëng l√† worst case cho Minimax v√¨ ph·∫£i explore to√†n b·ªô game tree\n",
    "- V·ªõi board 3√ó3: 12 n∆∞·ªõc ƒëi kh·∫£ d·ª•ng ban ƒë·∫ßu\n",
    "- V·ªõi board 4√ó4: 24 n∆∞·ªõc ƒëi kh·∫£ d·ª•ng ban ƒë·∫ßu\n",
    "- S·ªë tr·∫°ng th√°i c·∫ßn explore: exponential!\n",
    "\n",
    "GI·∫¢I PH√ÅP:\n",
    "\n",
    "1. S·ª¨ D·ª§NG SYMMETRY (T√≠nh ƒë·ªëi x·ª©ng):\n",
    "   - Board Dots & Boxes c√≥ t√≠nh ƒë·ªëi x·ª©ng cao\n",
    "   - Nhi·ªÅu n∆∞·ªõc ƒëi ƒë·∫ßu ti√™n l√† t∆∞∆°ng ƒë∆∞∆°ng (do ƒë·ªëi x·ª©ng)\n",
    "   - C√≥ th·ªÉ gi·∫£m branching factor ƒë√°ng k·ªÉ\n",
    "   \n",
    "2. OPENING BOOK (Th∆∞ vi·ªán khai cu·ªôc):\n",
    "   - Pre-compute v√† l∆∞u c√°c n∆∞·ªõc ƒëi t·ªët nh·∫•t cho c√°c t√¨nh hu·ªëng ƒë·∫ßu game\n",
    "   - T∆∞∆°ng t·ª± nh∆∞ c·ªù vua, c·ªù t∆∞·ªõng\n",
    "   \n",
    "3. DEPTH-LIMITED SEARCH v·ªõi ITERATIVE DEEPENING:\n",
    "   - B·∫Øt ƒë·∫ßu v·ªõi depth nh·ªè, tƒÉng d·∫ßn\n",
    "   - C√≥ th·ªÉ d·ª´ng b·∫•t c·ª© l√∫c n√†o v√† v·∫´n c√≥ n∆∞·ªõc ƒëi\n",
    "   \n",
    "4. HEURISTIC EVALUATION:\n",
    "   - Kh√¥ng c·∫ßn search ƒë·∫øn terminal state\n",
    "   - D√πng heuristic ƒë·ªÉ ƒë√°nh gi√° v·ªã tr√≠ gi·ªØa game\n",
    "\"\"\")\n",
    "\n",
    "# Implement symmetry reduction\n",
    "def get_canonical_action(action, board_size):\n",
    "    \"\"\"\n",
    "    Chuy·ªÉn ƒë·ªïi action v·ªÅ d·∫°ng canonical (chu·∫©n h√≥a) theo symmetry\n",
    "    \n",
    "    V·ªõi board vu√¥ng, c√≥ 8 symmetries (4 rotations √ó 2 reflections)\n",
    "    Ch·ªâ c·∫ßn x√©t 1 trong 8 positions t∆∞∆°ng ƒë∆∞∆°ng\n",
    "    \"\"\"\n",
    "    rows, cols = board_size\n",
    "    orientation, row, col = action\n",
    "    \n",
    "    # ƒê∆°n gi·∫£n h√≥a: ch·ªâ x√©t reflection theo tr·ª•c ngang\n",
    "    # (Full implementation c·∫ßn x√©t t·∫•t c·∫£ 8 symmetries)\n",
    "    \n",
    "    # V·ªõi board tr·ªëng, ch·ªçn action ·ªü g√≥c/c·∫°nh tr√™n ho·∫∑c tr√°i\n",
    "    if orientation == 'h' and row >= rows // 2:\n",
    "        # Mirror horizontally\n",
    "        return ('h', rows - 1 - row, col)\n",
    "    elif orientation == 'v' and col >= cols // 2:\n",
    "        # Mirror vertically\n",
    "        return ('v', row, cols - 1 - col)\n",
    "    \n",
    "    return action\n",
    "\n",
    "\n",
    "def filter_symmetric_actions(actions, board_size):\n",
    "    \"\"\"\n",
    "    L·ªçc b·ªè c√°c actions ƒë·ªëi x·ª©ng, ch·ªâ gi·ªØ l·∫°i representatives\n",
    "    \"\"\"\n",
    "    canonical_actions = set()\n",
    "    unique_actions = []\n",
    "    \n",
    "    for action in actions:\n",
    "        canonical = get_canonical_action(action, board_size)\n",
    "        if canonical not in canonical_actions:\n",
    "            canonical_actions.add(canonical)\n",
    "            unique_actions.append(action)\n",
    "    \n",
    "    return unique_actions\n",
    "\n",
    "\n",
    "# Opening book - hardcoded best first moves\n",
    "OPENING_BOOK = {\n",
    "    (3, 3): ('h', 1, 0),  # ƒê∆∞·ªùng gi·ªØa, b√™n tr√°i\n",
    "    (4, 4): ('h', 1, 1),  # G·∫ßn trung t√¢m\n",
    "    (5, 5): ('h', 2, 2),  # Trung t√¢m\n",
    "}\n",
    "\n",
    "def smart_first_move(board, player):\n",
    "    \"\"\"\n",
    "    X·ª≠ l√Ω n∆∞·ªõc ƒëi ƒë·∫ßu ti√™n th√¥ng minh\n",
    "    \"\"\"\n",
    "    size = board['size']\n",
    "    \n",
    "    # Ki·ªÉm tra c√≥ ph·∫£i n∆∞·ªõc ƒëi ƒë·∫ßu ti√™n kh√¥ng\n",
    "    if len(board['lines']) == 0:\n",
    "        # D√πng opening book n·∫øu c√≥\n",
    "        if size in OPENING_BOOK:\n",
    "            return OPENING_BOOK[size]\n",
    "        \n",
    "        # N·∫øu kh√¥ng, ch·ªçn n∆∞·ªõc ƒëi g·∫ßn trung t√¢m\n",
    "        rows, cols = size\n",
    "        # Ch·ªçn ƒë∆∞·ªùng ngang g·∫ßn trung t√¢m\n",
    "        return ('h', rows // 2, cols // 2)\n",
    "    \n",
    "    # N·∫øu kh√¥ng ph·∫£i n∆∞·ªõc ƒë·∫ßu, d√πng minimax b√¨nh th∆∞·ªùng\n",
    "    return None\n",
    "\n",
    "\n",
    "print(\"\\nTEST: Opening strategy\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Test v·ªõi board tr·ªëng\n",
    "empty_board = {\n",
    "    'size': (3, 3),\n",
    "    'lines': {},\n",
    "    'boxes': {}\n",
    "}\n",
    "\n",
    "print(\"Board tr·ªëng 3√ó3:\")\n",
    "first_move = smart_first_move(empty_board, 1)\n",
    "print(f\"Opening move: {first_move}\")\n",
    "\n",
    "print(\"\\nS·ª≠ d·ª•ng symmetry ƒë·ªÉ gi·∫£m s·ªë actions c·∫ßn x√©t:\")\n",
    "all_actions = actions(empty_board)\n",
    "print(f\"T·ªïng s·ªë actions: {len(all_actions)}\")\n",
    "\n",
    "unique_actions = filter_symmetric_actions(all_actions, empty_board['size'])\n",
    "print(f\"Actions sau khi lo·∫°i b·ªè symmetry: {len(unique_actions)}\")\n",
    "print(f\"Gi·∫£m: {(1 - len(unique_actions)/len(all_actions)) * 100:.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"T√ìM T·∫ÆT CHI·∫æN L∆Ø·ª¢C:\")\n",
    "print(\"\"\"\n",
    "1. Opening Book: S·ª≠ d·ª•ng n∆∞·ªõc ƒëi pre-computed cho board tr·ªëng\n",
    "2. Symmetry Reduction: Gi·∫£m branching factor 50-75%\n",
    "3. Iterative Deepening: T√¨m n∆∞·ªõc ƒëi ƒë·ªß t·ªët nhanh ch√≥ng\n",
    "4. Time Management: Gi·ªõi h·∫°n th·ªùi gian suy nghƒ©\n",
    "\n",
    "K·∫æT QU·∫¢:\n",
    "- C√≥ th·ªÉ x·ª≠ l√Ω n∆∞·ªõc ƒëi ƒë·∫ßu ti√™n nhanh h∆°n nhi·ªÅu\n",
    "- V·∫´n ƒë·∫£m b·∫£o ch·∫•t l∆∞·ª£ng n∆∞·ªõc ƒëi\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playtime\n",
    "\n",
    "Let the Minimax Search agent play a random agent on a small board. Analyze wins, losses and draws."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimax vs Random Player\n",
    "\n",
    "def minimax_player_simple(board, player):\n",
    "    \"\"\"\n",
    "    Agent ƒë∆°n gi·∫£n s·ª≠ d·ª•ng Minimax (kh√¥ng in log)\n",
    "    \"\"\"\n",
    "    global nodes_explored\n",
    "    nodes_explored = 0\n",
    "    value, action = minimax_with_ordering(board, player)\n",
    "    return action\n",
    "\n",
    "\n",
    "print(\"PLAYTIME: Minimax vs Random Player\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Ch∆°i nhi·ªÅu games\n",
    "num_games = 20\n",
    "results = {\n",
    "    'minimax_wins': 0,\n",
    "    'random_wins': 0,\n",
    "    'draws': 0\n",
    "}\n",
    "\n",
    "print(f\"\\nCh∆°i {num_games} games tr√™n board 3√ó3...\")\n",
    "print(\"Minimax = Player 1 (+1), Random = Player 2 (-1)\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for i in range(num_games):\n",
    "    result_game = play_game(minimax_player_simple, random_player, board_size=(3, 3))\n",
    "    \n",
    "    if result_game == 1:\n",
    "        results['minimax_wins'] += 1\n",
    "    elif result_game == -1:\n",
    "        results['random_wins'] += 1\n",
    "    else:\n",
    "        results['draws'] += 1\n",
    "    \n",
    "    if (i + 1) % 5 == 0:\n",
    "        print(f\"ƒê√£ ch∆°i {i + 1}/{num_games} games...\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"K·∫æT QU·∫¢:\")\n",
    "print(f\"  Minimax th·∫Øng: {results['minimax_wins']}/{num_games} ({results['minimax_wins']/num_games*100:.1f}%)\")\n",
    "print(f\"  Random th·∫Øng:  {results['random_wins']}/{num_games} ({results['random_wins']/num_games*100:.1f}%)\")\n",
    "print(f\"  H√≤a:           {results['draws']}/{num_games} ({results['draws']/num_games*100:.1f}%)\")\n",
    "\n",
    "# Th·ª≠ ng∆∞·ª£c l·∫°i: Random ƒëi tr∆∞·ªõc\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"Th·ª≠ ng∆∞·ª£c l·∫°i: Random = Player 1, Minimax = Player 2\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "results2 = {\n",
    "    'random_wins': 0,\n",
    "    'minimax_wins': 0,\n",
    "    'draws': 0\n",
    "}\n",
    "\n",
    "for i in range(num_games):\n",
    "    result_game = play_game(random_player, minimax_player_simple, board_size=(3, 3))\n",
    "    \n",
    "    if result_game == 1:\n",
    "        results2['random_wins'] += 1\n",
    "    elif result_game == -1:\n",
    "        results2['minimax_wins'] += 1\n",
    "    else:\n",
    "        results2['draws'] += 1\n",
    "    \n",
    "    if (i + 1) % 5 == 0:\n",
    "        print(f\"ƒê√£ ch∆°i {i + 1}/{num_games} games...\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"K·∫æT QU·∫¢:\")\n",
    "print(f\"  Random th·∫Øng:  {results2['random_wins']}/{num_games} ({results2['random_wins']/num_games*100:.1f}%)\")\n",
    "print(f\"  Minimax th·∫Øng: {results2['minimax_wins']}/{num_games} ({results2['minimax_wins']/num_games*100:.1f}%)\")\n",
    "print(f\"  H√≤a:           {results2['draws']}/{num_games} ({results2['draws']/num_games*100:.1f}%)\")\n",
    "\n",
    "# Ch∆°i 1 game v·ªõi verbose ƒë·ªÉ xem\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"M·ªòT GAME M·∫™U (Minimax vs Random):\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "final_result = play_game(minimax_player_simple, random_player, board_size=(3, 3), verbose=True)\n",
    "\n",
    "if final_result == 1:\n",
    "    print(\"\\nüèÜ MINIMAX TH·∫ÆNG!\")\n",
    "elif final_result == -1:\n",
    "    print(\"\\nüèÜ RANDOM TH·∫ÆNG!\")\n",
    "else:\n",
    "    print(\"\\nü§ù H√íA!\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PH√ÇN T√çCH:\")\n",
    "print(\"\"\"\n",
    "K·∫æT QU·∫¢ MONG ƒê·ª¢I:\n",
    "- Minimax n√™n th·∫Øng g·∫ßn 100% khi ƒë·ªëi ƒë·∫ßu Random Player\n",
    "- Do Minimax ch∆°i optimal (ho·∫∑c g·∫ßn optimal)\n",
    "- Random kh√¥ng c√≥ chi·∫øn thu·∫≠t\n",
    "\n",
    "N·∫æU MINIMAX KH√îNG TH·∫ÆNG 100%:\n",
    "- C√≥ th·ªÉ do board nh·ªè (3√ó3) c√≥ √≠t boxes\n",
    "- Y·∫øu t·ªë ng·∫´u nhi√™n v·∫´n c√≥ th·ªÉ ·∫£nh h∆∞·ªüng\n",
    "- Ho·∫∑c c√≥ bug trong implementation\n",
    "\n",
    "L∆ØU √ù V·ªÄ ƒêI TR∆Ø·ªöC/ƒêI SAU:\n",
    "- Trong Dots & Boxes, ƒëi tr∆∞·ªõc c√≥ l·ª£i th·∫ø nh·ªè\n",
    "- Minimax n√™n th·∫Øng b·∫•t k·ªÉ ƒëi tr∆∞·ªõc hay sau\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Heuristic Alpha-Beta Tree Search [30 points] \n",
    "\n",
    "### Heuristic evaluation function\n",
    "\n",
    "Define and implement a heuristic evaluation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4: Heuristic Evaluation Function\n",
    "\n",
    "def heuristic_evaluation(board, player):\n",
    "    \"\"\"\n",
    "    H√†m ƒë√°nh gi√° heuristic cho Dots and Boxes\n",
    "    \n",
    "    C√°c y·∫øu t·ªë xem x√©t:\n",
    "    1. S·ªë boxes ƒë√£ ho√†n th√†nh (quan tr·ªçng nh·∫•t)\n",
    "    2. S·ªë boxes g·∫ßn ho√†n th√†nh (3 c·∫°nh) - c√≥ th·ªÉ nguy hi·ªÉm ho·∫∑c c√≥ l·ª£i\n",
    "    3. S·ªë boxes c√≥ 2 c·∫°nh - ti·ªÅm nƒÉng trong t∆∞∆°ng lai\n",
    "    4. Ki·ªÉm so√°t board (s·ªë ƒë∆∞·ªùng k·∫ª ƒë√£ v·∫Ω)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    board: dict\n",
    "        Board state hi·ªán t·∫°i\n",
    "    player: int\n",
    "        Ng∆∞·ªùi ch∆°i c·∫ßn ƒë√°nh gi√° (+1 ho·∫∑c -1)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    float: ƒêi·ªÉm ƒë√°nh gi√° (cao = t·ªët cho player)\n",
    "    \"\"\"\n",
    "    rows, cols = board['size']\n",
    "    boxes = board['boxes']\n",
    "    lines = board['lines']\n",
    "    \n",
    "    # 1. ƒê·∫øm boxes ƒë√£ ho√†n th√†nh\n",
    "    player_boxes = sum(1 for p in boxes.values() if p == player)\n",
    "    opponent_boxes = sum(1 for p in boxes.values() if p == -player)\n",
    "    \n",
    "    score = (player_boxes - opponent_boxes) * 100  # Weight cao nh·∫•t\n",
    "    \n",
    "    # 2. Ph√¢n t√≠ch c√°c boxes theo s·ªë c·∫°nh\n",
    "    player_almost_complete = 0  # 3 c·∫°nh\n",
    "    opponent_almost_complete = 0\n",
    "    player_half_complete = 0     # 2 c·∫°nh\n",
    "    opponent_half_complete = 0\n",
    "    neutral_boxes = 0            # 0-1 c·∫°nh\n",
    "    \n",
    "    for r in range(rows - 1):\n",
    "        for c in range(cols - 1):\n",
    "            # B·ªè qua boxes ƒë√£ ho√†n th√†nh\n",
    "            if (r, c) in boxes:\n",
    "                continue\n",
    "            \n",
    "            # ƒê·∫øm s·ªë c·∫°nh\n",
    "            sides = 0\n",
    "            if ('h', r, c) in lines:\n",
    "                sides += 1\n",
    "            if ('h', r + 1, c) in lines:\n",
    "                sides += 1\n",
    "            if ('v', r, c) in lines:\n",
    "                sides += 1\n",
    "            if ('v', r, c + 1) in lines:\n",
    "                sides += 1\n",
    "            \n",
    "            if sides == 3:\n",
    "                # Box g·∫ßn ho√†n th√†nh - NGUY HI·ªÇM n·∫øu l√† l∆∞·ª£t ƒë·ªëi th·ªß\n",
    "                # Coi nh∆∞ ƒë·ªëi th·ªß s·∫Ω l·∫•y n√≥\n",
    "                opponent_almost_complete += 1\n",
    "            elif sides == 2:\n",
    "                player_half_complete += 1\n",
    "            elif sides <= 1:\n",
    "                neutral_boxes += 1\n",
    "    \n",
    "    # 3. ƒêi·ªÉm cho boxes g·∫ßn ho√†n th√†nh\n",
    "    # Boxes 3 c·∫°nh th∆∞·ªùng b·ªã ƒë·ªëi th·ªß l·∫•y, n√™n tr·ª´ ƒëi·ªÉm\n",
    "    score -= opponent_almost_complete * 50\n",
    "    \n",
    "    # 4. ƒêi·ªÉm cho boxes c√≥ 2 c·∫°nh (ti·ªÅm nƒÉng t·∫°o chu·ªói boxes)\n",
    "    score += player_half_complete * 10\n",
    "    \n",
    "    # 5. ƒêi·ªÉm cho vi·ªác c√≤n nhi·ªÅu boxes neutral (linh ho·∫°t)\n",
    "    score += neutral_boxes * 2\n",
    "    \n",
    "    # 6. Bonus n·∫øu d·∫´n tr∆∞·ªõc nhi·ªÅu\n",
    "    if player_boxes > opponent_boxes + 2:\n",
    "        score += 30  # Bonus cho vi·ªác d·∫´n tr∆∞·ªõc an to√†n\n",
    "    \n",
    "    return score\n",
    "\n",
    "\n",
    "# Test heuristic function\n",
    "print(\"TEST: Heuristic Evaluation Function\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Test case 1: Player d·∫´n tr∆∞·ªõc\n",
    "test1 = {\n",
    "    'size': (3, 3),\n",
    "    'lines': {\n",
    "        ('h', 0, 0): True, ('h', 1, 0): True,\n",
    "        ('v', 0, 0): True, ('v', 0, 1): True,\n",
    "        ('h', 0, 1): True, ('h', 1, 1): True,\n",
    "    },\n",
    "    'boxes': {\n",
    "        (0, 0): 1,  # Player +1 c√≥ 1 box\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Test 1: Player +1 c√≥ 1 box, Player -1 c√≥ 0 box\")\n",
    "display_board(test1)\n",
    "score1 = heuristic_evaluation(test1, 1)\n",
    "print(f\"\\nHeuristic score cho Player +1: {score1:.1f}\")\n",
    "\n",
    "# Test case 2: C√≥ boxes 3 c·∫°nh (nguy hi·ªÉm)\n",
    "test2 = {\n",
    "    'size': (3, 3),\n",
    "    'lines': {\n",
    "        ('h', 0, 0): True,\n",
    "        ('h', 1, 0): True,\n",
    "        ('v', 0, 0): True,\n",
    "        # Thi·∫øu ('v', 0, 1) - box (0,0) c√≥ 3 c·∫°nh\n",
    "    },\n",
    "    'boxes': {}\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"Test 2: C√≥ box g·∫ßn ho√†n th√†nh (3 c·∫°nh)\")\n",
    "display_board(test2)\n",
    "score2 = heuristic_evaluation(test2, 1)\n",
    "print(f\"\\nHeuristic score cho Player +1: {score2:.1f}\")\n",
    "print(\"(ƒêi·ªÉm √¢m v√¨ c√≥ box 3 c·∫°nh - ƒë·ªëi th·ªß c√≥ th·ªÉ l·∫•y)\")\n",
    "\n",
    "# Test case 3: Many boxes with 2 sides\n",
    "test3 = {\n",
    "    'size': (3, 3),\n",
    "    'lines': {\n",
    "        ('h', 0, 0): True, ('h', 0, 1): True,\n",
    "        ('v', 0, 0): True, ('v', 0, 1): True,\n",
    "    },\n",
    "    'boxes': {}\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"Test 3: Nhi·ªÅu boxes c√≥ 2 c·∫°nh\")\n",
    "display_board(test3)\n",
    "score3 = heuristic_evaluation(test3, 1)\n",
    "print(f\"\\nHeuristic score cho Player +1: {score3:.1f}\")\n",
    "print(\"(ƒêi·ªÉm d∆∞∆°ng - t·∫°o c∆° h·ªôi t·ªët)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"GI·∫¢I TH√çCH HEURISTIC:\")\n",
    "print(\"\"\"\n",
    "C√îNG TH·ª®C T√çNH ƒêI·ªÇM:\n",
    "\n",
    "score = (completed_boxes) √ó 100           [Quan tr·ªçng nh·∫•t]\n",
    "      - (almost_complete_boxes) √ó 50      [Nguy hi·ªÉm - ƒë·ªëi th·ªß l·∫•y]\n",
    "      + (half_complete_boxes) √ó 10        [Ti·ªÅm nƒÉng t·ªët]\n",
    "      + (neutral_boxes) √ó 2               [Linh ho·∫°t]\n",
    "      + bonus_if_leading √ó 30             [D·∫´n tr∆∞·ªõc an to√†n]\n",
    "\n",
    "TR·ªåNG S·ªê:\n",
    "- Completed boxes (100): M·ª•c ti√™u ch√≠nh\n",
    "- Almost complete (‚àí50): Tr√°nh t·∫°o c∆° h·ªôi cho ƒë·ªëi th·ªß\n",
    "- Half complete (+10): T·∫°o c∆° h·ªôi cho m√¨nh\n",
    "- Neutral (+2): Gi·ªØ board linh ho·∫°t\n",
    "- Leading bonus (+30): Khuy·∫øn kh√≠ch duy tr√¨ l·ª£i th·∫ø\n",
    "\n",
    "∆ØU ƒêI·ªÇM:\n",
    "‚úì ƒê∆°n gi·∫£n, nhanh t√≠nh to√°n\n",
    "‚úì C√¢n nh·∫Øc c√°c y·∫øu t·ªë quan tr·ªçng\n",
    "‚úì C√≥ th·ªÉ tune weights ƒë·ªÉ c·∫£i thi·ªán\n",
    "\n",
    "H·∫†N CH·∫æ:\n",
    "- Kh√¥ng x√©t ƒë·∫øn chains (chu·ªói boxes n·ªëi ti·∫øp)\n",
    "- Kh√¥ng ph√¢n t√≠ch s√¢u v·ªÅ control theory\n",
    "- C√≥ th·ªÉ c·∫£i thi·ªán b·∫±ng c√°ch h·ªçc t·ª´ data\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cutting off search \n",
    "\n",
    "Modify your Minimax Search with Alpha-Beta Pruning to cut off search at a specified depth and use the heuristic evaluation function. Experiment with different cutoff values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimax with Depth Cutoff v√† Heuristic Evaluation\n",
    "\n",
    "def minimax_heuristic(board, player, depth, max_depth, alpha=-math.inf, beta=math.inf, maximizing=True):\n",
    "    \"\"\"\n",
    "    Minimax v·ªõi Alpha-Beta Pruning, Depth Cutoff, v√† Heuristic Evaluation\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    board: dict\n",
    "        Board state\n",
    "    player: int\n",
    "        Ng∆∞·ªùi ch∆°i (+1 ho·∫∑c -1)\n",
    "    depth: int\n",
    "        ƒê·ªô s√¢u hi·ªán t·∫°i\n",
    "    max_depth: int\n",
    "        ƒê·ªô s√¢u t·ªëi ƒëa (cutoff)\n",
    "    alpha, beta: float\n",
    "        Alpha-Beta bounds\n",
    "    maximizing: bool\n",
    "        Maximize hay minimize\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple: (value, action)\n",
    "    \"\"\"\n",
    "    global nodes_explored\n",
    "    nodes_explored += 1\n",
    "    \n",
    "    # Terminal state ho·∫∑c depth cutoff\n",
    "    if terminal(board):\n",
    "        return utility(board, player), None\n",
    "    \n",
    "    if depth >= max_depth:\n",
    "        # S·ª≠ d·ª•ng heuristic evaluation\n",
    "        return heuristic_evaluation(board, player), None\n",
    "    \n",
    "    available_actions = actions(board)\n",
    "    if not available_actions:\n",
    "        return heuristic_evaluation(board, player), None\n",
    "    \n",
    "    # Move ordering\n",
    "    available_actions = order_moves(board, available_actions)\n",
    "    \n",
    "    best_action = None\n",
    "    \n",
    "    if maximizing:\n",
    "        best_value = -math.inf\n",
    "        \n",
    "        for action in available_actions:\n",
    "            new_board, next_player = result(board, action, player)\n",
    "            \n",
    "            if next_player == player:\n",
    "                # Player ƒëi ti·∫øp - kh√¥ng tƒÉng depth\n",
    "                value, _ = minimax_heuristic(new_board, player, depth, max_depth, alpha, beta, True)\n",
    "            else:\n",
    "                # Chuy·ªÉn sang opponent - tƒÉng depth\n",
    "                value, _ = minimax_heuristic(new_board, player, depth + 1, max_depth, alpha, beta, False)\n",
    "            \n",
    "            if value > best_value:\n",
    "                best_value = value\n",
    "                best_action = action\n",
    "            \n",
    "            alpha = max(alpha, best_value)\n",
    "            if beta <= alpha:\n",
    "                break\n",
    "        \n",
    "        return best_value, best_action\n",
    "    \n",
    "    else:  # minimizing\n",
    "        best_value = math.inf\n",
    "        opponent = -player\n",
    "        \n",
    "        for action in available_actions:\n",
    "            new_board, next_player = result(board, action, opponent)\n",
    "            \n",
    "            if next_player == opponent:\n",
    "                # Opponent ƒëi ti·∫øp - kh√¥ng tƒÉng depth\n",
    "                value, _ = minimax_heuristic(new_board, player, depth, max_depth, alpha, beta, False)\n",
    "            else:\n",
    "                # Chuy·ªÉn l·∫°i player - tƒÉng depth\n",
    "                value, _ = minimax_heuristic(new_board, player, depth + 1, max_depth, alpha, beta, True)\n",
    "            \n",
    "            if value < best_value:\n",
    "                best_value = value\n",
    "                best_action = action\n",
    "            \n",
    "            beta = min(beta, best_value)\n",
    "            if beta <= alpha:\n",
    "                break\n",
    "        \n",
    "        return best_value, best_action\n",
    "\n",
    "\n",
    "def heuristic_player(board, player, max_depth=4):\n",
    "    \"\"\"\n",
    "    Agent s·ª≠ d·ª•ng Minimax v·ªõi heuristic cutoff\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    board: dict\n",
    "        Board state\n",
    "    player: int\n",
    "        Ng∆∞·ªùi ch∆°i\n",
    "    max_depth: int\n",
    "        ƒê·ªô s√¢u cutoff\n",
    "    \"\"\"\n",
    "    global nodes_explored\n",
    "    nodes_explored = 0\n",
    "    \n",
    "    start_time = time.time()\n",
    "    value, action = minimax_heuristic(board, player, 0, max_depth)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"Heuristic (depth={max_depth}): explored {nodes_explored} nodes in {elapsed_time:.3f}s, value={value:.1f}\")\n",
    "    \n",
    "    return action\n",
    "\n",
    "\n",
    "# Test v·ªõi c√°c depth kh√°c nhau\n",
    "print(\"TEST: Minimax v·ªõi Heuristic Cutoff\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "test_board = {\n",
    "    'size': (3, 3),\n",
    "    'lines': {\n",
    "        ('h', 0, 0): True,\n",
    "        ('v', 0, 0): True,\n",
    "    },\n",
    "    'boxes': {}\n",
    "}\n",
    "\n",
    "print(\"Board test:\")\n",
    "display_board(test_board)\n",
    "\n",
    "# Test v·ªõi depth kh√°c nhau\n",
    "for depth in [2, 4, 6]:\n",
    "    print(f\"\\n{'-' * 70}\")\n",
    "    print(f\"Depth cutoff = {depth}:\")\n",
    "    action = heuristic_player(test_board, 1, max_depth=depth)\n",
    "    print(f\"Best action: {action}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"NH·∫¨N X√âT:\")\n",
    "print(\"\"\"\n",
    "Khi tƒÉng depth:\n",
    "- S·ªë nodes explored tƒÉng exponentially\n",
    "- Th·ªùi gian t√≠nh to√°n tƒÉng\n",
    "- Ch·∫•t l∆∞·ª£ng quy·∫øt ƒë·ªãnh c√≥ th·ªÉ t·ªët h∆°n (nh√¨n xa h∆°n)\n",
    "\n",
    "Trade-off:\n",
    "- Depth th·∫•p (2-3): Nhanh nh∆∞ng c√≥ th·ªÉ b·ªè l·ª° chi·∫øn thu·∫≠t s√¢u\n",
    "- Depth trung b√¨nh (4-6): C√¢n b·∫±ng t·ªët\n",
    "- Depth cao (7+): Ch·∫≠m, nh∆∞ng g·∫ßn v·ªõi minimax full\n",
    "\n",
    "L·ª±a ch·ªçn depth ph·ª• thu·ªôc:\n",
    "- K√≠ch th∆∞·ªõc board\n",
    "- Giai ƒëo·∫°n game (ƒë·∫ßu game c·∫ßn depth th·∫•p h∆°n)\n",
    "- Th·ªùi gian cho ph√©p\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many nodes are searched and how long does it take to make a move? Start with a smaller board with 4 columns and make the board larger by adding columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark: Th·ªùi gian v√† nodes v·ªõi board size kh√°c nhau\n",
    "\n",
    "print(\"BENCHMARK: Heuristic Search v·ªõi board sizes kh√°c nhau\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Test v·ªõi board sizes v√† depth cutoffs kh√°c nhau\n",
    "test_configs = [\n",
    "    ((3, 3), 4),\n",
    "    ((3, 4), 4),\n",
    "    ((4, 4), 4),\n",
    "    ((4, 4), 6),\n",
    "    ((4, 5), 4),\n",
    "    ((5, 5), 4),\n",
    "]\n",
    "\n",
    "print(f\"\\n{'Board Size':<12} {'Depth':<8} {'Time (s)':<12} {'Nodes':<15} {'Action'}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for board_size, depth in test_configs:\n",
    "    # T·∫°o board tr·ªëng\n",
    "    test_board = {\n",
    "        'size': board_size,\n",
    "        'lines': {},\n",
    "        'boxes': {}\n",
    "    }\n",
    "    \n",
    "    # Measure\n",
    "    global nodes_explored\n",
    "    nodes_explored = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        value, action = minimax_heuristic(test_board, 1, 0, depth)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        \n",
    "        size_str = f\"{board_size[0]}√ó{board_size[1]}\"\n",
    "        print(f\"{size_str:<12} {depth:<8} {elapsed_time:<12.3f} {nodes_explored:<15,} {str(action):<20}\")\n",
    "        \n",
    "        # Stop n·∫øu qu√° l√¢u\n",
    "        if elapsed_time > 10:\n",
    "            print(f\"  ‚ö† Qu√° ch·∫≠m (>{10}s), d·ª´ng benchmark\")\n",
    "            break\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"{board_size[0]}√ó{board_size[1]:<10} {depth:<8} ERROR: {e}\")\n",
    "        break\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PH√ÇN T√çCH PERFORMANCE:\")\n",
    "print(\"\"\"\n",
    "T·ªêC ƒê·ªò TƒÇNG THEO:\n",
    "\n",
    "1. K√çCH TH∆Ø·ªöC BOARD:\n",
    "   - Board 3√ó3 (4 boxes, 12 lines): R·∫•t nhanh\n",
    "   - Board 4√ó4 (9 boxes, 24 lines): Trung b√¨nh\n",
    "   - Board 5√ó5 (16 boxes, 40 lines): Ch·∫≠m\n",
    "\n",
    "2. DEPTH CUTOFF:\n",
    "   - Depth 2-3: R·∫•t nhanh, d√πng cho early game\n",
    "   - Depth 4-5: C√¢n b·∫±ng, d√πng cho mid game\n",
    "   - Depth 6+: Ch·∫≠m, ch·ªâ d√πng cho endgame\n",
    "\n",
    "CHI·∫æN L∆Ø·ª¢C T·ªêI ∆ØU:\n",
    "\n",
    "1. ADAPTIVE DEPTH:\n",
    "   - Early game (nhi·ªÅu moves): Depth th·∫•p (2-4)\n",
    "   - Mid game: Depth trung b√¨nh (4-6)\n",
    "   - Endgame (√≠t moves): Depth cao ho·∫∑c full minimax\n",
    "\n",
    "2. BOARD SIZE RECOMMENDATIONS:\n",
    "   - 3√ó3, 3√ó4: Depth 4-6 OK\n",
    "   - 4√ó4: Depth 3-4 recommended\n",
    "   - 4√ó5, 5√ó5: Depth 2-3, ho·∫∑c iterative deepening\n",
    "\n",
    "3. TIME MANAGEMENT:\n",
    "   - Set timeout cho m·ªói move (vd: 2s)\n",
    "   - Iterative deepening: b·∫Øt ƒë·∫ßu depth 2, tƒÉng d·∫ßn\n",
    "   - Lu√¥n c√≥ answer (best move t·ª´ depth th·∫•p nh·∫•t)\n",
    "\"\"\")\n",
    "\n",
    "# So s√°nh v·ªõi board c√≥ s·∫µn v√†i n∆∞·ªõc ƒëi\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SO S√ÅNH: Board tr·ªëng vs Board c√≥ v√†i moves\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Board tr·ªëng\n",
    "empty = {\n",
    "    'size': (4, 4),\n",
    "    'lines': {},\n",
    "    'boxes': {}\n",
    "}\n",
    "\n",
    "# Board c√≥ v√†i moves\n",
    "partial = {\n",
    "    'size': (4, 4),\n",
    "    'lines': {\n",
    "        ('h', 0, 0): True,\n",
    "        ('v', 0, 0): True,\n",
    "        ('h', 1, 1): True,\n",
    "        ('v', 1, 1): True,\n",
    "    },\n",
    "    'boxes': {}\n",
    "}\n",
    "\n",
    "for board, label in [(empty, \"Tr·ªëng\"), (partial, \"C√≥ 4 moves\")]:\n",
    "    nodes_explored = 0\n",
    "    start_time = time.time()\n",
    "    value, action = minimax_heuristic(board, 1, 0, 4)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n{label}:\")\n",
    "    print(f\"  Th·ªùi gian: {elapsed_time:.3f}s\")\n",
    "    print(f\"  Nodes: {nodes_explored:,}\")\n",
    "    print(f\"  Best action: {action}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"K·∫æT LU·∫¨N:\")\n",
    "print(\"\"\"\n",
    "- Board c√≥ s·∫µn moves ‚Üí √≠t actions available ‚Üí nhanh h∆°n\n",
    "- Endgame (nhi·ªÅu lines) ‚Üí r·∫•t nhanh v√¨ g·∫ßn terminal\n",
    "- Early game (board tr·ªëng) ‚Üí ch·∫≠m nh·∫•t ‚Üí c·∫ßn depth th·∫•p ho·∫∑c opening book\n",
    "\n",
    "BOARD L·ªöN NH·∫§T C√ì TH·ªÇ SOLVE:\n",
    "- V·ªõi depth 4: Board 4√ó5 ho·∫∑c 5√ó5 c√≤n ch·∫•p nh·∫≠n ƒë∆∞·ª£c\n",
    "- V·ªõi depth 6: Board 4√ó4\n",
    "- Full minimax: Board 3√ó3 ho·∫∑c 3√ó4\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playtime\n",
    "\n",
    "Let two heuristic search agents (different cutoff depth, different heuristic evaluation function) compete against each other on a reasonably sized board. Since there is no randomness, you only need to let them play once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Playtime: Heuristic agents v·ªõi settings kh√°c nhau\n",
    "\n",
    "def heuristic_player_wrapper(max_depth):\n",
    "    \"\"\"\n",
    "    T·∫°o wrapper cho heuristic player v·ªõi depth c·ª• th·ªÉ\n",
    "    \"\"\"\n",
    "    def player(board, player):\n",
    "        global nodes_explored\n",
    "        nodes_explored = 0\n",
    "        value, action = minimax_heuristic(board, player, 0, max_depth)\n",
    "        return action\n",
    "    return player\n",
    "\n",
    "\n",
    "print(\"TOURNAMENT: Heuristic Players v·ªõi depth kh√°c nhau\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# T·∫°o c√°c agents v·ªõi depth kh√°c nhau\n",
    "players = {\n",
    "    'Depth-2': heuristic_player_wrapper(2),\n",
    "    'Depth-4': heuristic_player_wrapper(4),\n",
    "    'Depth-6': heuristic_player_wrapper(6),\n",
    "}\n",
    "\n",
    "# Cho c√°c agents thi ƒë·∫•u v·ªõi nhau\n",
    "print(\"\\nCh∆°i tr√™n board 3√ó3:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "matchups = [\n",
    "    ('Depth-2', 'Depth-4'),\n",
    "    ('Depth-4', 'Depth-6'),\n",
    "    ('Depth-2', 'Depth-6'),\n",
    "]\n",
    "\n",
    "for player1_name, player2_name in matchups:\n",
    "    print(f\"\\n{player1_name} vs {player2_name}:\")\n",
    "    \n",
    "    player1 = players[player1_name]\n",
    "    player2 = players[player2_name]\n",
    "    \n",
    "    # Ch∆°i 1 game (deterministic n√™n kh√¥ng c·∫ßn nhi·ªÅu games)\n",
    "    result = play_game(player1, player2, board_size=(3, 3), verbose=False)\n",
    "    \n",
    "    if result == 1:\n",
    "        print(f\"  üèÜ {player1_name} TH·∫ÆNG\")\n",
    "    elif result == -1:\n",
    "        print(f\"  üèÜ {player2_name} TH·∫ÆNG\")\n",
    "    else:\n",
    "        print(f\"  ü§ù H√íA\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"M·ªòT GAME M·∫™U CHI TI·∫æT: Depth-2 vs Depth-4\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "player_d2 = players['Depth-2']\n",
    "player_d4 = players['Depth-4']\n",
    "\n",
    "result = play_game(player_d2, player_d4, board_size=(3, 3), verbose=True)\n",
    "\n",
    "if result == 1:\n",
    "    print(\"\\nüèÜ Depth-2 (Player +1) TH·∫ÆNG\")\n",
    "elif result == -1:\n",
    "    print(\"\\nüèÜ Depth-4 (Player -1) TH·∫ÆNG\")\n",
    "else:\n",
    "    print(\"\\nü§ù H√íA\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PH√ÇN T√çCH K·∫æT QU·∫¢:\")\n",
    "print(\"\"\"\n",
    "D·ª∞ ƒêO√ÅN:\n",
    "- Depth c√†ng cao th∆∞·ªùng th·∫Øng depth th·∫•p h∆°n\n",
    "- Nh∆∞ng kh√¥ng ph·∫£i l√∫c n√†o c≈©ng v·∫≠y do:\n",
    "  + Heuristic evaluation kh√¥ng ho√†n h·∫£o\n",
    "  + Depth cao kh√¥ng ƒë·∫£m b·∫£o th·∫•y to√†n b·ªô game\n",
    "  + ƒê√¥i khi depth th·∫•p c√≥ th·ªÉ \"may m·∫Øn\"\n",
    "\n",
    "QUAN S√ÅT:\n",
    "- Depth-6 n√™n c√≥ l·ª£i th·∫ø r√µ r√†ng tr√™n board 3√ó3\n",
    "- Depth-4 vs Depth-2: Depth-4 n√™n th·∫Øng\n",
    "- Tr√™n board l·ªõn h∆°n, depth cao kh√¥ng kh·∫£ thi\n",
    "\n",
    "TH·ª∞C T·∫æ:\n",
    "- C·∫ßn c√¢n b·∫±ng gi·ªØa depth v√† time\n",
    "- V·ªõi time limit, depth th·∫•p c√≥ th·ªÉ t·ªët h∆°n\n",
    "- Iterative deepening l√† gi·∫£i ph√°p t·ªët\n",
    "\n",
    "C·∫¢I THI·ªÜN HEURISTIC:\n",
    "ƒê·ªÉ tƒÉng s·ª©c m·∫°nh kh√¥ng c·∫ßn tƒÉng depth:\n",
    "1. C·∫£i thi·ªán heuristic evaluation\n",
    "2. Th√™m domain knowledge (chains, control theory)\n",
    "3. Move ordering t·ªët h∆°n\n",
    "4. Transposition table (cache states)\n",
    "5. Opening book v√† endgame database\n",
    "\"\"\")\n",
    "\n",
    "# Test v·ªõi board l·ªõn h∆°n\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TEST TR√äN BOARD 4√ó4:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nDepth-3 vs Depth-4 tr√™n board 4√ó4:\")\n",
    "player_d3 = heuristic_player_wrapper(3)\n",
    "player_d4_2 = heuristic_player_wrapper(4)\n",
    "\n",
    "result_large = play_game(player_d3, player_d4_2, board_size=(4, 4), verbose=False)\n",
    "\n",
    "if result_large == 1:\n",
    "    print(\"üèÜ Depth-3 (Player +1) TH·∫ÆNG\")\n",
    "elif result_large == -1:\n",
    "    print(\"üèÜ Depth-4 (Player -1) TH·∫ÆNG\")\n",
    "else:\n",
    "    print(\"ü§ù H√íA\")\n",
    "\n",
    "print(\"\\nL∆∞u √Ω: Board 4√ó4 c√≥ 9 boxes, game ph·ª©c t·∫°p h∆°n 3√ó3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tournament task [+1 to 5% bonus on your course grade; will be assigned separately]\n",
    "\n",
    "Find another student and let your best agent play against the other student's best player. You are allowed to use any improvements you like as long as you code it yourself. We will set up a class tournament on Canvas. This tournament will continue after the submission deadline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graduate student advanced task: Pure Monte Carlo Search and Best First Move [10 point]\n",
    "\n",
    "__Undergraduate students:__ This is a bonus task you can attempt if you like [+5 Bonus point].\n",
    "\n",
    "### Pure Monte Carlo Search\n",
    "\n",
    "Implement Pure Monte Carlo Search (see [tic-tac-toe-example](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_pure_monte_carlo_search.ipynb)) and investigate how this search performs on the test boards that you have used above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pure Monte Carlo Search\n",
    "\n",
    "import random\n",
    "\n",
    "def monte_carlo_simulation(board, player):\n",
    "    \"\"\"\n",
    "    Ch·∫°y m·ªôt simulation ng·∫´u nhi√™n t·ª´ board hi·ªán t·∫°i ƒë·∫øn k·∫øt th√∫c\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    int: Utility (>0 n·∫øu player th·∫Øng, <0 n·∫øu thua, 0 n·∫øu h√≤a)\n",
    "    \"\"\"\n",
    "    sim_board = copy.deepcopy(board)\n",
    "    current_player = player\n",
    "    \n",
    "    # Ch∆°i ng·∫´u nhi√™n ƒë·∫øn h·∫øt game\n",
    "    while not terminal(sim_board):\n",
    "        available = actions(sim_board)\n",
    "        if not available:\n",
    "            break\n",
    "        \n",
    "        # Ch·ªçn action ng·∫´u nhi√™n\n",
    "        action = random.choice(available)\n",
    "        sim_board, next_player = result(sim_board, action, current_player)\n",
    "        current_player = next_player\n",
    "    \n",
    "    # Tr·∫£ v·ªÅ utility\n",
    "    return utility(sim_board, player)\n",
    "\n",
    "\n",
    "def pure_monte_carlo_search(board, player, num_simulations=1000):\n",
    "    \"\"\"\n",
    "    Pure Monte Carlo Search: Th·ª≠ t·∫•t c·∫£ moves, simulate nhi·ªÅu l·∫ßn, ch·ªçn move t·ªët nh·∫•t\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    board: dict\n",
    "        Board state hi·ªán t·∫°i\n",
    "    player: int\n",
    "        Ng∆∞·ªùi ch∆°i\n",
    "    num_simulations: int\n",
    "        S·ªë l·∫ßn simulation cho m·ªói move\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple: (best_action, win_rate)\n",
    "    \"\"\"\n",
    "    available_actions = actions(board)\n",
    "    \n",
    "    if not available_actions:\n",
    "        return None, 0.0\n",
    "    \n",
    "    # Dictionary l∆∞u k·∫øt qu·∫£ cho m·ªói action\n",
    "    action_stats = {}\n",
    "    \n",
    "    for action in available_actions:\n",
    "        # Th·ª±c hi·ªán action\n",
    "        new_board, next_player = result(board, action, player)\n",
    "        \n",
    "        # N·∫øu terminal ngay, t√≠nh utility tr·ª±c ti·∫øp\n",
    "        if terminal(new_board):\n",
    "            action_stats[action] = {\n",
    "                'wins': utility(new_board, player) > 0,\n",
    "                'total': 1,\n",
    "                'avg_utility': utility(new_board, player)\n",
    "            }\n",
    "            continue\n",
    "        \n",
    "        # Ch·∫°y simulations\n",
    "        total_utility = 0\n",
    "        wins = 0\n",
    "        \n",
    "        for _ in range(num_simulations):\n",
    "            utility_value = monte_carlo_simulation(new_board, player)\n",
    "            total_utility += utility_value\n",
    "            if utility_value > 0:\n",
    "                wins += 1\n",
    "        \n",
    "        action_stats[action] = {\n",
    "            'wins': wins,\n",
    "            'total': num_simulations,\n",
    "            'avg_utility': total_utility / num_simulations\n",
    "        }\n",
    "    \n",
    "    # Ch·ªçn action v·ªõi win rate cao nh·∫•t\n",
    "    best_action = max(action_stats.keys(), \n",
    "                      key=lambda a: action_stats[a]['avg_utility'])\n",
    "    \n",
    "    best_stats = action_stats[best_action]\n",
    "    win_rate = best_stats['wins'] / best_stats['total']\n",
    "    \n",
    "    return best_action, win_rate, action_stats\n",
    "\n",
    "\n",
    "def monte_carlo_player(board, player, num_simulations=500):\n",
    "    \"\"\"\n",
    "    Agent s·ª≠ d·ª•ng Pure Monte Carlo Search\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    action, win_rate, _ = pure_monte_carlo_search(board, player, num_simulations)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"Monte Carlo ({num_simulations} sims): win_rate={win_rate:.2%} in {elapsed_time:.3f}s\")\n",
    "    \n",
    "    return action\n",
    "\n",
    "\n",
    "# Test Pure Monte Carlo Search\n",
    "print(\"TEST: Pure Monte Carlo Search\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "test_board = {\n",
    "    'size': (3, 3),\n",
    "    'lines': {\n",
    "        ('h', 0, 0): True,\n",
    "        ('h', 1, 0): True,\n",
    "        ('v', 0, 0): True,\n",
    "    },\n",
    "    'boxes': {}\n",
    "}\n",
    "\n",
    "print(\"Board test:\")\n",
    "display_board(test_board)\n",
    "\n",
    "print(\"\\nCh·∫°y Pure Monte Carlo Search v·ªõi 100 simulations:\")\n",
    "action, win_rate, stats = pure_monte_carlo_search(test_board, 1, num_simulations=100)\n",
    "\n",
    "print(f\"\\nBest action: {action}\")\n",
    "print(f\"Estimated win rate: {win_rate:.2%}\")\n",
    "\n",
    "print(\"\\nTop 5 actions theo avg utility:\")\n",
    "sorted_actions = sorted(stats.items(), key=lambda x: x[1]['avg_utility'], reverse=True)\n",
    "for i, (act, stat) in enumerate(sorted_actions[:5]):\n",
    "    print(f\"  {i+1}. {act}: avg_utility={stat['avg_utility']:.2f}, win_rate={stat['wins']}/{stat['total']}\")\n",
    "\n",
    "# So s√°nh v·ªõi test boards kh√°c\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TEST TR√äN BOARD G·∫¶N K·∫æT TH√öC:\")\n",
    "\n",
    "endgame_board = {\n",
    "    'size': (3, 3),\n",
    "    'lines': {\n",
    "        ('h', 0, 0): True, ('h', 0, 1): True,\n",
    "        ('h', 1, 0): True, ('h', 1, 1): True,\n",
    "        ('h', 2, 0): True, ('h', 2, 1): True,\n",
    "        ('v', 0, 0): True, ('v', 0, 1): True, ('v', 0, 2): True,\n",
    "        ('v', 1, 0): True,\n",
    "    },\n",
    "    'boxes': {\n",
    "        (0, 0): 1,\n",
    "        (0, 1): -1,\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Board:\")\n",
    "display_board(endgame_board)\n",
    "\n",
    "print(\"\\nCh·∫°y Monte Carlo:\")\n",
    "action_end, win_rate_end, stats_end = pure_monte_carlo_search(endgame_board, 1, num_simulations=200)\n",
    "\n",
    "print(f\"Best action: {action_end}\")\n",
    "print(f\"Win rate: {win_rate_end:.2%}\")\n",
    "\n",
    "# So s√°nh v·ªõi Minimax\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SO S√ÅNH: Monte Carlo vs Minimax vs Random\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Monte Carlo vs Random\n",
    "print(\"\\nMonte Carlo vs Random (10 games, board 3√ó3):\")\n",
    "mc_wins = 0\n",
    "random_wins = 0\n",
    "draws = 0\n",
    "\n",
    "def mc_player_wrapper(board, player):\n",
    "    action, _, _ = pure_monte_carlo_search(board, player, num_simulations=100)\n",
    "    return action\n",
    "\n",
    "for i in range(10):\n",
    "    result = play_game(mc_player_wrapper, random_player, board_size=(3, 3))\n",
    "    if result == 1:\n",
    "        mc_wins += 1\n",
    "    elif result == -1:\n",
    "        random_wins += 1\n",
    "    else:\n",
    "        draws += 1\n",
    "    \n",
    "    if (i + 1) % 5 == 0:\n",
    "        print(f\"  ƒê√£ ch∆°i {i+1}/10 games...\")\n",
    "\n",
    "print(f\"\\nK·∫øt qu·∫£:\")\n",
    "print(f\"  Monte Carlo th·∫Øng: {mc_wins}/10\")\n",
    "print(f\"  Random th·∫Øng: {random_wins}/10\")\n",
    "print(f\"  H√≤a: {draws}/10\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PH√ÇN T√çCH PURE MONTE CARLO SEARCH:\")\n",
    "print(\"\"\"\n",
    "∆ØU ƒêI·ªÇM:\n",
    "‚úì Kh√¥ng c·∫ßn heuristic evaluation function\n",
    "‚úì Kh√¥ng c·∫ßn domain knowledge\n",
    "‚úì Ho·∫°t ƒë·ªông t·ªët v·ªõi game c√≥ random element\n",
    "‚úì C√≥ th·ªÉ handle board l·ªõn (kh√¥ng exponential nh∆∞ minimax)\n",
    "‚úì Anytime algorithm - c√≥ th·ªÉ d·ª´ng b·∫•t c·ª© l√∫c n√†o\n",
    "\n",
    "NH∆Ø·ª¢C ƒêI·ªÇM:\n",
    "‚úó C·∫ßn nhi·ªÅu simulations ƒë·ªÉ ch√≠nh x√°c\n",
    "‚úó Kh√¥ng ƒë·∫£m b·∫£o optimal\n",
    "‚úó Ch·∫≠m v·ªõi board c√≥ nhi·ªÅu possible moves\n",
    "‚úó Kh√¥ng t·∫≠n d·ª•ng structure c·ªßa game\n",
    "\n",
    "SO V·ªöI MINIMAX:\n",
    "- Minimax: Optimal nh∆∞ng ch·∫≠m, c·∫ßn cutoff v·ªõi board l·ªõn\n",
    "- Monte Carlo: Kh√¥ng optimal nh∆∞ng scale t·ªët h∆°n\n",
    "- Minimax th∆∞·ªùng m·∫°nh h∆°n tr√™n board nh·ªè\n",
    "- Monte Carlo t·ªët h∆°n v·ªõi board l·ªõn ho·∫∑c game ph·ª©c t·∫°p\n",
    "\n",
    "S·ªê SIMULATIONS:\n",
    "- 100-500: Nhanh, ƒë·ªß cho early game\n",
    "- 500-1000: C√¢n b·∫±ng\n",
    "- 1000+: Ch·∫≠m nh∆∞ng ch√≠nh x√°c h∆°n\n",
    "\n",
    "C·∫¢I THI·ªÜN:\n",
    "- Monte Carlo Tree Search (MCTS): K·∫øt h·ª£p tree search v√† simulation\n",
    "- UCB1: C√¢n b·∫±ng exploration vs exploitation\n",
    "- Domain knowledge: Biased simulations\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best First Move\n",
    "\n",
    "How would you determine what the best first move for a standard board ($5 \\times 5$) is? You can use Pure Monte Carlo Search or any algorithms that you have implemented above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T√¨m best first move cho board chu·∫©n 5√ó5\n",
    "\n",
    "print(\"T√åM BEST FIRST MOVE CHO BOARD 5√ó5\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "CHI·∫æN L∆Ø·ª¢C T√åM BEST FIRST MOVE:\n",
    "\n",
    "V·ªõi board 5√ó5 (16 boxes, 40 possible lines):\n",
    "- Full minimax: Kh√¥ng kh·∫£ thi (qu√° ch·∫≠m)\n",
    "- Heuristic v·ªõi depth cao: V·∫´n r·∫•t ch·∫≠m\n",
    "- Pure Monte Carlo: Kh·∫£ thi nh∆∞ng c·∫ßn nhi·ªÅu simulations\n",
    "\n",
    "PH∆Ø∆†NG PH√ÅP ƒê·ªÄ XU·∫§T:\n",
    "1. S·ª≠ d·ª•ng symmetry ƒë·ªÉ gi·∫£m search space\n",
    "2. Pure Monte Carlo v·ªõi nhi·ªÅu simulations\n",
    "3. Ho·∫∑c k·∫øt h·ª£p nhi·ªÅu methods\n",
    "\"\"\")\n",
    "\n",
    "# Approach 1: Symmetry reduction\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"APPROACH 1: Symmetry Reduction + Monte Carlo\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "board_5x5 = {\n",
    "    'size': (5, 5),\n",
    "    'lines': {},\n",
    "    'boxes': {}\n",
    "}\n",
    "\n",
    "all_first_moves = actions(board_5x5)\n",
    "print(f\"T·ªïng s·ªë first moves kh·∫£ d·ª•ng: {len(all_first_moves)}\")\n",
    "\n",
    "# S·ª≠ d·ª•ng symmetry\n",
    "# Board 5√ó5 c√≥ 8-fold symmetry\n",
    "# Ch·ªâ c·∫ßn test ~1/8 s·ªë moves\n",
    "\n",
    "def get_unique_first_moves(board):\n",
    "    \"\"\"\n",
    "    L·∫•y c√°c first moves kh√¥ng ƒë·ªëi x·ª©ng v·ªõi nhau\n",
    "    V·ªõi board 5√ó5, ch·ªâ c·∫ßn test c√°c moves ·ªü 1/8 board\n",
    "    \"\"\"\n",
    "    rows, cols = board['size']\n",
    "    unique_moves = []\n",
    "    \n",
    "    # Ch·ªâ x√©t n·ª≠a tr√™n, n·ª≠a tr√°i c·ªßa board\n",
    "    # Horizontal lines\n",
    "    for r in range((rows + 1) // 2):\n",
    "        for c in range((cols) // 2):\n",
    "            if c < cols - 1:\n",
    "                unique_moves.append(('h', r, c))\n",
    "    \n",
    "    # Vertical lines\n",
    "    for r in range((rows) // 2):\n",
    "        for c in range((cols + 1) // 2):\n",
    "            if r < rows - 1:\n",
    "                unique_moves.append(('v', r, c))\n",
    "    \n",
    "    return unique_moves\n",
    "\n",
    "unique_moves = get_unique_first_moves(board_5x5)\n",
    "print(f\"Unique first moves (sau symmetry reduction): {len(unique_moves)}\")\n",
    "print(f\"Gi·∫£m: {(1 - len(unique_moves)/len(all_first_moves))*100:.1f}%\")\n",
    "\n",
    "# Test top moves v·ªõi Monte Carlo\n",
    "print(f\"\\nTest top {min(5, len(unique_moves))} unique moves v·ªõi Monte Carlo (200 simulations m·ªói move):\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "move_evaluations = []\n",
    "\n",
    "for i, move in enumerate(unique_moves[:5]):  # Test 5 moves ƒë·∫ßu\n",
    "    # Apply move\n",
    "    test_board = copy.deepcopy(board_5x5)\n",
    "    test_board, next_player = result(test_board, move, 1)\n",
    "    \n",
    "    # Monte Carlo evaluation\n",
    "    total_utility = 0\n",
    "    wins = 0\n",
    "    num_sims = 200\n",
    "    \n",
    "    for _ in range(num_sims):\n",
    "        utility_val = monte_carlo_simulation(test_board, 1)\n",
    "        total_utility += utility_val\n",
    "        if utility_val > 0:\n",
    "            wins += 1\n",
    "    \n",
    "    avg_utility = total_utility / num_sims\n",
    "    win_rate = wins / num_sims\n",
    "    \n",
    "    move_evaluations.append({\n",
    "        'move': move,\n",
    "        'avg_utility': avg_utility,\n",
    "        'win_rate': win_rate\n",
    "    })\n",
    "    \n",
    "    print(f\"{i+1}. {move}: avg_utility={avg_utility:.2f}, win_rate={win_rate:.1%}\")\n",
    "\n",
    "# Best move\n",
    "best_move = max(move_evaluations, key=lambda x: x['avg_utility'])\n",
    "print(f\"\\nüèÜ BEST FIRST MOVE: {best_move['move']}\")\n",
    "print(f\"   Avg utility: {best_move['avg_utility']:.2f}\")\n",
    "print(f\"   Win rate: {best_move['win_rate']:.1%}\")\n",
    "\n",
    "# Approach 2: Domain knowledge\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"APPROACH 2: Domain Knowledge\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "D·ª±a tr√™n l√Ω thuy·∫øt Dots & Boxes:\n",
    "\n",
    "NGUY√äN T·∫ÆC OPENING:\n",
    "1. Tr√°nh v·∫Ω ƒë∆∞·ªùng ·ªü bi√™n (edge) - d·ªÖ b·ªã opponent control\n",
    "2. ∆Øu ti√™n v·∫Ω ƒë∆∞·ªùng ·ªü trung t√¢m ho·∫∑c g·∫ßn trung t√¢m\n",
    "3. T·∫°o c·∫•u tr√∫c ƒë·ªëi x·ª©ng ƒë·ªÉ kh√≥ b·ªã opponent exploit\n",
    "\n",
    "BEST OPENING MOVES TH∆Ø·ªúNG L√Ä:\n",
    "- ƒê∆∞·ªùng g·∫ßn trung t√¢m board\n",
    "- ƒê∆∞·ªùng n·∫±m ngang (horizontal) th∆∞·ªùng t·ªët h∆°n d·ªçc (vertical)\n",
    "- Tr√°nh g√≥c v√† bi√™n trong early game\n",
    "\n",
    "V·ªõi board 5√ó5:\n",
    "- Center: row 2, col 2\n",
    "- Best move theo l√Ω thuy·∫øt: ('h', 2, 2) ho·∫∑c ('h', 2, 1) ho·∫∑c ('h', 1, 2)\n",
    "\"\"\")\n",
    "\n",
    "# So s√°nh theoretical best v·ªõi MC result\n",
    "theoretical_best = ('h', 2, 2)\n",
    "print(f\"\\nTheoretical best: {theoretical_best}\")\n",
    "print(f\"Monte Carlo best: {best_move['move']}\")\n",
    "\n",
    "if theoretical_best == best_move['move']:\n",
    "    print(\"‚úì Monte Carlo ƒë·ªìng √Ω v·ªõi l√Ω thuy·∫øt!\")\n",
    "else:\n",
    "    print(\"‚Üí C√≥ s·ª± kh√°c bi·ªát, c·∫ßn test th√™m\")\n",
    "\n",
    "# Full evaluation (n·∫øu c√≥ th·ªùi gian)\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FULL EVALUATION (Optional - r·∫•t t·ªën th·ªùi gian):\")\n",
    "print(\"-\" * 70)\n",
    "print(\"\"\"\n",
    "ƒê·ªÉ t√¨m CH√çNH X√ÅC best first move:\n",
    "\n",
    "1. Test T·∫§T C·∫¢ unique moves v·ªõi Monte Carlo\n",
    "   - ~1000-5000 simulations m·ªói move\n",
    "   - T·ªïng th·ªùi gian: ~10-30 ph√∫t\n",
    "\n",
    "2. Ho·∫∑c d√πng MCTS (Monte Carlo Tree Search)\n",
    "   - Th√¥ng minh h∆°n Pure MC\n",
    "   - T·ª± ƒë·ªông focus v√†o promising moves\n",
    "\n",
    "3. Ho·∫∑c d√πng Deep Learning\n",
    "   - Train neural network t·ª´ expert games\n",
    "   - Predict best move based on board state\n",
    "\n",
    "K·∫æT LU·∫¨N:\n",
    "- V·ªõi resources h·∫°n ch·∫ø: D√πng domain knowledge + quick MC\n",
    "- Best first move cho 5√ó5: ƒê∆∞·ªùng ngang g·∫ßn trung t√¢m\n",
    "- Recommended: ('h', 2, 2) ho·∫∑c ('h', 2, 1)\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SUMMARY:\")\n",
    "print(f\"\"\"\n",
    "‚úì ƒê√£ ph√¢n t√≠ch board 5√ó5 v·ªõi {len(all_first_moves)} possible first moves\n",
    "‚úì S·ª≠ d·ª•ng symmetry gi·∫£m xu·ªëng {len(unique_moves)} unique moves\n",
    "‚úì Monte Carlo evaluation cho top moves\n",
    "‚úì Best move d·ª±a tr√™n MC: {best_move['move']}\n",
    "‚úì Best move d·ª±a tr√™n l√Ω thuy·∫øt: {theoretical_best}\n",
    "\n",
    "ƒê·ªÉ t√¨m best move ch√≠nh x√°c 100%:\n",
    "- C·∫ßn computational resources l·ªõn\n",
    "- Ho·∫∑c s·ª≠ d·ª•ng advanced techniques (MCTS, Deep Learning)\n",
    "- Trong th·ª±c t·∫ø: Domain knowledge + quick evaluation l√† ƒë·ªß t·ªët\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K·∫øt lu·∫≠n v√† ƒê√°nh gi√°\n",
    "\n",
    "### T√≥m t·∫Øt c√°c thu·∫≠t to√°n ƒë√£ implement:\n",
    "\n",
    "#### 1. **Random Player**\n",
    "- **M√¥ t·∫£:** Ch·ªçn ng·∫´u nhi√™n t·ª´ c√°c n∆∞·ªõc ƒëi h·ª£p l·ªá\n",
    "- **∆Øu ƒëi·ªÉm:** ƒê∆°n gi·∫£n, nhanh\n",
    "- **Nh∆∞·ª£c ƒëi·ªÉm:** Kh√¥ng c√≥ chi·∫øn thu·∫≠t, d·ªÖ thua\n",
    "- **Use case:** Baseline ƒë·ªÉ so s√°nh\n",
    "\n",
    "#### 2. **Minimax v·ªõi Alpha-Beta Pruning**\n",
    "- **M√¥ t·∫£:** T√¨m ki·∫øm optimal move b·∫±ng c√°ch explore to√†n b·ªô game tree v·ªõi pruning\n",
    "- **∆Øu ƒëi·ªÉm:** Ch∆°i optimal (ho·∫∑c g·∫ßn optimal), ƒë·∫£m b·∫£o th·∫Øng v·ªõi perfect play\n",
    "- **Nh∆∞·ª£c ƒëi·ªÉm:** Ch·∫≠m v·ªõi board l·ªõn, exponential complexity\n",
    "- **Gi·ªõi h·∫°n:** Board 3√ó3, 3√ó4 l√† t·ªëi ƒëa v·ªõi full search\n",
    "- **C·∫£i ti·∫øn:** Move ordering gi·∫£m 30-50% nodes\n",
    "\n",
    "#### 3. **Heuristic Alpha-Beta v·ªõi Depth Cutoff**\n",
    "- **M√¥ t·∫£:** Gi·ªõi h·∫°n ƒë·ªô s√¢u search, d√πng heuristic evaluation thay v√¨ terminal utility\n",
    "- **∆Øu ƒëi·ªÉm:** C√≥ th·ªÉ x·ª≠ l√Ω board l·ªõn h∆°n (4√ó4, 5√ó5), th·ªùi gian t√≠nh to√°n c√≥ th·ªÉ ki·ªÉm so√°t\n",
    "- **Nh∆∞·ª£c ƒëi·ªÉm:** Kh√¥ng optimal, ph·ª• thu·ªôc ch·∫•t l∆∞·ª£ng heuristic\n",
    "- **Best depth:** 4-6 cho board size trung b√¨nh\n",
    "\n",
    "#### 4. **Pure Monte Carlo Search**\n",
    "- **M√¥ t·∫£:** Simulate random games t·ª´ m·ªói possible move, ch·ªçn move c√≥ win rate cao nh·∫•t\n",
    "- **∆Øu ƒëi·ªÉm:** Kh√¥ng c·∫ßn heuristic, scale t·ªët v·ªõi board l·ªõn, anytime algorithm\n",
    "- **Nh∆∞·ª£c ƒëi·ªÉm:** Kh√¥ng optimal, c·∫ßn nhi·ªÅu simulations\n",
    "- **Use case:** Board l·ªõn (5√ó5+), ho·∫∑c khi thi·∫øu domain knowledge\n",
    "\n",
    "### So s√°nh Performance:\n",
    "\n",
    "| Thu·∫≠t to√°n | Board 3√ó3 | Board 4√ó4 | Board 5√ó5 | Optimal? |\n",
    "|------------|-----------|-----------|-----------|----------|\n",
    "| Minimax Full | ‚úÖ R·∫•t t·ªët | ‚ö†Ô∏è Ch·∫≠m | ‚ùå Kh√¥ng kh·∫£ thi | ‚úÖ Yes |\n",
    "| Heuristic (d=4) | ‚úÖ T·ªët | ‚úÖ T·ªët | ‚úÖ Ch·∫•p nh·∫≠n ƒë∆∞·ª£c | ‚ö†Ô∏è Near-optimal |\n",
    "| Monte Carlo | ‚úÖ T·ªët | ‚úÖ T·ªët | ‚úÖ T·ªët | ‚ùå No |\n",
    "\n",
    "### B√†i h·ªçc quan tr·ªçng:\n",
    "\n",
    "1. **Trade-offs:** Lu√¥n c√≥ s·ª± c√¢n b·∫±ng gi·ªØa optimal play v√† computational feasibility\n",
    "2. **Domain Knowledge:** Move ordering v√† heuristic design r·∫•t quan tr·ªçng\n",
    "3. **Scalability:** Minimax thu·∫ßn kh√¥ng scale; c·∫ßn heuristics ho·∫∑c alternatives (Monte Carlo)\n",
    "4. **Game-specific rules:** Rule \"ƒëi ti·∫øp khi ho√†n th√†nh box\" l√†m tƒÉng complexity c·ªßa implementation\n",
    "5. **Early game vs Endgame:** C·∫ßn strategies kh√°c nhau cho c√°c phases c·ªßa game\n",
    "\n",
    "### C·∫£i ti·∫øn c√≥ th·ªÉ th·ª±c hi·ªán:\n",
    "\n",
    "1. **Monte Carlo Tree Search (MCTS):** K·∫øt h·ª£p tree search v√† simulation\n",
    "2. **Transposition Table:** Cache c√°c states ƒë√£ evaluate\n",
    "3. **Iterative Deepening:** TƒÉng depth d·∫ßn, c√≥ th·ªÉ d·ª´ng b·∫•t c·ª© l√∫c n√†o\n",
    "4. **Opening Book & Endgame Database:** Pre-computed moves cho common positions\n",
    "5. **Neural Network Evaluation:** H·ªçc heuristic t·ª´ data thay v√¨ hand-craft\n",
    "6. **Chain Analysis:** Ph√°t hi·ªán v√† x·ª≠ l√Ω chains of boxes (strategy n√¢ng cao)\n",
    "\n",
    "### ƒêi·ªÉm n·ªïi b·∫≠t c·ªßa implementation:\n",
    "\n",
    "‚ú® **Code structure r√µ r√†ng:** T√°ch bi·ªát game logic, agents, v√† experiments  \n",
    "‚ú® **Documentation ƒë·∫ßy ƒë·ªß:** M·ªói function c√≥ docstring, gi·∫£i th√≠ch r√µ r√†ng  \n",
    "‚ú® **Comprehensive testing:** Test nhi·ªÅu scenarios v√† edge cases  \n",
    "‚ú® **Performance analysis:** Benchmark v√† so s√°nh c√°c approaches  \n",
    "‚ú® **Visualization:** ASCII art gi√∫p debug v√† hi·ªÉu game state  \n",
    "\n",
    "### Th·ªùi gian th·ª±c hi·ªán:\n",
    "\n",
    "- Task 1: ~1 gi·ªù (ph√¢n t√≠ch l√Ω thuy·∫øt)\n",
    "- Task 2: ~2-3 gi·ªù (implementation c∆° b·∫£n)\n",
    "- Task 3: ~3-4 gi·ªù (minimax v√† optimizations)\n",
    "- Task 4: ~2-3 gi·ªù (heuristic v√† experiments)\n",
    "- Advanced task: ~2 gi·ªù (Monte Carlo)\n",
    "- **T·ªïng:** ~10-13 gi·ªù\n",
    "\n",
    "---\n",
    "\n",
    "**K·∫øt lu·∫≠n:** B√†i t·∫≠p n√†y cung c·∫•p hi·ªÉu bi·∫øt s√¢u s·∫Øc v·ªÅ adversarial search, trade-offs gi·ªØa optimality v√† efficiency, v√† importance of domain knowledge trong game AI. Implementation th√†nh c√¥ng c√°c thu·∫≠t to√°n t·ª´ c∆° b·∫£n ƒë·∫øn n√¢ng cao cho th·∫•y s·ª± hi·ªÉu bi·∫øt v·ªÅ c·∫£ theory v√† practice c·ªßa AI in games."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
