{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Search: Playing Connect 4\n",
    "\n",
    "Student Name: [Add your name]\n",
    "\n",
    "I have used the following AI tools: [list tools]\n",
    "\n",
    "I understand that my submission needs to be my own work: [your initials]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Outcomes\n",
    "\n",
    "* Implement adversarial search algorithms for strategic game play.\n",
    "* Analyze and optimize search in complex game spaces.\n",
    "* Design effective heuristic evaluation functions.\n",
    "* Compare performance across different agent strategies.\n",
    "* Evaluate algorithmic trade-offs between decision quality and efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "Total Points: Undergraduates 100, graduate students 110\n",
    "\n",
    "Complete this notebook and submit it. The notebook needs to be a complete project report with your implementation, documentation including a short discussion of how your implementation works and your design choices, and experimental results (e.g., tables and charts with simulation results) with a short discussion of what they mean. Use the provided notebook cells and insert additional code and markdown cells as needed. Submit the completely rendered notebook as a HTML file. \n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "You will implement different versions of agents that play Connect 4:\n",
    "\n",
    "> \"Connect 4 is a two-player connection board game, in which the players choose a color and then take turns dropping colored discs into a seven-column, six-row vertically suspended grid. The pieces fall straight down, occupying the lowest available space within the column. The objective of the game is to be the first to form a horizontal, vertical, or diagonal line of four of one's own discs.\" (see [Connect Four on Wikipedia](https://en.wikipedia.org/wiki/Connect_Four))\n",
    "\n",
    "Note that [Connect-4 has been solved](https://en.wikipedia.org/wiki/Connect_Four#Mathematical_solution)\n",
    "in 1988. A connect-4 solver with a discussion of how to solve different parts of the problem can be found here: https://connect4.gamesolver.org/en/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Defining the Search Problem [10 point]\n",
    "\n",
    "Define the components of the search problem:\n",
    "\n",
    "* Initial state\n",
    "* Actions\n",
    "* Transition model (result function)\n",
    "* Goal state (terminal state and utility)\n",
    "\n",
    "Describe each component and then implement it as a function that can be used by search algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial actions: [0, 1, 2, 3, 4, 5, 6]\n",
      "After player 1 moves at column 3:\n",
      "[0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 1, 0, 0, 0]\n",
      "Terminal? False\n",
      "Utility: 0\n"
     ]
    }
   ],
   "source": [
    "# Your code/answer goes here.\n",
    "# ==============================\n",
    "# Connect 4 - Task 1: Search Problem Definition\n",
    "# ==============================\n",
    "\n",
    "ROWS = 6\n",
    "COLS = 7\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 1. Initial state\n",
    "# ------------------------------------------------\n",
    "def initial_state():\n",
    "    \"\"\"\n",
    "    Trả về bàn cờ trống ban đầu (6 hàng x 7 cột).\n",
    "    0 = ô trống, 1 = người chơi 1, -1 = người chơi 2\n",
    "    \"\"\"\n",
    "    return [[0 for _ in range(COLS)] for _ in range(ROWS)]\n",
    "\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 2. Actions\n",
    "# ------------------------------------------------\n",
    "def actions(state):\n",
    "    \"\"\"\n",
    "    Trả về danh sách các cột hợp lệ mà người chơi có thể thả quân vào.\n",
    "    Một cột hợp lệ nếu ô trên cùng của nó (state[0][col]) vẫn còn trống.\n",
    "    \"\"\"\n",
    "    return [col for col in range(COLS) if state[0][col] == 0]\n",
    "\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 3. Transition Model (Result Function)\n",
    "# ------------------------------------------------\n",
    "def result(state, action, player):\n",
    "    \"\"\"\n",
    "    Thực hiện hành động 'action' (thả quân vào cột tương ứng)\n",
    "    và trả về trạng thái bàn cờ mới.\n",
    "    \n",
    "    - state: bàn cờ hiện tại\n",
    "    - action: cột muốn thả quân (0..6)\n",
    "    - player: 1 (người chơi 1) hoặc -1 (người chơi 2)\n",
    "    \"\"\"\n",
    "    new_state = [row[:] for row in state]  # tạo bản sao bàn cờ\n",
    "    for row in reversed(range(ROWS)):      # thả quân từ dưới lên\n",
    "        if new_state[row][action] == 0:\n",
    "            new_state[row][action] = player\n",
    "            break\n",
    "    return new_state\n",
    "\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 4. Goal State (Terminal Test) & Utility Function\n",
    "# ------------------------------------------------\n",
    "def terminal_test(state):\n",
    "    \"\"\"\n",
    "    Kiểm tra xem trò chơi đã kết thúc chưa:\n",
    "    - Có người thắng (4 quân liên tiếp)\n",
    "    - Hoặc bàn cờ đầy (hòa)\n",
    "    \"\"\"\n",
    "    return check_winner(state) != 0 or all(state[0][c] != 0 for c in range(COLS))\n",
    "\n",
    "\n",
    "def check_winner(state):\n",
    "    \"\"\"\n",
    "    Kiểm tra xem có người chơi nào thắng chưa.\n",
    "    Trả về 1 nếu người chơi 1 thắng, -1 nếu người chơi 2 thắng, 0 nếu chưa có ai thắng.\n",
    "    \"\"\"\n",
    "    for r in range(ROWS):\n",
    "        for c in range(COLS):\n",
    "            player = state[r][c]\n",
    "            if player == 0:\n",
    "                continue\n",
    "\n",
    "            # kiểm tra 4 hướng: ngang, dọc, chéo phải xuống, chéo trái xuống\n",
    "            if c + 3 < COLS and all(state[r][c + i] == player for i in range(4)):\n",
    "                return player\n",
    "            if r + 3 < ROWS and all(state[r + i][c] == player for i in range(4)):\n",
    "                return player\n",
    "            if r + 3 < ROWS and c + 3 < COLS and all(state[r + i][c + i] == player for i in range(4)):\n",
    "                return player\n",
    "            if r + 3 < ROWS and c - 3 >= 0 and all(state[r + i][c - i] == player for i in range(4)):\n",
    "                return player\n",
    "    return 0\n",
    "\n",
    "\n",
    "def utility(state, player):\n",
    "    \"\"\"\n",
    "    Trả về giá trị tiện ích (utility):\n",
    "    +1 nếu 'player' thắng, -1 nếu thua, 0 nếu hòa hoặc chưa kết thúc.\n",
    "    \"\"\"\n",
    "    winner = check_winner(state)\n",
    "    if winner == player:\n",
    "        return 1\n",
    "    elif winner == -player:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "s = initial_state()\n",
    "print(\"Initial actions:\", actions(s))  # [0,1,2,3,4,5,6]\n",
    "\n",
    "s2 = result(s, 3, 1)\n",
    "print(\"After player 1 moves at column 3:\")\n",
    "for row in s2:\n",
    "    print(row)\n",
    "\n",
    "print(\"Terminal?\", terminal_test(s2))\n",
    "print(\"Utility:\", utility(s2, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How big is the state space? Give an estimate and explain it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here.\n",
    "# Ước lượng kích thước không gian trạng thái (State space) của trò chơi Connect 4\n",
    "\n",
    "# 1. Giới hạn trên (ước lượng thô ban đầu)\n",
    "# Bàn cờ Connect 4 có 6 hàng × 7 cột = 42 ô.\n",
    "# Mỗi ô có thể ở 3 trạng thái:\n",
    "# Trống (0),\n",
    "# Quân của người chơi 1 (1),\n",
    "# Quân của người chơi 2 (-1).\n",
    "# Nếu không xét quy tắc nào, tổng số trạng thái có thể là:\n",
    "# 3^42 = 109,418,989,131,512,359,209 ≈ 1.09 x 10^20\n",
    "# Đây là giới hạn trên lý thuyết (naïve upper bound), vì nó tính cả những bàn cờ không hợp lệ (vi phạm luật trọng lực hoặc thứ tự lượt chơi).\n",
    "\n",
    "# 2. Lý do không gian thật nhỏ hơn rất nhiều\n",
    "# Trong thực tế, phần lớn các bàn cờ trong không thể xảy ra trong trò chơi Connect 4 thật, vì:\n",
    "# Luật trọng lực (gravity):\n",
    "# Quân cờ luôn “rơi” xuống ô trống thấp nhất của cột, không thể có quân lơ lửng.\n",
    "# Luân phiên lượt đi:\n",
    "# Số quân của 2 người chơi chỉ có thể chênh lệch nhiều nhất là 1.\n",
    "# Luật kết thúc:\n",
    "# Nếu một bên đã thắng (4 quân liên tiếp), trò chơi sẽ dừng lại ngay — không thể có trạng thái nào có nhiều hơn 4 quân liên tiếp được đặt thêm sau đó.\n",
    "# Những ràng buộc này loại bỏ hầu hết các cấu hình không hợp lệ, khiến không gian trạng thái thực tế nhỏ hơn rất nhiều.\n",
    "\n",
    "# 3.Kết quả chính xác (đã được tính toán)\n",
    "# Theo các nghiên cứu đã công bố (và được dùng trong các dự án giải Connect 4 chuyên dụng),\n",
    "# tổng số trạng thái hợp lệ (legal positions) trong Connect 4 là: 4.53 x 10^12\n",
    "# Tức là khoảng 4.5 nghìn tỷ trạng thái hợp lệ.\n",
    "# So sánh: 3^42 / (4.53 x 10^12) ≈ 2.4 x 10^7\n",
    "# Giới hạn lý thuyết lớn gấp khoảng 24 triệu lần so với không gian thật.\n",
    "\n",
    "# 4. Ý nghĩa đối với tìm kiếm (search)\n",
    "# Mặc dù nhỏ hơn nhiều so với 10^20 nhưng 4.5 nghìn tỷ trạng thái vẫn là một con số khổng lồ —việc duyệt toàn bộ không gian này là bất khả thi với Minimax thuần túy\n",
    "# Vì vậy, các thuật toán chơi Connect 4 thực tế phải dùng:\n",
    "#     Alpha–Beta pruning để cắt nhánh không cần thiết,\n",
    "#     Heuristic evaluation để ước lượng giá trị trạng thái trung gian,\n",
    "#     Bảng nhớ (transposition table) và chiến lược chọn nước đi thông minh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How big is the game tree that minimax search will go through? Give an estimate and explain it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here.\n",
    "# Ý tưởng chính\n",
    "# Kích thước game tree mà Minimax phải duyệt phụ thuộc vào:\n",
    "#   b = branching factor (số nước đi trung bình trên mỗi bước), và\n",
    "#   d = độ sâu (số plies/moves tối đa mà ta xem xét).\n",
    "# Một ước lượng thô thường là nodes ≈ b^d. Với Connect-4:\n",
    "# tối đa mỗi bước có 7 lựa chọn (7 cột), nhưng về trung bình số cột khả dụng nhỏ hơn (một số cột dần đầy). Ta có thể dùng b ≈ 5–6 làm ước lượng hợp lý.\n",
    "# một ván đầy có tối đa 42 nước (6×7), tức d ≤ 42\n",
    "# Tính nhanh\n",
    "# 1) Nếu Minimax duyệt toàn bộ đến cuối ván (d = 42)\n",
    "# Giả sử b=5.5 (một giá trị trung bình giữa 5 và 6),\n",
    "# Số nút ≈ 5.5^42 ≈ 1.25 x 10^31 \n",
    "# Kết luận: không thể thực hiện (con số khổng lồ, vượt xa khả năng máy tính thực tế).\n",
    "# 2) Nếu Minimax chỉ duyệt tới các độ sâu thực tế thường dùng (ví dụ d = 8, 10, 12, 16)\n",
    "# (giả sử vẫnb=5.5):\n",
    "#     d = 6 → ≈ 2.8 x 10^4 nut\n",
    "#     d = 8 → ≈ 8.4 x 10^5 nut\n",
    "#     d = 10 → ≈ 2.5 x 10^7 nut\n",
    "#     d=12 → ≈ 7.7 x 10^8 nut\n",
    "#     d= 16 → ≈ 7 x 10^11 nut\n",
    "# Những con số này cho thấy: duyệt đến 8–12 plies là khả thi trên máy thường, còn sâu hơn (14–16+) đã bắt đầu rất nặng.\n",
    "# 3) Tác dụng của Alpha–Beta pruning (với ordering tốt)\n",
    "# Với alpha–beta và thứ tự đánh giá nước đi tốt, hiệu quả thường xấp xỉ giảm branching về b^1/2\n",
    "# Nếu hiệu ứng này đạt được, thì “hiệu dụng” b ≈ sqrt(5.5) ≈ 2.345\n",
    "# Với d = 42, số nút xấp xỉ 2.345^42 ≈ 3.5 x 10^15 — vẫn rất lớn, nhưng nhỏ hơn b^d ban đầu hàng chục mũ.\n",
    "# Tức là alpha–beta có thể giảm đáng kể kích thước tree nhưng vẫn không biến việc duyệt toàn bộ đến độ sâu 42 thành khả thi; cần thêm transposition tables, symmetry reductions, heuristics, v.v.\n",
    "# So sánh với không gian trạng thái\n",
    "# Số vị trí hợp lệ (legal positions) của Connect-4 4.531985219092 × 10^12 (khoảng 4.53 nghìn tỷ)\n",
    "# Tuy nhiên số cây trò chơi (số chuỗi nước đi khác nhau, tức số lá nếu duyệt tới các kết thúc khác nhau) thường lớn hơn số trạng thái hợp lệ vì nhiều chuỗi khác nhau có thể dẫn tới cùng một trạng thái (những trạng thái lặp lại được lưu trong bảng băm sẽ giúp cắt bớt công việc).\n",
    "# Kết luận ngắn gọn\n",
    "# Game tree của Minimax đầy đủ (duyệt tới tất cả các plies hợp lệ) là khổng lồ — nếu tính theo b^d với b ≈ 5.5 và d <= 42 ta có 1.25 x 10^31 nút (ước lượng thô).\n",
    "# Thực tế người ta không duyệt toàn bộ: thường giới hạn độ sâu (8–12 plies), dùng alpha–beta pruning, transposition tables, move ordering, và heuristics. Những tối ưu này làm Minimax khả thi trong thực tế và thậm chí cho phép giải (strong-solve) Connect-4 bằng các phương pháp chuyên biệt. (Số trạng thái hợp lệ của trò chơi≈ 4.53 x 10^12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Game Environment and Random Agent [25 point]\n",
    "\n",
    "Use a numpy character array as the board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def empty_board(shape=(6, 7)):\n",
    "    return np.full(shape=shape, fill_value=0)\n",
    "\n",
    "print(empty_board())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard board is $6 \\times 7$ but you can use smaller boards to test your code. Instead of colors (red and yellow), I use 1 and -1 to represent the players. Make sure that your agent functions all have the from: `agent_type(board, player = 1)`, where board is the current board position (in the format above) and player is the player whose next move it is and who the agent should play (as 1 and -1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualization code by Randolph Rankin\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize(board):\n",
    "    plt.axes()\n",
    "    rectangle=plt.Rectangle((-0.5,len(board)*-1+0.5),len(board[0]),len(board),fc='blue')\n",
    "    circles=[]\n",
    "    for i,row in enumerate(board):\n",
    "        for j,val in enumerate(row):\n",
    "            color='white' if val==0 else 'red' if val==1 else 'yellow'\n",
    "            circles.append(plt.Circle((j,i*-1),0.4,fc=color))\n",
    "\n",
    "    plt.gca().add_patch(rectangle)\n",
    "    for circle in circles:\n",
    "        plt.gca().add_patch(circle)\n",
    "\n",
    "    plt.axis('scaled')\n",
    "    plt.show()\n",
    "    \n",
    "board = [[0, 0, 0, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 1, 0, 0, 0],\n",
    "         [0, 0, 0, 1, 0, 0, 0],\n",
    "         [0,-1,-1, 1,-1, 0, 0]]\n",
    "visualize(board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Implement helper functions for:\n",
    "\n",
    "* A check for available actions in each state `actions(state)`.\n",
    "* The transition model `result(state, player, action)`.\n",
    "* Check for terminal states `terminal(state)`.\n",
    "* The utility function `utility(state, player)`.\n",
    "\n",
    "The player argument is used so your agent can play red or yellow.\n",
    "Make sure that all these functions work with boards of different sizes (number of columns and rows).\n",
    "You can follow the [tic-tac-toe example from class.](https://colab.research.google.com/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_definitions.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Board:\n",
      " [[' ' ' ' ' ' ' ' ' ' ' ' ' ']\n",
      " [' ' ' ' ' ' ' ' ' ' ' ' ' ']\n",
      " [' ' ' ' ' ' ' ' ' ' ' ' ' ']\n",
      " [' ' ' ' ' ' ' ' ' ' ' ' ' ']\n",
      " [' ' ' ' ' ' ' ' ' ' ' ' ' ']\n",
      " [' ' ' ' ' ' ' ' ' ' ' ' ' ']]\n",
      "Available actions: [0, 1, 2, 3, 4, 5, 6]\n",
      "\n",
      "After player R moves at column 1:\n",
      "[[' ' ' ' ' ' ' ' ' ' ' ' ' ']\n",
      " [' ' ' ' ' ' ' ' ' ' ' ' ' ']\n",
      " [' ' ' ' ' ' ' ' ' ' ' ' ' ']\n",
      " [' ' ' ' ' ' ' ' ' ' ' ' ' ']\n",
      " [' ' ' ' ' ' ' ' ' ' ' ' ' ']\n",
      " [' ' 'R' ' ' ' ' ' ' ' ' ' ']]\n",
      "Terminal? False\n",
      "Utility (for R): 0\n"
     ]
    }
   ],
   "source": [
    "# Your code/ answer goes here.\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# ==============================\n",
    "# Connect 4 - Task 2: Game Environment and Random Agent\n",
    "# ==============================\n",
    "\n",
    "# Hàm khởi tạo bàn cờ\n",
    "def initial_state(rows=6, cols=7):\n",
    "    \"\"\"\n",
    "    Trả về bàn cờ trống (numpy character array)\n",
    "    rows: số hàng\n",
    "    cols: số cột\n",
    "    \"\"\"\n",
    "    return np.full((rows, cols), ' ', dtype=str)\n",
    "\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 1. Actions: trả về danh sách cột còn trống\n",
    "# ------------------------------------------------\n",
    "def actions(state):\n",
    "    \"\"\"\n",
    "    Trả về danh sách các cột có thể thả quân (ô trên cùng còn trống).\n",
    "    \"\"\"\n",
    "    rows, cols = state.shape\n",
    "    return [c for c in range(cols) if state[0, c] == ' ']\n",
    "\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 2. Transition model: thả quân vào cột được chọn\n",
    "# ------------------------------------------------\n",
    "def result(state, player, action):\n",
    "    \"\"\"\n",
    "    Trả về trạng thái mới sau khi player thả quân vào cột action.\n",
    "    player: 'R' hoặc 'Y'\n",
    "    \"\"\"\n",
    "    new_state = np.copy(state)\n",
    "    rows, cols = state.shape\n",
    "\n",
    "    for r in range(rows - 1, -1, -1):  # thả từ dưới lên\n",
    "        if new_state[r, action] == ' ':\n",
    "            new_state[r, action] = player\n",
    "            break\n",
    "    return new_state\n",
    "\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 3. Kiểm tra trạng thái kết thúc\n",
    "# ------------------------------------------------\n",
    "def terminal(state):\n",
    "    \"\"\"\n",
    "    Trả về True nếu:\n",
    "    - Một người chơi thắng (4 liên tiếp)\n",
    "    - Hoặc bàn cờ đầy (hòa)\n",
    "    \"\"\"\n",
    "    return check_winner(state) is not None or all(state[0, c] != ' ' for c in range(state.shape[1]))\n",
    "\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 4. Kiểm tra người thắng\n",
    "# ------------------------------------------------\n",
    "def check_winner(state):\n",
    "    \"\"\"\n",
    "    Kiểm tra xem có người chơi nào thắng chưa (4 liên tiếp).\n",
    "    Trả về 'R' hoặc 'Y' nếu có người thắng, None nếu chưa.\n",
    "    \"\"\"\n",
    "    rows, cols = state.shape\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            if state[r, c] == ' ':\n",
    "                continue\n",
    "            player = state[r, c]\n",
    "\n",
    "            # 4 hướng: ngang, dọc, chéo phải xuống, chéo trái xuống\n",
    "            if c + 3 < cols and all(state[r, c + i] == player for i in range(4)):\n",
    "                return player\n",
    "            if r + 3 < rows and all(state[r + i, c] == player for i in range(4)):\n",
    "                return player\n",
    "            if r + 3 < rows and c + 3 < cols and all(state[r + i, c + i] == player for i in range(4)):\n",
    "                return player\n",
    "            if r + 3 < rows and c - 3 >= 0 and all(state[r + i, c - i] == player for i in range(4)):\n",
    "                return player\n",
    "    return None\n",
    "\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 5. Utility function\n",
    "# ------------------------------------------------\n",
    "def utility(state, player):\n",
    "    \"\"\"\n",
    "    Trả về giá trị tiện ích:\n",
    "    +1 nếu player thắng,\n",
    "    -1 nếu đối thủ thắng,\n",
    "    0 nếu hòa hoặc chưa kết thúc.\n",
    "    \"\"\"\n",
    "    winner = check_winner(state)\n",
    "    if winner == player:\n",
    "        return 1\n",
    "    elif winner is not None and winner != player:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 6. Random Agent\n",
    "# ------------------------------------------------\n",
    "def random_agent_action(state):\n",
    "    \"\"\"\n",
    "    Chọn một hành động (cột) ngẫu nhiên trong danh sách hành động hợp lệ.\n",
    "    \"\"\"\n",
    "    legal_moves = actions(state)\n",
    "    return random.choice(legal_moves) if legal_moves else None\n",
    "\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 7. Demo test\n",
    "# ------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    state = initial_state(6, 7)\n",
    "    print(\"Initial Board:\\n\", state)\n",
    "    print(\"Available actions:\", actions(state))\n",
    "\n",
    "    # Player 'R' random move\n",
    "    move = random_agent_action(state)\n",
    "    state = result(state, 'R', move)\n",
    "    print(f\"\\nAfter player R moves at column {move}:\")\n",
    "    print(state)\n",
    "\n",
    "    print(\"Terminal?\", terminal(state))\n",
    "    print(\"Utility (for R):\", utility(state, 'R'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement an agent that plays randomly. Make sure the agent function receives as the percept the board and returns a valid action. Use an agent function definition with the following signature (arguments):\n",
    "\n",
    "`def random_player(board, player = 1): ...`\n",
    "\n",
    "The argument `player` is used for agents that do not store what color they are playing. The value passed on by the environment should be 1 ot -1 for player red and yellow, respectively.  See [Experiments section for tic-tac-toe](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_and_or_tree_search.ipynb#Experiments) for an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial board:\n",
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]]\n",
      "Available actions: [0, 1, 2, 3, 4, 5, 6]\n",
      "\n",
      "Random agent (Red) chooses column 3\n",
      "\n",
      "Board after move:\n",
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Your code/ answer goes here.\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# =====================================================\n",
    "# Task 2 (phần mở rộng): Random Player Agent\n",
    "# =====================================================\n",
    "\n",
    "def actions(board):\n",
    "    \"\"\"Trả về danh sách các cột hợp lệ.\"\"\"\n",
    "    rows, cols = board.shape\n",
    "    return [c for c in range(cols) if board[0, c] == 0]\n",
    "\n",
    "\n",
    "def result(board, player, action):\n",
    "    \"\"\"Thực hiện hành động và trả về bàn cờ mới.\"\"\"\n",
    "    new_board = np.copy(board)\n",
    "    rows, cols = board.shape\n",
    "    for r in range(rows - 1, -1, -1):\n",
    "        if new_board[r, action] == 0:\n",
    "            new_board[r, action] = player\n",
    "            break\n",
    "    return new_board\n",
    "\n",
    "\n",
    "def random_player(board, player=1):\n",
    "    \"\"\"\n",
    "    Agent ngẫu nhiên:\n",
    "    - board: numpy array (0 = trống, 1 = đỏ, -1 = vàng)\n",
    "    - player: 1 hoặc -1\n",
    "    Trả về chỉ số cột được chọn.\n",
    "    \"\"\"\n",
    "    possible_actions = actions(board)\n",
    "    if not possible_actions:\n",
    "        return None  # Không còn hành động hợp lệ\n",
    "    return random.choice(possible_actions)\n",
    "\n",
    "# Tạo bàn cờ ban đầu (6 hàng x 7 cột)\n",
    "board = np.zeros((6, 7), dtype=int)\n",
    "\n",
    "# In bàn cờ và hành động hợp lệ\n",
    "print(\"Initial board:\")\n",
    "print(board)\n",
    "print(\"Available actions:\", actions(board))\n",
    "\n",
    "# Random player (đỏ) chọn nước đi\n",
    "move = random_player(board, player=1)\n",
    "print(f\"\\nRandom agent (Red) chooses column {move}\")\n",
    "\n",
    "# Áp dụng hành động\n",
    "board = result(board, player=1, action=move)\n",
    "print(\"\\nBoard after move:\")\n",
    "print(board)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let two random agents play against each other 1000 times. Look at the [Experiments section for tic-tac-toe](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_and_or_tree_search.ipynb#Experiments) to see how the environment uses the agent functions to play against each other.\n",
    "\n",
    "How often does each player win? Is the result expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated 1000 random vs random Connect-4 games (Red goes first).\n",
      "Time taken: 0.54s\n",
      "Wins - Red (player 1): 571 (57.100%)\n",
      "Wins - Yellow (player -1): 428 (42.800%)\n",
      "Draws: 1 (0.100%)\n",
      "Average moves per game: 21.60, median: 21.0\n",
      "\n",
      "Move-length distribution (moves:count) for 7..42 where count>0:\n",
      "7:18  8:3  9:21  10:12  11:33  12:23  13:49  14:28  15:38  16:35  17:54  18:34  19:61  20:31  21:63  22:51  23:52  24:48  25:50  26:41  27:37  28:40  29:34  30:26  31:22  32:17  33:18  34:16  35:10  36:16  37:2  38:4  39:6  40:1  41:3  42:3  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({1: 571, -1: 428, 0: 1},\n",
       " 21.599,\n",
       " 21.0,\n",
       " [(21, 63), (19, 61), (17, 54), (23, 52), (22, 51)])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code/ answer goes here.\n",
    "# Retry simulation of 1000 random vs random Connect-4 games.\n",
    "import numpy as np, random, time, collections\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "ROWS, COLS = 6, 7\n",
    "def initial_state(rows=ROWS, cols=COLS):\n",
    "    return np.zeros((rows, cols), dtype=int)\n",
    "def actions(board):\n",
    "    rows, cols = board.shape\n",
    "    return [c for c in range(cols) if board[0, c] == 0]\n",
    "def result(board, player, action):\n",
    "    new = board.copy()\n",
    "    rows, cols = new.shape\n",
    "    for r in range(rows-1, -1, -1):\n",
    "        if new[r, action] == 0:\n",
    "            new[r, action] = player\n",
    "            break\n",
    "    return new\n",
    "def check_winner(board):\n",
    "    rows, cols = board.shape\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            player = board[r, c]\n",
    "            if player == 0:\n",
    "                continue\n",
    "            if c + 3 < cols and all(board[r, c+i] == player for i in range(4)):\n",
    "                return player\n",
    "            if r + 3 < rows and all(board[r+i, c] == player for i in range(4)):\n",
    "                return player\n",
    "            if r + 3 < rows and c + 3 < cols and all(board[r+i, c+i] == player for i in range(4)):\n",
    "                return player\n",
    "            if r + 3 < rows and c - 3 >= 0 and all(board[r+i, c-i] == player for i in range(4)):\n",
    "                return player\n",
    "    return None\n",
    "def terminal(board):\n",
    "    return check_winner(board) is not None or all(board[0, c] != 0 for c in range(board.shape[1]))\n",
    "def random_player_action(board, player=1):\n",
    "    legal = actions(board)\n",
    "    if not legal:\n",
    "        return None\n",
    "    return random.choice(legal)\n",
    "\n",
    "def play_game(first_player=1):\n",
    "    board = initial_state()\n",
    "    player = first_player\n",
    "    moves = 0\n",
    "    while True:\n",
    "        act = random_player_action(board, player)\n",
    "        if act is None:\n",
    "            break\n",
    "        board = result(board, player, act)\n",
    "        moves += 1\n",
    "        w = check_winner(board)\n",
    "        if w is not None:\n",
    "            return int(w), moves\n",
    "        if all(board[0, c] != 0 for c in range(board.shape[1])):\n",
    "            return 0, moves\n",
    "        player = -player\n",
    "    return 0, moves\n",
    "\n",
    "N = 1000\n",
    "wins = {1:0, -1:0, 0:0}\n",
    "moves_list = []\n",
    "start = time.time()\n",
    "for i in range(N):\n",
    "    w, moves = play_game(first_player=1)\n",
    "    wins[w] += 1\n",
    "    moves_list.append(moves)\n",
    "end = time.time()\n",
    "\n",
    "total = N\n",
    "win1 = wins[1]\n",
    "win2 = wins[-1]\n",
    "draws = wins[0]\n",
    "avg_moves = sum(moves_list)/len(moves_list)\n",
    "median_moves = np.median(moves_list)\n",
    "\n",
    "print(f\"Simulated {N} random vs random Connect-4 games (Red goes first).\")\n",
    "print(f\"Time taken: {end-start:.2f}s\")\n",
    "print(f\"Wins - Red (player 1): {win1} ({win1/total:.3%})\")\n",
    "print(f\"Wins - Yellow (player -1): {win2} ({win2/total:.3%})\")\n",
    "print(f\"Draws: {draws} ({draws/total:.3%})\")\n",
    "print(f\"Average moves per game: {avg_moves:.2f}, median: {median_moves}\")\n",
    "\n",
    "cnt = collections.Counter(moves_list)\n",
    "print(\"\\nMove-length distribution (moves:count) for 7..42 where count>0:\")\n",
    "for m in range(7, 43):\n",
    "    if cnt.get(m,0)>0:\n",
    "        print(f\"{m}:{cnt[m]}\", end=\"  \")\n",
    "print()\n",
    "wins, avg_moves, median_moves, cnt.most_common(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Minimax Search with Alpha-Beta Pruning\n",
    "\n",
    "### Implement the Search [20 points] \n",
    "\n",
    "Implement minimax search starting from a given board for specifying the player.\n",
    "\n",
    "__Important Notes:__ \n",
    "* You can use code from the [tic-tac-toe example](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_alpha_beta_tree_search.ipynb).\n",
    "* Make sure that all your agent functions have a signature consistent with the random agent above and that it [uses a class to store state information.](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/HOWTOs/store_agent_state_information.ipynb)\n",
    "This is essential to be able play against agents from other students later.\n",
    "* The game tree for a $6 \\times 7$ board is huge and optimal algorithms need to visit each or a large percentage of all nodes in the tree. You can experiment with smaller boards like a $4 \\times 4$ board first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Board:\n",
      " [[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]]\n",
      "\n",
      "Minimax (Red) chooses column 2\n",
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Your code/ answer goes here.\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "\n",
    "# ==============================\n",
    "# Connect 4 - Task 3: Minimax Search with Alpha-Beta Pruning\n",
    "# ==============================\n",
    "\n",
    "ROWS, COLS = 6, 7\n",
    "\n",
    "# ---------- Environment helper functions ----------\n",
    "def initial_state():\n",
    "    return np.zeros((ROWS, COLS), dtype=int)\n",
    "\n",
    "def actions(board):\n",
    "    \"\"\"Return list of valid column indices where a move can be made.\"\"\"\n",
    "    return [c for c in range(COLS) if board[0, c] == 0]\n",
    "\n",
    "def result(board, player, action):\n",
    "    \"\"\"Return a new board after the player drops a disc in column `action`.\"\"\"\n",
    "    new_board = np.copy(board)\n",
    "    for r in range(ROWS - 1, -1, -1):\n",
    "        if new_board[r, action] == 0:\n",
    "            new_board[r, action] = player\n",
    "            break\n",
    "    return new_board\n",
    "\n",
    "def check_winner(board):\n",
    "    \"\"\"Return 1 or -1 if there's a winner, else None.\"\"\"\n",
    "    for r in range(ROWS):\n",
    "        for c in range(COLS):\n",
    "            player = board[r, c]\n",
    "            if player == 0:\n",
    "                continue\n",
    "            # 4 directions: horizontal, vertical, diag-right, diag-left\n",
    "            if c + 3 < COLS and all(board[r, c + i] == player for i in range(4)):\n",
    "                return player\n",
    "            if r + 3 < ROWS and all(board[r + i, c] == player for i in range(4)):\n",
    "                return player\n",
    "            if r + 3 < ROWS and c + 3 < COLS and all(board[r + i, c + i] == player for i in range(4)):\n",
    "                return player\n",
    "            if r + 3 < ROWS and c - 3 >= 0 and all(board[r + i, c - i] == player for i in range(4)):\n",
    "                return player\n",
    "    return None\n",
    "\n",
    "def terminal(board):\n",
    "    \"\"\"Return True if game over (win or full board).\"\"\"\n",
    "    return check_winner(board) is not None or all(board[0, c] != 0 for c in range(COLS))\n",
    "\n",
    "def utility(board, player):\n",
    "    \"\"\"Utility for terminal state.\"\"\"\n",
    "    winner = check_winner(board)\n",
    "    if winner == player:\n",
    "        return 1\n",
    "    elif winner == -player:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# ---------- Heuristic Evaluation ----------\n",
    "def evaluate_board(board, player):\n",
    "    \"\"\"\n",
    "    Heuristic: +score for 2/3 in a row for player, -score for opponent.\n",
    "    Simple pattern counting (for mid-game positions).\n",
    "    \"\"\"\n",
    "    opp = -player\n",
    "    score = 0\n",
    "\n",
    "    def check_line(line):\n",
    "        nonlocal score\n",
    "        if line.count(player) == 3 and line.count(0) == 1:\n",
    "            score += 5\n",
    "        elif line.count(player) == 2 and line.count(0) == 2:\n",
    "            score += 2\n",
    "        if line.count(opp) == 3 and line.count(0) == 1:\n",
    "            score -= 5\n",
    "        elif line.count(opp) == 2 and line.count(0) == 2:\n",
    "            score -= 2\n",
    "\n",
    "    # Check rows, cols, diagonals\n",
    "    for r in range(ROWS):\n",
    "        for c in range(COLS - 3):\n",
    "            check_line(list(board[r, c:c + 4]))\n",
    "    for c in range(COLS):\n",
    "        for r in range(ROWS - 3):\n",
    "            check_line(list(board[r:r + 4, c]))\n",
    "    for r in range(ROWS - 3):\n",
    "        for c in range(COLS - 3):\n",
    "            check_line([board[r + i, c + i] for i in range(4)])\n",
    "            check_line([board[r + 3 - i, c + i] for i in range(4)])\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "# ---------- Minimax with Alpha-Beta ----------\n",
    "def minimax(board, depth, alpha, beta, maximizingPlayer, player):\n",
    "    if depth == 0 or terminal(board):\n",
    "        return evaluate_board(board, player), None\n",
    "\n",
    "    valid_moves = actions(board)\n",
    "    if maximizingPlayer:\n",
    "        value = -math.inf\n",
    "        best_action = random.choice(valid_moves)\n",
    "        for a in valid_moves:\n",
    "            new_board = result(board, player, a)\n",
    "            new_val, _ = minimax(new_board, depth - 1, alpha, beta, False, player)\n",
    "            if new_val > value:\n",
    "                value = new_val\n",
    "                best_action = a\n",
    "            alpha = max(alpha, value)\n",
    "            if alpha >= beta:\n",
    "                break  # β cut-off\n",
    "        return value, best_action\n",
    "    else:\n",
    "        value = math.inf\n",
    "        best_action = random.choice(valid_moves)\n",
    "        for a in valid_moves:\n",
    "            new_board = result(board, -player, a)\n",
    "            new_val, _ = minimax(new_board, depth - 1, alpha, beta, True, player)\n",
    "            if new_val < value:\n",
    "                value = new_val\n",
    "                best_action = a\n",
    "            beta = min(beta, value)\n",
    "            if alpha >= beta:\n",
    "                break  # α cut-off\n",
    "        return value, best_action\n",
    "\n",
    "\n",
    "# ---------- Minimax Agent ----------\n",
    "def minimax_player(board, player=1, depth=4):\n",
    "    \"\"\"\n",
    "    Choose the best action for player using minimax + alpha-beta pruning.\n",
    "    \"\"\"\n",
    "    _, action = minimax(board, depth, -math.inf, math.inf, True, player)\n",
    "    return action\n",
    "\n",
    "\n",
    "# ---------- Random Player (for comparison) ----------\n",
    "def random_player(board, player=1):\n",
    "    legal = actions(board)\n",
    "    return random.choice(legal) if legal else None\n",
    "\n",
    "\n",
    "# ---------- Simple Test ----------\n",
    "if __name__ == \"__main__\":\n",
    "    board = initial_state()\n",
    "    print(\"Initial Board:\\n\", board)\n",
    "\n",
    "    # Let minimax (Red) move first vs random (Yellow)\n",
    "    move = minimax_player(board, player=1, depth=4)\n",
    "    print(f\"\\nMinimax (Red) chooses column {move}\")\n",
    "    board = result(board, 1, move)\n",
    "    print(board)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with some manually created boards (at least 5) to check if the agent spots winning opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long does it take to make a move? Start with a smaller board with 4 columns and make the board larger by adding columns/rows. Explain why using this algorithm on a standard $6 \\times 7$ board is not feasible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move ordering [5 points]\n",
    "\n",
    "Starting the search with better moves will increase the efficiency of alpha-beta pruning. Describe and implement a simple move ordering strategy. Make a table that shows how the ordering strategies influence the time it takes to make a move?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The first few moves [5 points]\n",
    "\n",
    "Start with an empty board. This is the worst case scenario for minimax search since it needs solve all possible games that can be played (minus some pruning) before making the decision. What can you do? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playtime [5 points]\n",
    "\n",
    "Let the Minimax Search agent play a random agent on a $4 \\times 4$ board. Analyze wins, losses and draws."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Heuristic Alpha-Beta Tree Search\n",
    "\n",
    "### Heuristic evaluation function [15 points]\n",
    "\n",
    "Define and implement a heuristic evaluation function. Make sure that the heuristic value stays in the correct range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cutting Off Search [10 points]\n",
    "\n",
    "Modify your minimax search with alpha-beta pruning to cut off search at a specified depth and use the heuristic evaluation function. Experiment with different cutoff values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with the same manually created boards as above to check if the agent spots wining opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long does it take to make a move? Start with a smaller board with 4 columns and make the board larger by adding columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playtime [5 points]\n",
    "\n",
    "Let two heuristic search agents (different cutoff depth) compete against each other on a reasonably sized board. Since there is no randomness, you only need to let them play once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge task [up to +10 bonus point will be awarded separately]\n",
    "\n",
    "Find another student and let your best agent play against the other student's best player. We will set up a class tournament on Canvas. This tournament will continue after the submission deadline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graduate student advanced task: Pure Monte Carlo Search and Best First Move [10 point]\n",
    "\n",
    "__Undergraduate students:__ This is a bonus task you can attempt if you like [+5 bonus point].\n",
    "\n",
    "### Pure Monte Carlo Search\n",
    "\n",
    "Implement Pure Monte Carlo Search and investigate how this search performs on the test boards that you have used above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best First Move\n",
    "\n",
    "Use your Monte Carlo Search to determine what the best first move for red is? Describe under what assumptions this is the \"best\" first move.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
